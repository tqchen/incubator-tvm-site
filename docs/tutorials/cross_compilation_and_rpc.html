

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Cross Compilation and RPC &mdash; tvm 0.7.dev1 documentation</title>
  

  
  
    <link rel="shortcut icon" href="../_static/tvm-logo-square.png"/>
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/tvm_theme.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Get Started with Tensor Expression" href="tensor_expr_get_started.html" />
    <link rel="prev" title="Quick Start Tutorial for Compiling Deep Learning Models" href="relay_quick_start.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html">
          

          
            
            <img src="../_static/tvm-logo-small.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.7.dev1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../install/index.html">Installation</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Tutorials</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="relay_quick_start.html">Quick Start Tutorial for Compiling Deep Learning Models</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Cross Compilation and RPC</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#build-tvm-runtime-on-device">Build TVM Runtime on Device</a></li>
<li class="toctree-l3"><a class="reference internal" href="#set-up-rpc-server-on-device">Set Up RPC Server on Device</a></li>
<li class="toctree-l3"><a class="reference internal" href="#declare-and-cross-compile-kernel-on-local-machine">Declare and Cross Compile Kernel on Local Machine</a></li>
<li class="toctree-l3"><a class="reference internal" href="#run-cpu-kernel-remotely-by-rpc">Run CPU Kernel Remotely by RPC</a></li>
<li class="toctree-l3"><a class="reference internal" href="#run-opencl-kernel-remotely-by-rpc">Run OpenCL Kernel Remotely by RPC</a></li>
<li class="toctree-l3"><a class="reference internal" href="#summary">Summary</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="tensor_expr_get_started.html">Get Started with Tensor Expression</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#compile-deep-learning-models">Compile Deep Learning Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#tensor-expression-and-schedules">Tensor Expression and Schedules</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#optimize-tensor-operators">Optimize Tensor Operators</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#auto-tuning">Auto tuning</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#developer-tutorials">Developer Tutorials</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#topi-tvm-operator-inventory">TOPI: TVM Operator Inventory</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../vta/index.html">VTA: Deep Learning Accelerator Stack</a></li>
<li class="toctree-l1"><a class="reference internal" href="../deploy/index.html">Deploy and Integration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contribute/index.html">Contribute to TVM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">Frequently Asked Questions</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../langref/index.html">Language Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/python/index.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_links.html">Links to API References</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../dev/index.html">Design and Developer Guide</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../frontend/tensorflow.html">TensorFlow Frontend</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../genindex.html">Index</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">tvm</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="index.html">Tutorials</a> &raquo;</li>
        
      <li>Cross Compilation and RPC</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/tutorials/cross_compilation_and_rpc.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-tutorials-cross-compilation-and-rpc-py"><span class="std std-ref">here</span></a> to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="cross-compilation-and-rpc">
<span id="tutorial-cross-compilation-and-rpc"></span><span id="sphx-glr-tutorials-cross-compilation-and-rpc-py"></span><h1>Cross Compilation and RPC<a class="headerlink" href="#cross-compilation-and-rpc" title="Permalink to this headline">¶</a></h1>
<p><strong>Author</strong>: <a class="reference external" href="https://github.com/ZihengJiang/">Ziheng Jiang</a>, <a class="reference external" href="https://github.com/merrymercy/">Lianmin Zheng</a></p>
<p>This tutorial introduces cross compilation and remote device
execution with RPC in TVM.</p>
<p>With cross compilation and RPC, you can <strong>compile a program on your
local machine then run it on the remote device</strong>. It is useful when
the remote device resource are limited, like Raspberry Pi and mobile
platforms. In this tutorial, we will use the Raspberry Pi for a CPU example
and the Firefly-RK3399 for an OpenCL example.</p>
<div class="section" id="build-tvm-runtime-on-device">
<h2>Build TVM Runtime on Device<a class="headerlink" href="#build-tvm-runtime-on-device" title="Permalink to this headline">¶</a></h2>
<p>The first step is to build the TVM runtime on the remote device.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>All instructions in both this section and the next section should be
executed on the target device, e.g. Raspberry Pi.  We assume the target
is running Linux.</p>
</div>
<p>Since we do compilation on the local machine, the remote device is only used
for running the generated code. We only need to build the TVM runtime on
the remote device.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre>git clone --recursive https://github.com/apache/incubator-tvm tvm
<span class="nb">cd</span> tvm
make runtime -j2
</pre></div>
</div>
<p>After building the runtime successfully, we need to set environment variables
in <code class="code docutils literal notranslate"><span class="pre">~/.bashrc</span></code> file. We can edit <code class="code docutils literal notranslate"><span class="pre">~/.bashrc</span></code>
using <code class="code docutils literal notranslate"><span class="pre">vi</span> <span class="pre">~/.bashrc</span></code> and add the line below (Assuming your TVM
directory is in <code class="code docutils literal notranslate"><span class="pre">~/tvm</span></code>):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span class="nb">export</span> <span class="nv">PYTHONPATH</span><span class="o">=</span>$PYTHONPATH:~/tvm/python
</pre></div>
</div>
<p>To update the environment variables, execute <code class="code docutils literal notranslate"><span class="pre">source</span> <span class="pre">~/.bashrc</span></code>.</p>
</div>
<div class="section" id="set-up-rpc-server-on-device">
<h2>Set Up RPC Server on Device<a class="headerlink" href="#set-up-rpc-server-on-device" title="Permalink to this headline">¶</a></h2>
<p>To start an RPC server, run the following command on your remote device
(Which is Raspberry Pi in this example).</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre>python -m tvm.exec.rpc_server --host 0.0.0.0 --port<span class="o">=</span>9090
</pre></div>
</div>
</div></blockquote>
<p>If you see the line below, it means the RPC server started
successfully on your device.</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre>INFO:root:RPCServer: <span class="nb">bind</span> to 0.0.0.0:9090
</pre></div>
</div>
</div></blockquote>
</div>
<div class="section" id="declare-and-cross-compile-kernel-on-local-machine">
<h2>Declare and Cross Compile Kernel on Local Machine<a class="headerlink" href="#declare-and-cross-compile-kernel-on-local-machine" title="Permalink to this headline">¶</a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Now we go back to the local machine, which has a full TVM installed
(with LLVM).</p>
</div>
<p>Here we will declare a simple kernel on the local machine:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">tvm</span>
<span class="kn">from</span> <span class="nn">tvm</span> <span class="k">import</span> <span class="n">te</span>
<span class="kn">from</span> <span class="nn">tvm</span> <span class="k">import</span> <span class="n">rpc</span>
<span class="kn">from</span> <span class="nn">tvm.contrib</span> <span class="k">import</span> <span class="n">util</span>

<span class="n">n</span> <span class="o">=</span> <a href="../api/python/runtime.html#tvm.runtime.convert" title="View documentation for tvm.runtime.convert"><span class="n">tvm</span><span class="o">.</span><span class="n">runtime</span><span class="o">.</span><span class="n">convert</span></a><span class="p">(</span><span class="mi">1024</span><span class="p">)</span>
<span class="n">A</span> <span class="o">=</span> <a href="../api/python/te.html#tvm.te.placeholder" title="View documentation for tvm.te.placeholder"><span class="n">te</span><span class="o">.</span><span class="n">placeholder</span></a><span class="p">((</span><span class="n">n</span><span class="p">,),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;A&#39;</span><span class="p">)</span>
<span class="n">B</span> <span class="o">=</span> <a href="../api/python/te.html#tvm.te.compute" title="View documentation for tvm.te.compute"><span class="n">te</span><span class="o">.</span><span class="n">compute</span></a><span class="p">((</span><span class="n">n</span><span class="p">,),</span> <span class="k">lambda</span> <span class="n">i</span><span class="p">:</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;B&#39;</span><span class="p">)</span>
<span class="n">s</span> <span class="o">=</span> <a href="../api/python/te.html#tvm.te.create_schedule" title="View documentation for tvm.te.create_schedule"><span class="n">te</span><span class="o">.</span><span class="n">create_schedule</span></a><span class="p">(</span><span class="n">B</span><span class="o">.</span><span class="n">op</span><span class="p">)</span>
</pre></div>
</div>
<p>Then we cross compile the kernel.
The target should be ‘llvm -target=armv7l-linux-gnueabihf’ for
Raspberry Pi 3B, but we use ‘llvm’ here to make this tutorial runnable
on our webpage building server. See the detailed note in the following block.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="n">local_demo</span> <span class="o">=</span> <span class="kc">True</span>

<span class="k">if</span> <span class="n">local_demo</span><span class="p">:</span>
    <span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;llvm&#39;</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;llvm -target=armv7l-linux-gnueabihf&#39;</span>

<span class="n">func</span> <span class="o">=</span> <a href="../api/python/driver.html#tvm.build" title="View documentation for tvm.build"><span class="n">tvm</span><span class="o">.</span><span class="n">build</span></a><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="p">[</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">],</span> <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;add_one&#39;</span><span class="p">)</span>
<span class="c1"># save the lib at a local temp folder</span>
<span class="n">temp</span> <span class="o">=</span> <a href="../api/python/contrib.html#tvm.contrib.util.tempdir" title="View documentation for tvm.contrib.util.tempdir"><span class="n">util</span><span class="o">.</span><span class="n">tempdir</span></a><span class="p">()</span>
<span class="n">path</span> <span class="o">=</span> <span class="n">temp</span><span class="o">.</span><span class="n">relpath</span><span class="p">(</span><span class="s1">&#39;lib.tar&#39;</span><span class="p">)</span>
<span class="n">func</span><span class="o">.</span><span class="n">export_library</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>To run this tutorial with a real remote device, change <code class="code docutils literal notranslate"><span class="pre">local_demo</span></code>
to False and replace <code class="code docutils literal notranslate"><span class="pre">target</span></code> in <code class="code docutils literal notranslate"><span class="pre">build</span></code> with the appropriate
target triple for your device. The target triple which might be
different for different devices. For example, it is
<code class="code docutils literal notranslate"><span class="pre">'llvm</span> <span class="pre">-target=armv7l-linux-gnueabihf'</span></code> for Raspberry Pi 3B and
<code class="code docutils literal notranslate"><span class="pre">'llvm</span> <span class="pre">-target=aarch64-linux-gnu'</span></code> for RK3399.</p>
<p>Usually, you can query the target by running <code class="code docutils literal notranslate"><span class="pre">gcc</span> <span class="pre">-v</span></code> on your
device, and looking for the line starting with <code class="code docutils literal notranslate"><span class="pre">Target:</span></code>
(Though it may still be a loose configuration.)</p>
<p>Besides <code class="code docutils literal notranslate"><span class="pre">-target</span></code>, you can also set other compilation options
like:</p>
<ul>
<li><dl class="simple">
<dt>-mcpu=&lt;cpuname&gt;</dt><dd><p>Specify a specific chip in the current architecture to generate code for. By default this is inferred from the target triple and autodetected to the current architecture.</p>
</dd>
</dl>
</li>
<li><dl>
<dt>-mattr=a1,+a2,-a3,…</dt><dd><p>Override or control specific attributes of the target, such as whether SIMD operations are enabled or not. The default set of attributes is set by the current CPU.
To get the list of available attributes, you can do:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre>llc -mtriple<span class="o">=</span>&lt;your device target triple&gt; -mattr<span class="o">=</span><span class="nb">help</span>
</pre></div>
</div>
</dd>
</dl>
</li>
</ul>
<p>These options are consistent with <a class="reference external" href="http://llvm.org/docs/CommandGuide/llc.html">llc</a>.
It is recommended to set target triple and feature set to contain specific
feature available, so we can take full advantage of the features of the
board.
You can find more details about cross compilation attributes from
<a class="reference external" href="https://clang.llvm.org/docs/CrossCompilation.html">LLVM guide of cross compilation</a>.</p>
</div>
</div>
<div class="section" id="run-cpu-kernel-remotely-by-rpc">
<h2>Run CPU Kernel Remotely by RPC<a class="headerlink" href="#run-cpu-kernel-remotely-by-rpc" title="Permalink to this headline">¶</a></h2>
<p>We show how to run the generated CPU kernel on the remote device.
First we obtain an RPC session from remote device.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="k">if</span> <span class="n">local_demo</span><span class="p">:</span>
    <span class="n">remote</span> <span class="o">=</span> <a href="../api/python/rpc.html#tvm.rpc.LocalSession" title="View documentation for tvm.rpc.LocalSession"><span class="n">rpc</span><span class="o">.</span><span class="n">LocalSession</span></a><span class="p">()</span>
<span class="k">else</span><span class="p">:</span>
    <span class="c1"># The following is my environment, change this to the IP address of your target device</span>
    <span class="n">host</span> <span class="o">=</span> <span class="s1">&#39;10.77.1.162&#39;</span>
    <span class="n">port</span> <span class="o">=</span> <span class="mi">9090</span>
    <span class="n">remote</span> <span class="o">=</span> <a href="../api/python/rpc.html#tvm.rpc.connect" title="View documentation for tvm.rpc.connect"><span class="n">rpc</span><span class="o">.</span><span class="n">connect</span></a><span class="p">(</span><span class="n">host</span><span class="p">,</span> <span class="n">port</span><span class="p">)</span>
</pre></div>
</div>
<p>Upload the lib to the remote device, then invoke a device local
compiler to relink them. Now <cite>func</cite> is a remote module object.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="n">remote</span><span class="o">.</span><span class="n">upload</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
<span class="n">func</span> <span class="o">=</span> <span class="n">remote</span><span class="o">.</span><span class="n">load_module</span><span class="p">(</span><span class="s1">&#39;lib.tar&#39;</span><span class="p">)</span>

<span class="c1"># create arrays on the remote device</span>
<span class="n">ctx</span> <span class="o">=</span> <span class="n">remote</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
<span class="n">a</span> <span class="o">=</span> <a href="../api/python/ndarray.html#tvm.nd.array" title="View documentation for tvm.nd.array"><span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span></a><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">1024</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="n">ctx</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <a href="../api/python/ndarray.html#tvm.nd.array" title="View documentation for tvm.nd.array"><span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span></a><span class="p">(</span><a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros.html#numpy.zeros" title="View documentation for numpy.zeros"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">A</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="n">ctx</span><span class="p">)</span>
<span class="c1"># the function will run on the remote device</span>
<span class="n">func</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.testing.assert_equal.html#numpy.testing.assert_equal" title="View documentation for numpy.testing.assert_equal"><span class="n">np</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_equal</span></a><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(),</span> <span class="n">a</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>When you want to evaluate the performance of the kernel on the remote
device, it is important to avoid the overhead of network.
<code class="code docutils literal notranslate"><span class="pre">time_evaluator</span></code> will returns a remote function that runs the
function over number times, measures the cost per run on the remote
device and returns the measured cost. Network overhead is excluded.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="n">time_f</span> <span class="o">=</span> <span class="n">func</span><span class="o">.</span><span class="n">time_evaluator</span><span class="p">(</span><span class="n">func</span><span class="o">.</span><span class="n">entry_name</span><span class="p">,</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">number</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">cost</span> <span class="o">=</span> <span class="n">time_f</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">%g</span><span class="s1"> secs/op&#39;</span> <span class="o">%</span> <span class="n">cost</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre>1.723e-07 secs/op
</pre></div>
</div>
</div>
<div class="section" id="run-opencl-kernel-remotely-by-rpc">
<h2>Run OpenCL Kernel Remotely by RPC<a class="headerlink" href="#run-opencl-kernel-remotely-by-rpc" title="Permalink to this headline">¶</a></h2>
<p>For remote OpenCL devices, the workflow is almost the same as above.
You can define the kernel, upload files, and run via RPC.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Raspberry Pi does not support OpenCL, the following code is tested on
Firefly-RK3399. You may follow this <a class="reference external" href="https://gist.github.com/mli/585aed2cec0b5178b1a510f9f236afa2">tutorial</a>
to setup the OS and OpenCL driver for RK3399.</p>
<p>Also we need to build the runtime with OpenCL enabled on rk3399 board. In the TVM
root directory, execute</p>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre>cp cmake/config.cmake .
sed -i <span class="s2">&quot;s/USE_OPENCL OFF/USE_OPENCL ON/&quot;</span> config.cmake
make runtime -j4
</pre></div>
</div>
<p>The following function shows how we run an OpenCL kernel remotely</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="k">def</span> <span class="nf">run_opencl</span><span class="p">():</span>
    <span class="c1"># NOTE: This is the setting for my rk3399 board. You need to modify</span>
    <span class="c1"># them according to your environment.</span>
    <span class="n">target_host</span> <span class="o">=</span> <span class="s2">&quot;llvm -target=aarch64-linux-gnu&quot;</span>
    <span class="n">opencl_device_host</span> <span class="o">=</span> <span class="s1">&#39;10.77.1.145&#39;</span>
    <span class="n">opencl_device_port</span> <span class="o">=</span> <span class="mi">9090</span>

    <span class="c1"># create schedule for the above &quot;add one&quot; compute declaration</span>
    <span class="n">s</span> <span class="o">=</span> <a href="../api/python/te.html#tvm.te.create_schedule" title="View documentation for tvm.te.create_schedule"><span class="n">te</span><span class="o">.</span><span class="n">create_schedule</span></a><span class="p">(</span><span class="n">B</span><span class="o">.</span><span class="n">op</span><span class="p">)</span>
    <span class="n">xo</span><span class="p">,</span> <span class="n">xi</span> <span class="o">=</span> <span class="n">s</span><span class="p">[</span><span class="n">B</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">B</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">axis</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">factor</span><span class="o">=</span><span class="mi">32</span><span class="p">)</span>
    <span class="n">s</span><span class="p">[</span><span class="n">B</span><span class="p">]</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="n">xo</span><span class="p">,</span> <a href="../api/python/te.html#tvm.te.thread_axis" title="View documentation for tvm.te.thread_axis"><span class="n">te</span><span class="o">.</span><span class="n">thread_axis</span></a><span class="p">(</span><span class="s2">&quot;blockIdx.x&quot;</span><span class="p">))</span>
    <span class="n">s</span><span class="p">[</span><span class="n">B</span><span class="p">]</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="n">xi</span><span class="p">,</span> <a href="../api/python/te.html#tvm.te.thread_axis" title="View documentation for tvm.te.thread_axis"><span class="n">te</span><span class="o">.</span><span class="n">thread_axis</span></a><span class="p">(</span><span class="s2">&quot;threadIdx.x&quot;</span><span class="p">))</span>
    <span class="n">func</span> <span class="o">=</span> <a href="../api/python/driver.html#tvm.build" title="View documentation for tvm.build"><span class="n">tvm</span><span class="o">.</span><span class="n">build</span></a><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="p">[</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">],</span> <span class="s2">&quot;opencl&quot;</span><span class="p">,</span> <span class="n">target_host</span><span class="o">=</span><span class="n">target_host</span><span class="p">)</span>

    <span class="n">remote</span> <span class="o">=</span> <a href="../api/python/rpc.html#tvm.rpc.connect" title="View documentation for tvm.rpc.connect"><span class="n">rpc</span><span class="o">.</span><span class="n">connect</span></a><span class="p">(</span><span class="n">opencl_device_host</span><span class="p">,</span> <span class="n">opencl_device_port</span><span class="p">)</span>

    <span class="c1"># export and upload</span>
    <span class="n">path</span> <span class="o">=</span> <span class="n">temp</span><span class="o">.</span><span class="n">relpath</span><span class="p">(</span><span class="s1">&#39;lib_cl.tar&#39;</span><span class="p">)</span>
    <span class="n">func</span><span class="o">.</span><span class="n">export_library</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
    <span class="n">remote</span><span class="o">.</span><span class="n">upload</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
    <span class="n">func</span> <span class="o">=</span> <span class="n">remote</span><span class="o">.</span><span class="n">load_module</span><span class="p">(</span><span class="s1">&#39;lib_cl.tar&#39;</span><span class="p">)</span>

    <span class="c1"># run</span>
    <span class="n">ctx</span> <span class="o">=</span> <span class="n">remote</span><span class="o">.</span><span class="n">cl</span><span class="p">()</span>
    <span class="n">a</span> <span class="o">=</span> <a href="../api/python/ndarray.html#tvm.nd.array" title="View documentation for tvm.nd.array"><span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span></a><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">1024</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="n">ctx</span><span class="p">)</span>
    <span class="n">b</span> <span class="o">=</span> <a href="../api/python/ndarray.html#tvm.nd.array" title="View documentation for tvm.nd.array"><span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span></a><span class="p">(</span><a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros.html#numpy.zeros" title="View documentation for numpy.zeros"><span class="n">np</span><span class="o">.</span><span class="n">zeros</span></a><span class="p">(</span><span class="mi">1024</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">A</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span> <span class="n">ctx</span><span class="p">)</span>
    <span class="n">func</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
    <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.testing.assert_equal.html#numpy.testing.assert_equal" title="View documentation for numpy.testing.assert_equal"><span class="n">np</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_equal</span></a><span class="p">(</span><span class="n">b</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(),</span> <span class="n">a</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;OpenCL test passed!&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h2>
<p>This tutorial provides a walk through of cross compilation and RPC
features in TVM.</p>
<ul class="simple">
<li><p>Set up an RPC server on the remote device.</p></li>
<li><p>Set up the target device configuration to cross compile the kernels on the
local machine.</p></li>
<li><p>Upload and run the kernels remotely via the RPC API.</p></li>
</ul>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  0.133 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-tutorials-cross-compilation-and-rpc-py">
<div class="sphx-glr-download docutils container">
<p><a class="reference download internal" download="" href="../_downloads/4cb9cb94f36033c7820ba70d890df4a1/cross_compilation_and_rpc.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">cross_compilation_and_rpc.py</span></code></a></p>
</div>
<div class="sphx-glr-download docutils container">
<p><a class="reference download internal" download="" href="../_downloads/7630fb4eead0706f214a455190118d17/cross_compilation_and_rpc.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">cross_compilation_and_rpc.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="tensor_expr_get_started.html" class="btn btn-neutral float-right" title="Get Started with Tensor Expression" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="relay_quick_start.html" class="btn btn-neutral float-left" title="Quick Start Tutorial for Compiling Deep Learning Models" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, Apache Software Foundation

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-75982049-2', 'auto');
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>