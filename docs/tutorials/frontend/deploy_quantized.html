

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Deploy a Quantized Model on Cuda &mdash; tvm 0.7.dev1 documentation</title>
  

  
  
    <link rel="shortcut icon" href="../../_static/tvm-logo-square.png"/>
  
  
  

  
  <script type="text/javascript" src="../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/tvm_theme.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Compile Caffe2 Models" href="from_caffe2.html" />
    <link rel="prev" title="Compile Keras Models" href="from_keras.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html">
          

          
            
            <img src="../../_static/tvm-logo-small.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.7.dev1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../install/index.html">Installation</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Tutorials</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../relay_quick_start.html">Quick Start Tutorial for Compiling Deep Learning Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cross_compilation_and_rpc.html">Cross Compilation and RPC</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_expr_get_started.html">Get Started with Tensor Expression</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../index.html#compile-deep-learning-models">Compile Deep Learning Models</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="from_onnx.html">Compile ONNX Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="deploy_ssd_gluoncv.html">Deploy Single Shot Multibox Detector(SSD) model</a></li>
<li class="toctree-l3"><a class="reference internal" href="using_external_lib.html">Using External Libraries in Relay</a></li>
<li class="toctree-l3"><a class="reference internal" href="from_coreml.html">Compile CoreML Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="from_keras.html">Compile Keras Models</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Deploy a Quantized Model on Cuda</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#prepare-the-dataset">Prepare the Dataset</a></li>
<li class="toctree-l4"><a class="reference internal" href="#import-the-model">Import the model</a></li>
<li class="toctree-l4"><a class="reference internal" href="#quantize-the-model">Quantize the Model</a></li>
<li class="toctree-l4"><a class="reference internal" href="#run-inference">Run Inference</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="from_caffe2.html">Compile Caffe2 Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="from_mxnet.html">Compile MXNet Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="deploy_model_on_rasp.html">Deploy the Pretrained Model on Raspberry Pi</a></li>
<li class="toctree-l3"><a class="reference internal" href="from_pytorch.html">Compile PyTorch Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="from_tflite.html">Compile TFLite Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="deploy_model_on_android.html">Deploy the Pretrained Model on Android</a></li>
<li class="toctree-l3"><a class="reference internal" href="from_tensorflow.html">Compile Tensorflow Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="from_darknet.html">Compile YOLO-V2 and YOLO-V3 in DarkNet Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="build_gcn.html">Building a Graph Convolutional Network</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#tensor-expression-and-schedules">Tensor Expression and Schedules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#optimize-tensor-operators">Optimize Tensor Operators</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#auto-tuning">Auto tuning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#developer-tutorials">Developer Tutorials</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#topi-tvm-operator-inventory">TOPI: TVM Operator Inventory</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../vta/index.html">VTA: Deep Learning Accelerator Stack</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deploy/index.html">Deploy and Integration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../contribute/index.html">Contribute to TVM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq.html">Frequently Asked Questions</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../langref/index.html">Language Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/index.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_links.html">Links to API References</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../dev/index.html">Design and Developer Guide</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../frontend/tensorflow.html">TensorFlow Frontend</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../genindex.html">Index</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">tvm</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../index.html">Tutorials</a> &raquo;</li>
        
      <li>Deploy a Quantized Model on Cuda</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/tutorials/frontend/deploy_quantized.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-tutorials-frontend-deploy-quantized-py"><span class="std std-ref">here</span></a> to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="deploy-a-quantized-model-on-cuda">
<span id="sphx-glr-tutorials-frontend-deploy-quantized-py"></span><h1>Deploy a Quantized Model on Cuda<a class="headerlink" href="#deploy-a-quantized-model-on-cuda" title="Permalink to this headline">Â¶</a></h1>
<p><strong>Author</strong>: <a class="reference external" href="https://github.com/vinx13">Wuwei Lin</a></p>
<p>This article is an introductory tutorial of automatic quantization with TVM.
Automatic quantization is one of the quantization modes in TVM. More details on
the quantization story in TVM can be found
<a class="reference external" href="https://discuss.tvm.ai/t/quantization-story/3920">here</a>.
In this tutorial, we will import a GluonCV pre-trained model on ImageNet to
Relay, quantize the Relay model and then perform the inference.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">tvm</span>
<span class="kn">from</span> <span class="nn">tvm</span> <span class="k">import</span> <span class="n">te</span>
<span class="kn">from</span> <span class="nn">tvm</span> <span class="k">import</span> <span class="n">relay</span>
<span class="kn">import</span> <span class="nn">mxnet</span> <span class="k">as</span> <span class="nn">mx</span>
<span class="kn">from</span> <span class="nn">tvm.contrib.download</span> <span class="k">import</span> <span class="n">download_testdata</span>
<span class="kn">from</span> <span class="nn">mxnet</span> <span class="k">import</span> <span class="n">gluon</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;resnet18_v1&quot;</span>
<span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;cuda&#39;</span>
<span class="n">ctx</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="prepare-the-dataset">
<h2>Prepare the Dataset<a class="headerlink" href="#prepare-the-dataset" title="Permalink to this headline">Â¶</a></h2>
<p>We will demonstrate how to prepare the calibration dataset for quantization.
We first download the validation set of ImageNet and pre-process the dataset.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="n">calibration_rec</span> <span class="o">=</span> <span class="n">download_testdata</span><span class="p">(</span>
    <span class="s1">&#39;http://data.mxnet.io.s3-website-us-west-1.amazonaws.com/data/val_256_q90.rec&#39;</span><span class="p">,</span>
    <span class="s1">&#39;val_256_q90.rec&#39;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">get_val_data</span><span class="p">(</span><span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">):</span>
    <span class="n">mean_rgb</span> <span class="o">=</span> <span class="p">[</span><span class="mf">123.68</span><span class="p">,</span> <span class="mf">116.779</span><span class="p">,</span> <span class="mf">103.939</span><span class="p">]</span>
    <span class="n">std_rgb</span> <span class="o">=</span> <span class="p">[</span><span class="mf">58.393</span><span class="p">,</span> <span class="mf">57.12</span><span class="p">,</span> <span class="mf">57.375</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">batch_fn</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">batch</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(),</span> <span class="n">batch</span><span class="o">.</span><span class="n">label</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>

    <span class="n">img_size</span> <span class="o">=</span> <span class="mi">299</span> <span class="k">if</span> <span class="n">model_name</span> <span class="o">==</span> <span class="s1">&#39;inceptionv3&#39;</span> <span class="k">else</span> <span class="mi">224</span>
    <span class="n">val_data</span> <span class="o">=</span> <span class="n">mx</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">ImageRecordIter</span><span class="p">(</span>
        <span class="n">path_imgrec</span><span class="o">=</span><span class="n">calibration_rec</span><span class="p">,</span>
        <span class="n">preprocess_threads</span><span class="o">=</span><span class="n">num_workers</span><span class="p">,</span>
        <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
        <span class="n">resize</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
        <span class="n">data_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">img_size</span><span class="p">,</span> <span class="n">img_size</span><span class="p">),</span>
        <span class="n">mean_r</span><span class="o">=</span><span class="n">mean_rgb</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
        <span class="n">mean_g</span><span class="o">=</span><span class="n">mean_rgb</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
        <span class="n">mean_b</span><span class="o">=</span><span class="n">mean_rgb</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>
        <span class="n">std_r</span><span class="o">=</span><span class="n">std_rgb</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
        <span class="n">std_g</span><span class="o">=</span><span class="n">std_rgb</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
        <span class="n">std_b</span><span class="o">=</span><span class="n">std_rgb</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">val_data</span><span class="p">,</span> <span class="n">batch_fn</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre>File /workspace/.tvm_test_data/val_256_q90.rec exists, skip.
</pre></div>
</div>
<p>The calibration dataset should be an iterable object. We define the
calibration dataset as a generator object in Python. In this tutorial, we
only use a few samples for calibration.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="n">calibration_samples</span> <span class="o">=</span> <span class="mi">10</span>

<span class="k">def</span> <span class="nf">calibrate_dataset</span><span class="p">():</span>
    <span class="n">val_data</span><span class="p">,</span> <span class="n">batch_fn</span> <span class="o">=</span> <span class="n">get_val_data</span><span class="p">()</span>
    <span class="n">val_data</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">val_data</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">*</span> <span class="n">batch_size</span> <span class="o">&gt;=</span> <span class="n">calibration_samples</span><span class="p">:</span>
            <span class="k">break</span>
        <span class="n">data</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">batch_fn</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
        <span class="k">yield</span> <span class="p">{</span><span class="s1">&#39;data&#39;</span><span class="p">:</span> <span class="n">data</span><span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="import-the-model">
<h2>Import the model<a class="headerlink" href="#import-the-model" title="Permalink to this headline">Â¶</a></h2>
<p>We use the Relay MxNet frontend to import a model from the Gluon model zoo.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="k">def</span> <span class="nf">get_model</span><span class="p">():</span>
    <span class="n">gluon_model</span> <span class="o">=</span> <span class="n">gluon</span><span class="o">.</span><span class="n">model_zoo</span><span class="o">.</span><span class="n">vision</span><span class="o">.</span><span class="n">get_model</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">img_size</span> <span class="o">=</span> <span class="mi">299</span> <span class="k">if</span> <span class="n">model_name</span> <span class="o">==</span> <span class="s1">&#39;inceptionv3&#39;</span> <span class="k">else</span> <span class="mi">224</span>
    <span class="n">data_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">img_size</span><span class="p">,</span> <span class="n">img_size</span><span class="p">)</span>
    <span class="n">mod</span><span class="p">,</span> <span class="n">params</span> <span class="o">=</span> <a href="../../api/python/relay/frontend.html#tvm.relay.frontend.from_mxnet" title="View documentation for tvm.relay.frontend.from_mxnet"><span class="n">relay</span><span class="o">.</span><span class="n">frontend</span><span class="o">.</span><span class="n">from_mxnet</span></a><span class="p">(</span><span class="n">gluon_model</span><span class="p">,</span> <span class="p">{</span><span class="s2">&quot;data&quot;</span><span class="p">:</span> <span class="n">data_shape</span><span class="p">})</span>
    <span class="k">return</span> <span class="n">mod</span><span class="p">,</span> <span class="n">params</span>
</pre></div>
</div>
</div>
<div class="section" id="quantize-the-model">
<h2>Quantize the Model<a class="headerlink" href="#quantize-the-model" title="Permalink to this headline">Â¶</a></h2>
<p>In quantization, we need to find the scale for each weight and intermediate
feature map tensor of each layer.</p>
<p>For weights, the scales are directly calculated based on the value of the
weights. Two modes are supported: <cite>power2</cite> and <cite>max</cite>. Both modes find the
maximum value within the weight tensor first. In <cite>power2</cite> mode, the maximum
is rounded down to power of two. If the scales of both weights and
intermediate feature maps are power of two, we can leverage bit shifting for
multiplications. This make it computationally more efficient. In <cite>max</cite> mode,
the maximum is used as the scale. Without rounding, <cite>max</cite> mode might have
better accuracy in some cases. When the scales are not powers of two, fixed
point multiplications will be used.</p>
<p>For intermediate feature maps, we can find the scales with data-aware
quantization. Data-aware quantization takes a calibration dataset as the
input argument. Scales are calculated by minimizing the KL divergence between
distribution of activation before and after quantization.
Alternatively, we can also use pre-defined global scales. This saves the time
for calibration. But the accuracy might be impacted.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="k">def</span> <span class="nf">quantize</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">data_aware</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">data_aware</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">relay</span><span class="o">.</span><span class="n">quantize</span><span class="o">.</span><span class="n">qconfig</span><span class="p">(</span><span class="n">calibrate_mode</span><span class="o">=</span><span class="s1">&#39;kl_divergence&#39;</span><span class="p">,</span> <span class="n">weight_scale</span><span class="o">=</span><span class="s1">&#39;max&#39;</span><span class="p">):</span>
            <span class="n">mod</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">quantize</span><span class="o">.</span><span class="n">quantize</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">dataset</span><span class="o">=</span><span class="n">calibrate_dataset</span><span class="p">())</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">relay</span><span class="o">.</span><span class="n">quantize</span><span class="o">.</span><span class="n">qconfig</span><span class="p">(</span><span class="n">calibrate_mode</span><span class="o">=</span><span class="s1">&#39;global_scale&#39;</span><span class="p">,</span> <span class="n">global_scale</span><span class="o">=</span><span class="mf">8.0</span><span class="p">):</span>
            <span class="n">mod</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">quantize</span><span class="o">.</span><span class="n">quantize</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">mod</span>
</pre></div>
</div>
</div>
<div class="section" id="run-inference">
<h2>Run Inference<a class="headerlink" href="#run-inference" title="Permalink to this headline">Â¶</a></h2>
<p>We create a Relay VM to build and execute the model.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="k">def</span> <span class="nf">run_inference</span><span class="p">(</span><span class="n">mod</span><span class="p">):</span>
    <span class="n">executor</span> <span class="o">=</span> <a href="../../api/python/relay/index.html#tvm.relay.create_executor" title="View documentation for tvm.relay.create_executor"><span class="n">relay</span><span class="o">.</span><span class="n">create_executor</span></a><span class="p">(</span><span class="s1">&#39;vm&#39;</span><span class="p">,</span> <span class="n">mod</span><span class="p">,</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
    <span class="n">val_data</span><span class="p">,</span> <span class="n">batch_fn</span> <span class="o">=</span> <span class="n">get_val_data</span><span class="p">()</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">batch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">val_data</span><span class="p">):</span>
        <span class="n">data</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">batch_fn</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>
        <span class="n">prediction</span> <span class="o">=</span> <span class="n">executor</span><span class="o">.</span><span class="n">evaluate</span><span class="p">()(</span><span class="n">data</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">10</span><span class="p">:</span>  <span class="c1"># only run inference on a few samples in this tutorial</span>
            <span class="k">break</span>

<span class="k">def</span> <span class="nf">main</span><span class="p">():</span>
    <span class="n">mod</span><span class="p">,</span> <span class="n">params</span> <span class="o">=</span> <span class="n">get_model</span><span class="p">()</span>
    <span class="n">mod</span> <span class="o">=</span> <span class="n">quantize</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">data_aware</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">run_inference</span><span class="p">(</span><span class="n">mod</span><span class="p">)</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s1">&#39;__main__&#39;</span><span class="p">:</span>
    <span class="n">main</span><span class="p">()</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre>ANTLR runtime and generated code versions disagree: 4.8!=4.7.2
ANTLR runtime and generated code versions disagree: 4.8!=4.7.2
</pre></div>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  18.909 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-tutorials-frontend-deploy-quantized-py">
<div class="sphx-glr-download docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/5b32f1dc3e9e2fc5ac5be0918758b967/deploy_quantized.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">deploy_quantized.py</span></code></a></p>
</div>
<div class="sphx-glr-download docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/4f4a49a5483a0d0aa4af30f58c3c8664/deploy_quantized.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">deploy_quantized.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="from_caffe2.html" class="btn btn-neutral float-right" title="Compile Caffe2 Models" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="from_keras.html" class="btn btn-neutral float-left" title="Compile Keras Models" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, Apache Software Foundation

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-75982049-2', 'auto');
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>