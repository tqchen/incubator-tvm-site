

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Building a Graph Convolutional Network &mdash; tvm 0.7.dev1 documentation</title>
  

  
  
    <link rel="shortcut icon" href="../../_static/tvm-logo-square.png"/>
  
  
  

  
  <script type="text/javascript" src="../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/tvm_theme.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Use Tensor Expression Debug Display (TEDD) for Visualization" href="../language/tedd.html" />
    <link rel="prev" title="Compile YOLO-V2 and YOLO-V3 in DarkNet Models" href="from_darknet.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html">
          

          
            
            <img src="../../_static/tvm-logo-small.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.7.dev1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../install/index.html">Installation</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Tutorials</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../relay_quick_start.html">Quick Start Tutorial for Compiling Deep Learning Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cross_compilation_and_rpc.html">Cross Compilation and RPC</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_expr_get_started.html">Get Started with Tensor Expression</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../index.html#compile-deep-learning-models">Compile Deep Learning Models</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="from_onnx.html">Compile ONNX Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="deploy_ssd_gluoncv.html">Deploy Single Shot Multibox Detector(SSD) model</a></li>
<li class="toctree-l3"><a class="reference internal" href="using_external_lib.html">Using External Libraries in Relay</a></li>
<li class="toctree-l3"><a class="reference internal" href="from_coreml.html">Compile CoreML Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="from_keras.html">Compile Keras Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="deploy_quantized.html">Deploy a Quantized Model on Cuda</a></li>
<li class="toctree-l3"><a class="reference internal" href="from_caffe2.html">Compile Caffe2 Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="from_mxnet.html">Compile MXNet Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="deploy_model_on_rasp.html">Deploy the Pretrained Model on Raspberry Pi</a></li>
<li class="toctree-l3"><a class="reference internal" href="from_pytorch.html">Compile PyTorch Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="from_tflite.html">Compile TFLite Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="deploy_model_on_android.html">Deploy the Pretrained Model on Android</a></li>
<li class="toctree-l3"><a class="reference internal" href="from_tensorflow.html">Compile Tensorflow Models</a></li>
<li class="toctree-l3"><a class="reference internal" href="from_darknet.html">Compile YOLO-V2 and YOLO-V3 in DarkNet Models</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">Building a Graph Convolutional Network</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#define-gcn-in-dgl-with-pytorch-backend">Define GCN in DGL with PyTorch backend</a></li>
<li class="toctree-l4"><a class="reference internal" href="#define-the-functions-to-load-dataset-and-evaluate-accuracy">Define the functions to load dataset and evaluate accuracy</a></li>
<li class="toctree-l4"><a class="reference internal" href="#load-the-data-and-set-up-model-parameters">Load the data and set up model parameters</a></li>
<li class="toctree-l4"><a class="reference internal" href="#set-up-the-dgl-pytorch-model-and-get-the-golden-results">Set up the DGL-PyTorch model and get the golden results</a></li>
<li class="toctree-l4"><a class="reference internal" href="#run-the-dgl-model-and-test-for-accuracy">Run the DGL model and test for accuracy</a></li>
<li class="toctree-l4"><a class="reference internal" href="#define-graph-convolution-layer-in-relay">Define Graph Convolution Layer in Relay</a></li>
<li class="toctree-l4"><a class="reference internal" href="#prepare-the-parameters-needed-in-the-graphconv-layers">Prepare the parameters needed in the GraphConv layers</a></li>
<li class="toctree-l4"><a class="reference internal" href="#put-layers-together">Put layers together</a></li>
<li class="toctree-l4"><a class="reference internal" href="#compile-and-run-with-tvm">Compile and run with TVM</a></li>
<li class="toctree-l4"><a class="reference internal" href="#run-the-tvm-model-test-for-accuracy-and-verify-with-dgl">Run the TVM model, test for accuracy and verify with DGL</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#tensor-expression-and-schedules">Tensor Expression and Schedules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#optimize-tensor-operators">Optimize Tensor Operators</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#auto-tuning">Auto tuning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#developer-tutorials">Developer Tutorials</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#topi-tvm-operator-inventory">TOPI: TVM Operator Inventory</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../vta/index.html">VTA: Deep Learning Accelerator Stack</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deploy/index.html">Deploy and Integration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../contribute/index.html">Contribute to TVM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq.html">Frequently Asked Questions</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../langref/index.html">Language Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/index.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_links.html">Links to API References</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../dev/index.html">Design and Developer Guide</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../frontend/tensorflow.html">TensorFlow Frontend</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../genindex.html">Index</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">tvm</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../index.html">Tutorials</a> &raquo;</li>
        
      <li>Building a Graph Convolutional Network</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/tutorials/frontend/build_gcn.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-tutorials-frontend-build-gcn-py"><span class="std std-ref">here</span></a> to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="building-a-graph-convolutional-network">
<span id="sphx-glr-tutorials-frontend-build-gcn-py"></span><h1>Building a Graph Convolutional Network<a class="headerlink" href="#building-a-graph-convolutional-network" title="Permalink to this headline">¶</a></h1>
<p><strong>Author</strong>: <a class="reference external" href="https://yulunyao.io/">Yulun Yao</a>,             <a class="reference external" href="https://homes.cs.washington.edu/~cyulin/">Chien-Yu Lin</a></p>
<p>This article is an introductory tutorial to build a Graph Convolutional Network (GCN) with Relay.
In this tutorial, we will run our GCN on Cora dataset to demonstrate.
Cora dataset is a common benchmark for Graph Neural Networks (GNN) and frameworks that support GNN training and inference.
We directly load the dataset from DGL library to do the apples to apples comparison against DGL.</p>
<p>Please refer to DGL doc for DGL installation at
<a class="reference external" href="https://docs.dgl.ai/install/index.html">https://docs.dgl.ai/install/index.html</a>.</p>
<p>Please refer to PyTorch guide for PyTorch installation at
<a class="reference external" href="https://pytorch.org/get-started/locally/">https://pytorch.org/get-started/locally/</a>.</p>
<div class="section" id="define-gcn-in-dgl-with-pytorch-backend">
<h2>Define GCN in DGL with PyTorch backend<a class="headerlink" href="#define-gcn-in-dgl-with-pytorch-backend" title="Permalink to this headline">¶</a></h2>
<p>DGL example: <a class="reference external" href="https://github.com/dmlc/dgl/tree/master/examples/pytorch/gcn">https://github.com/dmlc/dgl/tree/master/examples/pytorch/gcn</a>
This part reuses the code from the above example.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">dgl</span>
<span class="kn">import</span> <span class="nn">networkx</span> <span class="k">as</span> <span class="nn">nx</span>
<span class="kn">from</span> <span class="nn">dgl.nn.pytorch</span> <span class="k">import</span> <span class="n">GraphConv</span>

<span class="k">class</span> <span class="nc">GCN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">g</span><span class="p">,</span>
                 <span class="n">n_infeat</span><span class="p">,</span>
                 <span class="n">n_hidden</span><span class="p">,</span>
                 <span class="n">n_classes</span><span class="p">,</span>
                 <span class="n">n_layers</span><span class="p">,</span>
                 <span class="n">activation</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GCN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">g</span> <span class="o">=</span> <span class="n">g</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">GraphConv</span><span class="p">(</span><span class="n">n_infeat</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_layers</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">GraphConv</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">,</span> <span class="n">n_hidden</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">activation</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">GraphConv</span><span class="p">(</span><span class="n">n_hidden</span><span class="p">,</span> <span class="n">n_classes</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">):</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">features</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">):</span>
            <span class="c1"># handle api changes for differnt DGL version</span>
            <span class="k">if</span> <span class="n">dgl</span><span class="o">.</span><span class="n">__version__</span> <span class="o">&gt;</span> <span class="s1">&#39;0.3&#39;</span><span class="p">:</span>
                <span class="n">h</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">g</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">h</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">g</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">h</span>
</pre></div>
</div>
</div>
<div class="section" id="define-the-functions-to-load-dataset-and-evaluate-accuracy">
<h2>Define the functions to load dataset and evaluate accuracy<a class="headerlink" href="#define-the-functions-to-load-dataset-and-evaluate-accuracy" title="Permalink to this headline">¶</a></h2>
<p>You may substitute this part with your own dataset, here we load data from DGL</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">dgl.data</span> <span class="k">import</span> <span class="n">load_data</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="k">import</span> <span class="n">namedtuple</span>

<span class="k">def</span> <span class="nf">load_dataset</span><span class="p">(</span><span class="n">dataset</span><span class="o">=</span><span class="s2">&quot;cora&quot;</span><span class="p">):</span>
    <span class="n">args</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s2">&quot;args&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;dataset&quot;</span><span class="p">])</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="n">args</span><span class="p">(</span><span class="n">dataset</span><span class="p">))</span>

    <span class="c1"># Remove self-loops to avoid duplicate passing of a node&#39;s feature to itself</span>
    <span class="n">g</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">graph</span>
    <span class="n">g</span><span class="o">.</span><span class="n">remove_edges_from</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">selfloop_edges</span><span class="p">(</span><span class="n">g</span><span class="p">))</span>
    <span class="n">g</span><span class="o">.</span><span class="n">add_edges_from</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">nodes</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">nodes</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">g</span><span class="p">,</span> <span class="n">data</span>


<span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">logits</span><span class="p">):</span>
    <span class="n">test_mask</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">test_mask</span> <span class="c1"># the test set which isn&#39;t included in the training phase</span>

    <span class="n">pred</span> <span class="o">=</span> <span class="n">logits</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">acc</span> <span class="o">=</span> <span class="p">((</span><span class="n">pred</span> <span class="o">==</span> <span class="n">data</span><span class="o">.</span><span class="n">labels</span><span class="p">)</span> <span class="o">*</span> <span class="n">test_mask</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="n">test_mask</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

    <span class="k">return</span> <span class="n">acc</span>
</pre></div>
</div>
</div>
<div class="section" id="load-the-data-and-set-up-model-parameters">
<h2>Load the data and set up model parameters<a class="headerlink" href="#load-the-data-and-set-up-model-parameters" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Parameters</span>
<span class="sd">----------</span>
<span class="sd">dataset: str</span>
<span class="sd">    Name of dataset. You can choose from [&#39;cora&#39;, &#39;citeseer&#39;, &#39;pubmed&#39;].</span>

<span class="sd">num_layer: int</span>
<span class="sd">    number of hidden layers</span>

<span class="sd">num_hidden: int</span>
<span class="sd">    number of the hidden units in the hidden layer</span>

<span class="sd">infeat_dim: int</span>
<span class="sd">    dimension of the input features</span>

<span class="sd">num_classes: int</span>
<span class="sd">    dimension of model output (Number of classes)</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="s2">&quot;cora&quot;</span>

<span class="n">g</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>

<span class="n">num_layers</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">num_hidden</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">infeat_dim</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">features</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">num_labels</span>
</pre></div>
</div>
</div>
<div class="section" id="set-up-the-dgl-pytorch-model-and-get-the-golden-results">
<h2>Set up the DGL-PyTorch model and get the golden results<a class="headerlink" href="#set-up-the-dgl-pytorch-model-and-get-the-golden-results" title="Permalink to this headline">¶</a></h2>
<p>The weights are trained with <a class="reference external" href="https://github.com/dmlc/dgl/blob/master/examples/pytorch/gcn/train.py">https://github.com/dmlc/dgl/blob/master/examples/pytorch/gcn/train.py</a></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">tvm.contrib.download</span> <span class="k">import</span> <span class="n">download_testdata</span>
<span class="kn">from</span> <span class="nn">dgl</span> <span class="k">import</span> <span class="n">DGLGraph</span>

<span class="n">features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">features</span><span class="p">)</span>
<span class="n">dgl_g</span> <span class="o">=</span> <span class="n">DGLGraph</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>

<span class="n">torch_model</span> <span class="o">=</span> <span class="n">GCN</span><span class="p">(</span><span class="n">dgl_g</span><span class="p">,</span>
                  <span class="n">infeat_dim</span><span class="p">,</span>
                  <span class="n">num_hidden</span><span class="p">,</span>
                  <span class="n">num_classes</span><span class="p">,</span>
                  <span class="n">num_layers</span><span class="p">,</span>
                  <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">)</span>

<span class="c1"># Download the pretrained weights</span>
<span class="n">model_url</span> <span class="o">=</span> <span class="s2">&quot;https://homes.cs.washington.edu/~cyulin/media/gnn_model/gcn_</span><span class="si">%s</span><span class="s2">.torch&quot;</span><span class="o">%</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
<span class="n">model_path</span> <span class="o">=</span> <span class="n">download_testdata</span><span class="p">(</span><span class="n">model_url</span><span class="p">,</span> <span class="s2">&quot;gcn_</span><span class="si">%s</span><span class="s2">.pickle&quot;</span><span class="o">%</span><span class="p">(</span><span class="n">dataset</span><span class="p">),</span> <span class="n">module</span><span class="o">=</span><span class="s1">&#39;gcn_model&#39;</span><span class="p">)</span>

<span class="c1"># Load the weights into the model</span>
<span class="n">torch_model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">model_path</span><span class="p">))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre>File /workspace/.tvm_test_data/gcn_model/gcn_cora.pickle exists, skip.
</pre></div>
</div>
</div>
<div class="section" id="run-the-dgl-model-and-test-for-accuracy">
<h2>Run the DGL model and test for accuracy<a class="headerlink" href="#run-the-dgl-model-and-test-for-accuracy" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="n">torch_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">logits_torch</span> <span class="o">=</span> <span class="n">torch_model</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Print the first five outputs from DGL-PyTorch execution</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">logits_torch</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>

<span class="n">acc</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">logits_torch</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test accuracy of DGL results: {:.2%}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">acc</span><span class="p">))</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre>Print the first five outputs from DGL-PyTorch execution
 tensor([[-2.1450, -1.3411,  3.6003,  0.1190, -0.9690, -1.4138, -1.0221],
        [ 0.6063, -1.1822, -0.3693, -0.9476,  0.5819,  1.2295,  0.2738],
        [-1.0876,  0.0565, -0.2626, -0.9312,  2.7453, -0.0950, -0.6077],
        [-1.4724,  0.0105, -0.1038, -0.2135,  2.2795, -0.5208, -0.5848],
        [-1.6528, -1.2279,  0.0541,  3.6322, -1.6748, -1.6925,  0.1763]])
Test accuracy of DGL results: 81.40%
</pre></div>
</div>
</div>
<div class="section" id="define-graph-convolution-layer-in-relay">
<h2>Define Graph Convolution Layer in Relay<a class="headerlink" href="#define-graph-convolution-layer-in-relay" title="Permalink to this headline">¶</a></h2>
<p>To run GCN on TVM, we first need to implement Graph Convolution Layer.
You may refer to <a class="reference external" href="https://github.com/dmlc/dgl/blob/master/python/dgl/nn/mxnet/conv.py">https://github.com/dmlc/dgl/blob/master/python/dgl/nn/mxnet/conv.py</a> for a GraphConv Layer implemented in DGL with MXNet Backend</p>
<p>The layer is defined with below operations, note that we apply two transposes to keep adjacency matrix on right hand side of sparse_dense operator,
this method is temporary and will be updated in next few weeks when we have sparse matrix transpose and support for left sparse operator.</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\mbox{GraphConv}(A, H, W)   = A * H * W
                            = ((H * W)^t * A^t)^t
                            = ((W^t * H^t) * A^t)^t\]</div>
</div></blockquote>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">tvm</span> <span class="k">import</span> <span class="n">relay</span>
<span class="kn">from</span> <span class="nn">tvm.contrib</span> <span class="k">import</span> <span class="n">graph_runtime</span>
<span class="kn">import</span> <span class="nn">tvm</span>
<span class="kn">from</span> <span class="nn">tvm</span> <span class="k">import</span> <span class="n">te</span>

<span class="k">def</span> <span class="nf">GraphConv</span><span class="p">(</span><span class="n">layer_name</span><span class="p">,</span>
              <span class="n">input_dim</span><span class="p">,</span>
              <span class="n">output_dim</span><span class="p">,</span>
              <span class="n">adj</span><span class="p">,</span>
              <span class="nb">input</span><span class="p">,</span>
              <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
              <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
              <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    layer_name: str</span>
<span class="sd">    Name of layer</span>

<span class="sd">    input_dim: int</span>
<span class="sd">    Input dimension per node feature</span>

<span class="sd">    output_dim: int,</span>
<span class="sd">    Output dimension per node feature</span>

<span class="sd">    adj: namedtuple,</span>
<span class="sd">    Graph representation (Adjacency Matrix) in Sparse Format (`data`, `indices`, `indptr`),</span>
<span class="sd">    where `data` has shape [num_nonzeros], indices` has shape [num_nonzeros], `indptr` has shape [num_nodes + 1]</span>

<span class="sd">    input: relay.Expr,</span>
<span class="sd">    Input feature to current layer with shape [num_nodes, input_dim]</span>

<span class="sd">    norm: relay.Expr,</span>
<span class="sd">    Norm passed to this layer to normalize features before and after Convolution.</span>

<span class="sd">    bias: bool</span>
<span class="sd">    Set bias to True to add bias when doing GCN layer</span>

<span class="sd">    activation: &lt;function relay.op.nn&gt;,</span>
<span class="sd">    Activation function applies to the output. e.g. relay.nn.{relu, sigmoid, log_softmax, softmax, leaky_relu}</span>

<span class="sd">    Returns</span>
<span class="sd">    ----------</span>
<span class="sd">    output: tvm.relay.Expr</span>
<span class="sd">    The Output Tensor for this layer [num_nodes, output_dim]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">norm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">input</span> <span class="o">=</span> <a href="../../api/python/relay/index.html#tvm.relay.multiply" title="View documentation for tvm.relay.multiply"><span class="n">relay</span><span class="o">.</span><span class="n">multiply</span></a><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">norm</span><span class="p">)</span>

    <span class="n">weight</span> <span class="o">=</span> <a href="../../api/python/relay/index.html#tvm.relay.var" title="View documentation for tvm.relay.var"><span class="n">relay</span><span class="o">.</span><span class="n">var</span></a><span class="p">(</span><span class="n">layer_name</span> <span class="o">+</span> <span class="s2">&quot;.weight&quot;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">))</span>
    <span class="n">weight_t</span> <span class="o">=</span> <a href="../../api/python/relay/index.html#tvm.relay.transpose" title="View documentation for tvm.relay.transpose"><span class="n">relay</span><span class="o">.</span><span class="n">transpose</span></a><span class="p">(</span><span class="n">weight</span><span class="p">)</span>
    <span class="n">dense</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">weight_t</span><span class="p">,</span> <span class="nb">input</span><span class="p">)</span>
    <span class="n">output</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sparse_dense</span><span class="p">(</span><span class="n">dense</span><span class="p">,</span> <span class="n">adj</span><span class="p">)</span>
    <span class="n">output_t</span> <span class="o">=</span> <a href="../../api/python/relay/index.html#tvm.relay.transpose" title="View documentation for tvm.relay.transpose"><span class="n">relay</span><span class="o">.</span><span class="n">transpose</span></a><span class="p">(</span><span class="n">output</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">norm</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">output_t</span> <span class="o">=</span> <a href="../../api/python/relay/index.html#tvm.relay.multiply" title="View documentation for tvm.relay.multiply"><span class="n">relay</span><span class="o">.</span><span class="n">multiply</span></a><span class="p">(</span><span class="n">output_t</span><span class="p">,</span> <span class="n">norm</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">bias</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">_bias</span> <span class="o">=</span> <a href="../../api/python/relay/index.html#tvm.relay.var" title="View documentation for tvm.relay.var"><span class="n">relay</span><span class="o">.</span><span class="n">var</span></a><span class="p">(</span><span class="n">layer_name</span> <span class="o">+</span> <span class="s2">&quot;.bias&quot;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">output_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">output_t</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">bias_add</span><span class="p">(</span><span class="n">output_t</span><span class="p">,</span> <span class="n">_bias</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">activation</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">output_t</span> <span class="o">=</span> <span class="n">activation</span><span class="p">(</span><span class="n">output_t</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">output_t</span>
</pre></div>
</div>
</div>
<div class="section" id="prepare-the-parameters-needed-in-the-graphconv-layers">
<h2>Prepare the parameters needed in the GraphConv layers<a class="headerlink" href="#prepare-the-parameters-needed-in-the-graphconv-layers" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">networkx</span> <span class="k">as</span> <span class="nn">nx</span>

<span class="k">def</span> <span class="nf">prepare_params</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
    <span class="n">params</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">params</span><span class="p">[</span><span class="s1">&#39;infeats&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">features</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span> <span class="c1"># Only support float32 as feature for now</span>

    <span class="c1"># Generate adjacency matrix</span>
    <span class="n">adjacency</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">to_scipy_sparse_matrix</span><span class="p">(</span><span class="n">g</span><span class="p">)</span>
    <span class="n">params</span><span class="p">[</span><span class="s1">&#39;g_data&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">adjacency</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span>
    <span class="n">params</span><span class="p">[</span><span class="s1">&#39;indices&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">adjacency</span><span class="o">.</span><span class="n">indices</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;int32&#39;</span><span class="p">)</span>
    <span class="n">params</span><span class="p">[</span><span class="s1">&#39;indptr&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">adjacency</span><span class="o">.</span><span class="n">indptr</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;int32&#39;</span><span class="p">)</span>

    <span class="c1"># Normalization w.r.t. node degrees</span>
    <span class="n">degs</span> <span class="o">=</span> <span class="p">[</span><span class="n">g</span><span class="o">.</span><span class="n">in_degree</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">number_of_nodes</span><span class="p">())]</span>
    <span class="n">params</span><span class="p">[</span><span class="s1">&#39;norm&#39;</span><span class="p">]</span> <span class="o">=</span> <a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.power.html#numpy.power" title="View documentation for numpy.power"><span class="n">np</span><span class="o">.</span><span class="n">power</span></a><span class="p">(</span><span class="n">degs</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s1">&#39;float32&#39;</span><span class="p">)</span>
    <span class="n">params</span><span class="p">[</span><span class="s1">&#39;norm&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;norm&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;norm&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">params</span>

<span class="n">params</span> <span class="o">=</span> <span class="n">prepare_params</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>

<span class="c1"># Check shape of features and the validity of adjacency matrix</span>
<span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;infeats&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span>
<span class="k">assert</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;g_data&#39;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;indices&#39;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;indptr&#39;</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
<span class="k">assert</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;infeats&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">params</span><span class="p">[</span><span class="s1">&#39;indptr&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>
</pre></div>
</div>
</div>
<div class="section" id="put-layers-together">
<h2>Put layers together<a class="headerlink" href="#put-layers-together" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="c1"># Define input features, norms, adjacency matrix in Relay</span>
<span class="n">infeats</span> <span class="o">=</span> <a href="../../api/python/relay/index.html#tvm.relay.var" title="View documentation for tvm.relay.var"><span class="n">relay</span><span class="o">.</span><span class="n">var</span></a><span class="p">(</span><span class="s2">&quot;infeats&quot;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">features</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">norm</span> <span class="o">=</span> <a href="../../api/python/relay/index.html#tvm.relay.Constant" title="View documentation for tvm.relay.Constant"><span class="n">relay</span><span class="o">.</span><span class="n">Constant</span></a><span class="p">(</span><a href="../../api/python/ndarray.html#tvm.nd.array" title="View documentation for tvm.nd.array"><span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span></a><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;norm&#39;</span><span class="p">]))</span>
<span class="n">g_data</span> <span class="o">=</span> <a href="../../api/python/relay/index.html#tvm.relay.Constant" title="View documentation for tvm.relay.Constant"><span class="n">relay</span><span class="o">.</span><span class="n">Constant</span></a><span class="p">(</span><a href="../../api/python/ndarray.html#tvm.nd.array" title="View documentation for tvm.nd.array"><span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span></a><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;g_data&#39;</span><span class="p">]))</span>
<span class="n">indices</span> <span class="o">=</span> <a href="../../api/python/relay/index.html#tvm.relay.Constant" title="View documentation for tvm.relay.Constant"><span class="n">relay</span><span class="o">.</span><span class="n">Constant</span></a><span class="p">(</span><a href="../../api/python/ndarray.html#tvm.nd.array" title="View documentation for tvm.nd.array"><span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span></a><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;indices&#39;</span><span class="p">]))</span>
<span class="n">indptr</span> <span class="o">=</span> <a href="../../api/python/relay/index.html#tvm.relay.Constant" title="View documentation for tvm.relay.Constant"><span class="n">relay</span><span class="o">.</span><span class="n">Constant</span></a><span class="p">(</span><a href="../../api/python/ndarray.html#tvm.nd.array" title="View documentation for tvm.nd.array"><span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span></a><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;indptr&#39;</span><span class="p">]))</span>

<span class="n">Adjacency</span> <span class="o">=</span> <span class="n">namedtuple</span><span class="p">(</span><span class="s1">&#39;Adjacency&#39;</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;data&#39;</span><span class="p">,</span> <span class="s1">&#39;indices&#39;</span><span class="p">,</span> <span class="s1">&#39;indptr&#39;</span><span class="p">])</span>
<span class="n">adj</span> <span class="o">=</span> <span class="n">Adjacency</span><span class="p">(</span><span class="n">g_data</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">indptr</span><span class="p">)</span>

<span class="c1"># Construct the 2-layer GCN</span>
<span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">GraphConv</span><span class="p">(</span>
    <span class="n">layer_name</span><span class="o">=</span><span class="s2">&quot;layers.0&quot;</span><span class="p">,</span>
    <span class="n">input_dim</span><span class="o">=</span><span class="n">infeat_dim</span><span class="p">,</span>
    <span class="n">output_dim</span><span class="o">=</span><span class="n">num_hidden</span><span class="p">,</span>
    <span class="n">adj</span><span class="o">=</span><span class="n">adj</span><span class="p">,</span>
    <span class="nb">input</span><span class="o">=</span><span class="n">infeats</span><span class="p">,</span>
    <span class="n">norm</span><span class="o">=</span><span class="n">norm</span><span class="p">,</span>
    <span class="n">activation</span><span class="o">=</span><span class="n">relay</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span>
<span class="p">))</span>
<span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">GraphConv</span><span class="p">(</span>
    <span class="n">layer_name</span><span class="o">=</span><span class="s2">&quot;layers.1&quot;</span><span class="p">,</span>
    <span class="n">input_dim</span><span class="o">=</span><span class="n">num_hidden</span><span class="p">,</span>
    <span class="n">output_dim</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span>
    <span class="n">adj</span><span class="o">=</span><span class="n">adj</span><span class="p">,</span>
    <span class="nb">input</span><span class="o">=</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
    <span class="n">norm</span><span class="o">=</span><span class="n">norm</span><span class="p">,</span>
    <span class="n">activation</span><span class="o">=</span><span class="kc">None</span>
<span class="p">))</span>

<span class="c1"># Analyze free variables and generate Relay function</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="section" id="compile-and-run-with-tvm">
<h2>Compile and run with TVM<a class="headerlink" href="#compile-and-run-with-tvm" title="Permalink to this headline">¶</a></h2>
<p>Export the weigths from PyTorch model to Python Dict</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="n">model_params</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">param_tensor</span> <span class="ow">in</span> <span class="n">torch_model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">():</span>
    <span class="n">model_params</span><span class="p">[</span><span class="n">param_tensor</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch_model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()[</span><span class="n">param_tensor</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">params</span><span class="p">[</span><span class="s2">&quot;layers.</span><span class="si">%d</span><span class="s2">.weight&quot;</span><span class="o">%</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="n">model_params</span><span class="p">[</span><span class="s2">&quot;layers.</span><span class="si">%d</span><span class="s2">.weight&quot;</span><span class="o">%</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span>
    <span class="n">params</span><span class="p">[</span><span class="s2">&quot;layers.</span><span class="si">%d</span><span class="s2">.bias&quot;</span><span class="o">%</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span> <span class="o">=</span> <span class="n">model_params</span><span class="p">[</span><span class="s2">&quot;layers.</span><span class="si">%d</span><span class="s2">.bias&quot;</span><span class="o">%</span><span class="p">(</span><span class="n">i</span><span class="p">)]</span>

<span class="c1"># Set the TVM build target</span>
<span class="n">target</span> <span class="o">=</span> <span class="s1">&#39;llvm&#39;</span> <span class="c1"># Currently only support `llvm` as target</span>

<span class="n">func</span> <span class="o">=</span> <a href="../../api/python/relay/index.html#tvm.relay.Function" title="View documentation for tvm.relay.Function"><span class="n">relay</span><span class="o">.</span><span class="n">Function</span></a><span class="p">(</span><a href="../../api/python/relay/analysis.html#tvm.relay.analysis.free_vars" title="View documentation for tvm.relay.analysis.free_vars"><span class="n">relay</span><span class="o">.</span><span class="n">analysis</span><span class="o">.</span><span class="n">free_vars</span></a><span class="p">(</span><span class="n">output</span><span class="p">),</span> <span class="n">output</span><span class="p">)</span>
<span class="n">func</span> <span class="o">=</span> <span class="n">relay</span><span class="o">.</span><span class="n">build_module</span><span class="o">.</span><span class="n">bind_params_by_name</span><span class="p">(</span><span class="n">func</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
<span class="n">mod</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">IRModule</span><span class="p">()</span>
<span class="n">mod</span><span class="p">[</span><span class="s2">&quot;main&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">func</span>
<span class="c1"># Build with Relay</span>
<span class="k">with</span> <a href="../../api/python/relay/index.html#tvm.relay.build_config" title="View documentation for tvm.relay.build_config"><span class="n">relay</span><span class="o">.</span><span class="n">build_config</span></a><span class="p">(</span><span class="n">opt_level</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span> <span class="c1"># Currently only support opt_level=0</span>
    <span class="n">graph</span><span class="p">,</span> <span class="n">lib</span><span class="p">,</span> <span class="n">params</span> <span class="o">=</span> <a href="../../api/python/relay/index.html#tvm.relay.build" title="View documentation for tvm.relay.build"><span class="n">relay</span><span class="o">.</span><span class="n">build</span></a><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">params</span><span class="o">=</span><span class="n">params</span><span class="p">)</span>

<span class="c1"># Generate graph runtime</span>
<span class="n">ctx</span> <span class="o">=</span> <span class="n">tvm</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">m</span> <span class="o">=</span> <a href="../../api/python/graph_runtime.html#tvm.contrib.graph_runtime.create" title="View documentation for tvm.contrib.graph_runtime.create"><span class="n">graph_runtime</span><span class="o">.</span><span class="n">create</span></a><span class="p">(</span><span class="n">graph</span><span class="p">,</span> <span class="n">lib</span><span class="p">,</span> <span class="n">ctx</span><span class="p">)</span>
<span class="n">m</span><span class="o">.</span><span class="n">set_input</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="run-the-tvm-model-test-for-accuracy-and-verify-with-dgl">
<h2>Run the TVM model, test for accuracy and verify with DGL<a class="headerlink" href="#run-the-tvm-model-test-for-accuracy-and-verify-with-dgl" title="Permalink to this headline">¶</a></h2>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="n">m</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
<span class="n">logits_tvm</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">get_output</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Print the first five outputs from TVM execution</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">logits_tvm</span><span class="p">[:</span><span class="mi">5</span><span class="p">])</span>

<span class="n">labels</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">labels</span>
<span class="n">test_mask</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">test_mask</span>

<span class="n">acc</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">logits_tvm</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test accuracy of TVM results: {:.2%}&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">acc</span><span class="p">))</span>

<span class="c1"># Verify the results with the DGL model</span>
<span class="n">tvm</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_allclose</span><span class="p">(</span><span class="n">logits_torch</span><span class="p">,</span> <span class="n">logits_tvm</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mi">1</span><span class="n">e</span><span class="o">-</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre>Print the first five outputs from TVM execution
 [[-2.1450336  -1.341066    3.600258    0.11899108 -0.96899545 -1.4137654
  -1.0221214 ]
 [ 0.60626334 -1.182223   -0.36925027 -0.94760215  0.581874    1.2294779
   0.27382204]
 [-1.0875838   0.05650991 -0.2626103  -0.93124706  2.7452836  -0.09504303
  -0.6076888 ]
 [-1.4723883   0.01050094 -0.10382691 -0.21350211  2.27953    -0.52083516
  -0.5848303 ]
 [-1.6527934  -1.2278551   0.05413637  3.6321862  -1.6748215  -1.6924572
   0.176308  ]]
Test accuracy of TVM results: 81.40%
</pre></div>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  4.613 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-tutorials-frontend-build-gcn-py">
<div class="sphx-glr-download docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/70d345c5409f99cb5de9dc44f147ff6f/build_gcn.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">build_gcn.py</span></code></a></p>
</div>
<div class="sphx-glr-download docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/c316f4b828b813e437473ee752bacdf9/build_gcn.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">build_gcn.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../language/tedd.html" class="btn btn-neutral float-right" title="Use Tensor Expression Debug Display (TEDD) for Visualization" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="from_darknet.html" class="btn btn-neutral float-left" title="Compile YOLO-V2 and YOLO-V3 in DarkNet Models" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, Apache Software Foundation

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-75982049-2', 'auto');
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>