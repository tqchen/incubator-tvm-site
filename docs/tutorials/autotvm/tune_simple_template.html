

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Writing tunable template and Using auto-tuner &mdash; tvm 0.7.dev1 documentation</title>
  

  
  
    <link rel="shortcut icon" href="../../_static/tvm-logo-square.png"/>
  
  
  

  
  <script type="text/javascript" src="../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/tvm_theme.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Tuning High Performance Convolution on NVIDIA GPUs" href="tune_conv2d_cuda.html" />
    <link rel="prev" title="How to optimize matmul with Auto TensorCore CodeGen" href="../optimize/opt_matmul_auto_tensorcore.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html">
          

          
            
            <img src="../../_static/tvm-logo-small.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.7.dev1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../install/index.html">Installation</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">Tutorials</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../relay_quick_start.html">Quick Start Tutorial for Compiling Deep Learning Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cross_compilation_and_rpc.html">Cross Compilation and RPC</a></li>
<li class="toctree-l2"><a class="reference internal" href="../tensor_expr_get_started.html">Get Started with Tensor Expression</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#compile-deep-learning-models">Compile Deep Learning Models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#tensor-expression-and-schedules">Tensor Expression and Schedules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#optimize-tensor-operators">Optimize Tensor Operators</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../index.html#auto-tuning">Auto tuning</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">Writing tunable template and Using auto-tuner</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#install-dependencies">Install dependencies</a></li>
<li class="toctree-l4"><a class="reference internal" href="#step-1-define-the-search-space">Step 1:  Define the search space</a></li>
<li class="toctree-l4"><a class="reference internal" href="#step-2-search-through-the-space">Step 2:  Search through the space</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="tune_conv2d_cuda.html">Tuning High Performance Convolution on NVIDIA GPUs</a></li>
<li class="toctree-l3"><a class="reference internal" href="tune_relay_x86.html">Auto-tuning a convolutional network for x86 CPU</a></li>
<li class="toctree-l3"><a class="reference internal" href="tune_relay_cuda.html">Auto-tuning a convolutional network for NVIDIA GPU</a></li>
<li class="toctree-l3"><a class="reference internal" href="tune_relay_arm.html">Auto-tuning a convolutional network for ARM CPU</a></li>
<li class="toctree-l3"><a class="reference internal" href="tune_relay_mobile_gpu.html">Auto-tuning a convolutional network for Mobile GPU</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#developer-tutorials">Developer Tutorials</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#topi-tvm-operator-inventory">TOPI: TVM Operator Inventory</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../vta/index.html">VTA: Deep Learning Accelerator Stack</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../deploy/index.html">Deploy and Integration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../contribute/index.html">Contribute to TVM</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../faq.html">Frequently Asked Questions</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../langref/index.html">Language Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api/python/index.html">Python API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../api_links.html">Links to API References</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../dev/index.html">Design and Developer Guide</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../frontend/tensorflow.html">TensorFlow Frontend</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../genindex.html">Index</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">tvm</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../index.html">Tutorials</a> &raquo;</li>
        
      <li>Writing tunable template and Using auto-tuner</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/tutorials/autotvm/tune_simple_template.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-tutorials-autotvm-tune-simple-template-py"><span class="std std-ref">here</span></a> to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="writing-tunable-template-and-using-auto-tuner">
<span id="sphx-glr-tutorials-autotvm-tune-simple-template-py"></span><h1>Writing tunable template and Using auto-tuner<a class="headerlink" href="#writing-tunable-template-and-using-auto-tuner" title="Permalink to this headline">¶</a></h1>
<p><strong>Author</strong>: <a class="reference external" href="https://github.com/merrymercy">Lianmin Zheng</a></p>
<p>This is an introduction tutorial to the auto-tuning module in TVM.</p>
<p>There are two steps in auto-tuning.
The first step is defining a search space.
The second step is running a search algorithm to explore through this space.
In this tutorial, you can learn how to perform these two steps in TVM.
The whole workflow is illustrated by a matrix multiplication example.</p>
<div class="section" id="install-dependencies">
<h2>Install dependencies<a class="headerlink" href="#install-dependencies" title="Permalink to this headline">¶</a></h2>
<p>To use autotvm package in TVM, we need to install some extra dependencies.
This step (installing xgboost) can be skipped as it doesn’t need XGBoost
(change “3” to “2” if you use python2):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre>pip3 install --user psutil xgboost
</pre></div>
</div>
<p>To make TVM run faster in tuning, it is recommended to use cython
as FFI of TVM. In the root directory of TVM, execute
(change “3” to “2” if you use python2):</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre>pip3 install --user cython
sudo make cython3
</pre></div>
</div>
<p>Now return to python code. Import packages.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">import</span> <span class="nn">sys</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tvm</span>
<span class="kn">from</span> <span class="nn">tvm</span> <span class="k">import</span> <span class="n">te</span>

<span class="c1"># the module is called `autotvm`</span>
<span class="kn">from</span> <span class="nn">tvm</span> <span class="k">import</span> <span class="n">autotvm</span>
</pre></div>
</div>
</div>
<div class="section" id="step-1-define-the-search-space">
<h2>Step 1:  Define the search space<a class="headerlink" href="#step-1-define-the-search-space" title="Permalink to this headline">¶</a></h2>
<p>In this section, we will rewrite a deterministic TVM schedule code to a
tunable schedule template. You can regard the process of search space definition
as the parameterization of our existing schedule code.</p>
<p>To begin with, here is how we implement a blocked matrix multiplication in TVM.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="c1"># Matmul V0: Constant tiling factor</span>
<span class="k">def</span> <span class="nf">matmul_v0</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">dtype</span><span class="p">):</span>
    <span class="n">A</span> <span class="o">=</span> <a href="../../api/python/te.html#tvm.te.placeholder" title="View documentation for tvm.te.placeholder"><span class="n">te</span><span class="o">.</span><span class="n">placeholder</span></a><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">L</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">B</span> <span class="o">=</span> <a href="../../api/python/te.html#tvm.te.placeholder" title="View documentation for tvm.te.placeholder"><span class="n">te</span><span class="o">.</span><span class="n">placeholder</span></a><span class="p">((</span><span class="n">L</span><span class="p">,</span> <span class="n">M</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>

    <span class="n">k</span> <span class="o">=</span> <a href="../../api/python/te.html#tvm.te.reduce_axis" title="View documentation for tvm.te.reduce_axis"><span class="n">te</span><span class="o">.</span><span class="n">reduce_axis</span></a><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="n">L</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
    <span class="n">C</span> <span class="o">=</span> <a href="../../api/python/te.html#tvm.te.compute" title="View documentation for tvm.te.compute"><span class="n">te</span><span class="o">.</span><span class="n">compute</span></a><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">),</span> <span class="k">lambda</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">:</span> <a href="../../api/python/te.html#tvm.te.sum" title="View documentation for tvm.te.sum"><span class="n">te</span><span class="o">.</span><span class="n">sum</span></a><span class="p">(</span><span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">B</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">j</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="n">k</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;C&#39;</span><span class="p">)</span>
    <span class="n">s</span> <span class="o">=</span> <a href="../../api/python/te.html#tvm.te.create_schedule" title="View documentation for tvm.te.create_schedule"><span class="n">te</span><span class="o">.</span><span class="n">create_schedule</span></a><span class="p">(</span><span class="n">C</span><span class="o">.</span><span class="n">op</span><span class="p">)</span>

    <span class="c1"># schedule</span>
    <span class="n">y</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="n">s</span><span class="p">[</span><span class="n">C</span><span class="p">]</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">axis</span>
    <span class="n">k</span> <span class="o">=</span> <span class="n">s</span><span class="p">[</span><span class="n">C</span><span class="p">]</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">reduce_axis</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">yo</span><span class="p">,</span> <span class="n">yi</span> <span class="o">=</span> <span class="n">s</span><span class="p">[</span><span class="n">C</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
    <span class="n">xo</span><span class="p">,</span> <span class="n">xi</span> <span class="o">=</span> <span class="n">s</span><span class="p">[</span><span class="n">C</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>

    <span class="n">s</span><span class="p">[</span><span class="n">C</span><span class="p">]</span><span class="o">.</span><span class="n">reorder</span><span class="p">(</span><span class="n">yo</span><span class="p">,</span> <span class="n">xo</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">yi</span><span class="p">,</span> <span class="n">xi</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">s</span><span class="p">,</span> <span class="p">[</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">C</span><span class="p">]</span>
</pre></div>
</div>
<div class="section" id="parametrize-the-schedule">
<h3>Parametrize the schedule<a class="headerlink" href="#parametrize-the-schedule" title="Permalink to this headline">¶</a></h3>
<p>In the previous schedule code, we use a constant “8” as tiling factor.
However, it might not be the best one because the best tiling factor depends
on real hardware environment and input shape.</p>
<p>If you want the schedule code to be portable across a wider range of input shapes
and target hardware, it is better to define a set of candidate values and
pick the best one according to the measurement results on target hardware.</p>
<p>In autotvm, we can define a tunable parameter, or a “knob” for such kind of value.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="c1"># Matmul V1: List candidate values</span>
<span class="nd">@autotvm</span><span class="o">.</span><span class="n">template</span><span class="p">(</span><span class="s2">&quot;tutorial/matmul_v1&quot;</span><span class="p">)</span>  <span class="c1"># 1. use a decorator</span>
<span class="k">def</span> <span class="nf">matmul_v1</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">dtype</span><span class="p">):</span>
    <span class="n">A</span> <span class="o">=</span> <a href="../../api/python/te.html#tvm.te.placeholder" title="View documentation for tvm.te.placeholder"><span class="n">te</span><span class="o">.</span><span class="n">placeholder</span></a><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">L</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">B</span> <span class="o">=</span> <a href="../../api/python/te.html#tvm.te.placeholder" title="View documentation for tvm.te.placeholder"><span class="n">te</span><span class="o">.</span><span class="n">placeholder</span></a><span class="p">((</span><span class="n">L</span><span class="p">,</span> <span class="n">M</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>

    <span class="n">k</span> <span class="o">=</span> <a href="../../api/python/te.html#tvm.te.reduce_axis" title="View documentation for tvm.te.reduce_axis"><span class="n">te</span><span class="o">.</span><span class="n">reduce_axis</span></a><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="n">L</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
    <span class="n">C</span> <span class="o">=</span> <a href="../../api/python/te.html#tvm.te.compute" title="View documentation for tvm.te.compute"><span class="n">te</span><span class="o">.</span><span class="n">compute</span></a><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">),</span> <span class="k">lambda</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">:</span> <a href="../../api/python/te.html#tvm.te.sum" title="View documentation for tvm.te.sum"><span class="n">te</span><span class="o">.</span><span class="n">sum</span></a><span class="p">(</span><span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">B</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">j</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="n">k</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;C&#39;</span><span class="p">)</span>
    <span class="n">s</span> <span class="o">=</span> <a href="../../api/python/te.html#tvm.te.create_schedule" title="View documentation for tvm.te.create_schedule"><span class="n">te</span><span class="o">.</span><span class="n">create_schedule</span></a><span class="p">(</span><span class="n">C</span><span class="o">.</span><span class="n">op</span><span class="p">)</span>

    <span class="c1"># schedule</span>
    <span class="n">y</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="n">s</span><span class="p">[</span><span class="n">C</span><span class="p">]</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">axis</span>
    <span class="n">k</span> <span class="o">=</span> <span class="n">s</span><span class="p">[</span><span class="n">C</span><span class="p">]</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">reduce_axis</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># 2. get the config object</span>
    <span class="n">cfg</span> <span class="o">=</span> <span class="n">autotvm</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>

    <span class="c1"># 3. define search space</span>
    <span class="n">cfg</span><span class="o">.</span><span class="n">define_knob</span><span class="p">(</span><span class="s2">&quot;tile_y&quot;</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">])</span>
    <span class="n">cfg</span><span class="o">.</span><span class="n">define_knob</span><span class="p">(</span><span class="s2">&quot;tile_x&quot;</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">])</span>

    <span class="c1"># 4. schedule according to config</span>
    <span class="n">yo</span><span class="p">,</span> <span class="n">yi</span> <span class="o">=</span> <span class="n">s</span><span class="p">[</span><span class="n">C</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">cfg</span><span class="p">[</span><span class="s1">&#39;tile_y&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">val</span><span class="p">)</span>
    <span class="n">xo</span><span class="p">,</span> <span class="n">xi</span> <span class="o">=</span> <span class="n">s</span><span class="p">[</span><span class="n">C</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">cfg</span><span class="p">[</span><span class="s1">&#39;tile_x&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">val</span><span class="p">)</span>

    <span class="n">s</span><span class="p">[</span><span class="n">C</span><span class="p">]</span><span class="o">.</span><span class="n">reorder</span><span class="p">(</span><span class="n">yo</span><span class="p">,</span> <span class="n">xo</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">yi</span><span class="p">,</span> <span class="n">xi</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">s</span><span class="p">,</span> <span class="p">[</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">C</span><span class="p">]</span>
</pre></div>
</div>
<p>Here we make four modifications to the previous schedule code and get
a tunable “template”. We can explain the modifications one by one.</p>
<ol class="arabic">
<li><p>Use a decorator to mark this function as a simple template.</p></li>
<li><p>Get a config object:
You can regard this <code class="code docutils literal notranslate"><span class="pre">cfg</span></code> as an argument of this function but
we obtain it in a different way. With this argument, this function is no longer
a deterministic schedule code. Instead, we can pass different configurations to
this function and get different schedules, so this function is a “template”.</p>
<p>To make the template function more compact, we do two things in a single function.
(1) define a search space and (2) schedule according to an entity in this space.
To achieve this, we make <code class="code docutils literal notranslate"><span class="pre">cfg</span></code> be either
a <a class="reference internal" href="../../api/python/autotvm.html#tvm.autotvm.task.space.ConfigSpace" title="tvm.autotvm.task.space.ConfigSpace"><code class="xref any py py-class docutils literal notranslate"><span class="pre">ConfigSpace</span></code></a> or a <a class="reference internal" href="../../api/python/autotvm.html#tvm.autotvm.task.space.ConfigEntity" title="tvm.autotvm.task.space.ConfigEntity"><code class="xref any py py-class docutils literal notranslate"><span class="pre">ConfigEntity</span></code></a> object.</p>
<p>When it is a <a class="reference internal" href="../../api/python/autotvm.html#tvm.autotvm.task.space.ConfigSpace" title="tvm.autotvm.task.space.ConfigSpace"><code class="xref any py py-class docutils literal notranslate"><span class="pre">ConfigSpace</span></code></a>, it will collect all tunable knobs in this function and
build the search space.
When it is a <a class="reference internal" href="../../api/python/autotvm.html#tvm.autotvm.task.space.ConfigEntity" title="tvm.autotvm.task.space.ConfigEntity"><code class="xref any py py-class docutils literal notranslate"><span class="pre">ConfigEntity</span></code></a>, it will ignore all space definition API
(namely, <code class="code docutils literal notranslate"><span class="pre">cfg.define_XXXXX(...)</span></code>).   Instead, it stores deterministic values for
all tunable knobs, and we schedule according to these values.</p>
<p>During auto-tuning, we will first call this template with a <a class="reference internal" href="../../api/python/autotvm.html#tvm.autotvm.task.space.ConfigSpace" title="tvm.autotvm.task.space.ConfigSpace"><code class="xref any py py-class docutils literal notranslate"><span class="pre">ConfigSpace</span></code></a>
object to build the search space. Then we call this template with different <a class="reference internal" href="../../api/python/autotvm.html#tvm.autotvm.task.space.ConfigEntity" title="tvm.autotvm.task.space.ConfigEntity"><code class="xref any py py-class docutils literal notranslate"><span class="pre">ConfigEntity</span></code></a>
in the built space to get different schedules. Finally we will measure the code generated by
different schedules and pick the best one.</p>
</li>
<li><p>Define two tunable knobs. The first one is <code class="code docutils literal notranslate"><span class="pre">tile_y</span></code> with
5 possible values. The second one is <code class="code docutils literal notranslate"><span class="pre">tile_x</span></code> with a same
list of possible values. These two knobs are independent, so they
span a search space with size = 5x5 = 25</p></li>
<li><p>Schedule according to the deterministic values in <code class="code docutils literal notranslate"><span class="pre">cfg</span></code></p></li>
</ol>
</div>
<div class="section" id="use-better-space-definition-api">
<h3>Use better space definition API<a class="headerlink" href="#use-better-space-definition-api" title="Permalink to this headline">¶</a></h3>
<p>In the previous template, we manually list all possible values for a knob.
This is the lowest level API to define the space.
However, we also provide another set of API to make the space definition
easier and smarter. It is recommended to use this set of high level API.</p>
<p>In the following example, we use <a class="reference internal" href="../../api/python/autotvm.html#tvm.autotvm.task.space.ConfigSpace.define_split" title="tvm.autotvm.task.space.ConfigSpace.define_split"><code class="xref any py py-meth docutils literal notranslate"><span class="pre">ConfigSpace.define_split</span></code></a> to define a split
knob. It will enumerate all the possible ways to split an axis and construct
the space.</p>
<p>We also have <a class="reference internal" href="../../api/python/autotvm.html#tvm.autotvm.task.space.ConfigSpace.define_reorder" title="tvm.autotvm.task.space.ConfigSpace.define_reorder"><code class="xref any py py-meth docutils literal notranslate"><span class="pre">ConfigSpace.define_reorder</span></code></a> for reorder knob and
<a class="reference internal" href="../../api/python/autotvm.html#tvm.autotvm.task.space.ConfigSpace.define_annotate" title="tvm.autotvm.task.space.ConfigSpace.define_annotate"><code class="xref any py py-meth docutils literal notranslate"><span class="pre">ConfigSpace.define_annotate</span></code></a> for annotation like unroll, vectorization,
thread binding.
When the high level API cannot meet your requirement, you can always fall
back to use low level API.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="nd">@autotvm</span><span class="o">.</span><span class="n">template</span><span class="p">(</span><span class="s2">&quot;tutorial/matmul&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">matmul</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">dtype</span><span class="p">):</span>
    <span class="n">A</span> <span class="o">=</span> <a href="../../api/python/te.html#tvm.te.placeholder" title="View documentation for tvm.te.placeholder"><span class="n">te</span><span class="o">.</span><span class="n">placeholder</span></a><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">L</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;A&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">B</span> <span class="o">=</span> <a href="../../api/python/te.html#tvm.te.placeholder" title="View documentation for tvm.te.placeholder"><span class="n">te</span><span class="o">.</span><span class="n">placeholder</span></a><span class="p">((</span><span class="n">L</span><span class="p">,</span> <span class="n">M</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;B&#39;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>

    <span class="n">k</span> <span class="o">=</span> <a href="../../api/python/te.html#tvm.te.reduce_axis" title="View documentation for tvm.te.reduce_axis"><span class="n">te</span><span class="o">.</span><span class="n">reduce_axis</span></a><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="n">L</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
    <span class="n">C</span> <span class="o">=</span> <a href="../../api/python/te.html#tvm.te.compute" title="View documentation for tvm.te.compute"><span class="n">te</span><span class="o">.</span><span class="n">compute</span></a><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="n">M</span><span class="p">),</span> <span class="k">lambda</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">:</span> <a href="../../api/python/te.html#tvm.te.sum" title="View documentation for tvm.te.sum"><span class="n">te</span><span class="o">.</span><span class="n">sum</span></a><span class="p">(</span><span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">B</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">j</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="n">k</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;C&#39;</span><span class="p">)</span>
    <span class="n">s</span> <span class="o">=</span> <a href="../../api/python/te.html#tvm.te.create_schedule" title="View documentation for tvm.te.create_schedule"><span class="n">te</span><span class="o">.</span><span class="n">create_schedule</span></a><span class="p">(</span><span class="n">C</span><span class="o">.</span><span class="n">op</span><span class="p">)</span>

    <span class="c1"># schedule</span>
    <span class="n">y</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="n">s</span><span class="p">[</span><span class="n">C</span><span class="p">]</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">axis</span>
    <span class="n">k</span> <span class="o">=</span> <span class="n">s</span><span class="p">[</span><span class="n">C</span><span class="p">]</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">reduce_axis</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1">##### define space begin #####</span>
    <span class="n">cfg</span> <span class="o">=</span> <span class="n">autotvm</span><span class="o">.</span><span class="n">get_config</span><span class="p">()</span>
    <span class="n">cfg</span><span class="o">.</span><span class="n">define_split</span><span class="p">(</span><span class="s2">&quot;tile_y&quot;</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">num_outputs</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">cfg</span><span class="o">.</span><span class="n">define_split</span><span class="p">(</span><span class="s2">&quot;tile_x&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">num_outputs</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="c1">##### define space end #####</span>

    <span class="c1"># schedule according to config</span>
    <span class="n">yo</span><span class="p">,</span> <span class="n">yi</span> <span class="o">=</span> <span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;tile_y&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">xo</span><span class="p">,</span> <span class="n">xi</span> <span class="o">=</span> <span class="n">cfg</span><span class="p">[</span><span class="s2">&quot;tile_x&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

    <span class="n">s</span><span class="p">[</span><span class="n">C</span><span class="p">]</span><span class="o">.</span><span class="n">reorder</span><span class="p">(</span><span class="n">yo</span><span class="p">,</span> <span class="n">xo</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">yi</span><span class="p">,</span> <span class="n">xi</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">s</span><span class="p">,</span> <span class="p">[</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">C</span><span class="p">]</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>More Explanation on <code class="code docutils literal notranslate"><span class="pre">cfg.defile_split</span></code></p>
<p>In this template, <code class="code docutils literal notranslate"><span class="pre">cfg.define_split(&quot;tile_y&quot;,</span> <span class="pre">y,</span> <span class="pre">num_outputs=2)</span></code> will enumerate
all possible combinations that can split axis y into two axes with factors of the length of y.
For example, if the length of y is 32 and we want to split it into two axes
using factors of 32, then there are 6 possible values for
(length of outer axis, length of inner axis) pair, namely
(32, 1), (16, 2), (8, 4), (4, 8), (2, 16) or (1, 32).
They are just the 6 possible values of <cite>tile_y</cite>.</p>
<p>During schedule, <code class="code docutils literal notranslate"><span class="pre">cfg[&quot;tile_y&quot;]</span></code> is a <code class="code docutils literal notranslate"><span class="pre">SplitEntity</span></code> object.
We stores the lengths of outer axes and inner axes in <code class="code docutils literal notranslate"><span class="pre">cfg['tile_y'].size</span></code>
(a tuple with two elements).
In this template, we apply it by using <code class="code docutils literal notranslate"><span class="pre">yo,</span> <span class="pre">yi</span> <span class="pre">=</span> <span class="pre">cfg['tile_y'].apply(s,</span> <span class="pre">C,</span> <span class="pre">y)</span></code>.
Actually, this is equivalent to
<code class="code docutils literal notranslate"><span class="pre">yo,</span> <span class="pre">yi</span> <span class="pre">=</span> <span class="pre">s[C].split(y,</span> <span class="pre">cfg[&quot;tile_y&quot;].size[1])</span></code>
or  <code class="code docutils literal notranslate"><span class="pre">yo,</span> <span class="pre">yi</span> <span class="pre">=</span> <span class="pre">s[C].split(y,</span> <span class="pre">nparts=cfg['tile_y&quot;].size[0])</span></code></p>
<p>The advantage of using cfg.apply API is that it makes multi-level split
(when num_outputs &gt;= 3) easier.</p>
</div>
</div>
</div>
<div class="section" id="step-2-search-through-the-space">
<h2>Step 2:  Search through the space<a class="headerlink" href="#step-2-search-through-the-space" title="Permalink to this headline">¶</a></h2>
<p>In step 1, we build the search space by extending our old schedule code
into a template. The next step is to pick a tuner and explore in this space.</p>
<div class="section" id="auto-tuners-in-tvm">
<h3>Auto-tuners in TVM<a class="headerlink" href="#auto-tuners-in-tvm" title="Permalink to this headline">¶</a></h3>
<p>The job for a tuner can be described by following pseudo code</p>
<blockquote>
<div><div class="highlight-c notranslate"><div class="highlight"><pre><span class="n">ct</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">while</span> <span class="n">ct</span> <span class="o">&lt;</span> <span class="nl">max_number_of_trials</span><span class="p">:</span>
    <span class="n">propose</span> <span class="n">a</span> <span class="n">batch</span> <span class="n">of</span> <span class="n">configs</span>
    <span class="n">measure</span> <span class="n">this</span> <span class="n">batch</span> <span class="n">of</span> <span class="n">configs</span> <span class="n">on</span> <span class="n">real</span> <span class="n">hardware</span> <span class="n">and</span> <span class="n">get</span> <span class="n">results</span>
    <span class="n">ct</span> <span class="o">+=</span> <span class="n">batch_size</span>
</pre></div>
</div>
</div></blockquote>
<p>When proposing the next batch of configs, the tuner can take different strategies. We
provide four tuners with different strategies in autotvm.</p>
<ul class="simple">
<li><p><a class="reference internal" href="../../api/python/autotvm.html#tvm.autotvm.tuner.RandomTuner" title="tvm.autotvm.tuner.RandomTuner"><code class="xref any py py-class docutils literal notranslate"><span class="pre">RandomTuner</span></code></a>: Enumerate the space in a random order</p></li>
<li><p><a class="reference internal" href="../../api/python/autotvm.html#tvm.autotvm.tuner.GridSearchTuner" title="tvm.autotvm.tuner.GridSearchTuner"><code class="xref any py py-class docutils literal notranslate"><span class="pre">GridSearchTuner</span></code></a>: Enumerate the space in a grid search order</p></li>
<li><p><a class="reference internal" href="../../api/python/autotvm.html#tvm.autotvm.tuner.GATuner" title="tvm.autotvm.tuner.GATuner"><code class="xref any py py-class docutils literal notranslate"><span class="pre">GATuner</span></code></a>: Using genetic algorithm to search through the space</p></li>
<li><p><a class="reference internal" href="../../api/python/autotvm.html#tvm.autotvm.tuner.XGBTuner" title="tvm.autotvm.tuner.XGBTuner"><code class="xref any py py-class docutils literal notranslate"><span class="pre">XGBTuner</span></code></a>: Uses a model based method. Train a XGBoost model to predict the speed of lowered IR and pick the next batch according to the prediction.</p></li>
</ul>
<p>You can choose the tuner according to the size of your space, your time budget and other factors.
For example, if your space is very small (less than 1000), a gridsearch tuner or a
random tuner is good enough. If your space is at the level of 10^9 (this is the space
size of a conv2d operator on CUDA GPU), XGBoostTuner can explore more efficiently
and find better configs.</p>
</div>
<div class="section" id="begin-tuning">
<h3>Begin tuning<a class="headerlink" href="#begin-tuning" title="Permalink to this headline">¶</a></h3>
<p>Here we continue our matrix multiplication example.
First we should create a tuning task.
We can also inspect the initialized search space.
In this case, for a 512x512 square matrix multiplication, the space size
is 10x10=100</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="n">N</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="n">M</span> <span class="o">=</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">512</span>
<span class="n">task</span> <span class="o">=</span> <span class="n">autotvm</span><span class="o">.</span><span class="n">task</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="s2">&quot;tutorial/matmul&quot;</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="s1">&#39;float32&#39;</span><span class="p">),</span> <span class="n">target</span><span class="o">=</span><span class="s1">&#39;llvm&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">task</span><span class="o">.</span><span class="n">config_space</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre>ConfigSpace (len=100, space_map=
   0 tile_y: Split(policy=factors, product=512, num_outputs=2) len=10
   1 tile_x: Split(policy=factors, product=512, num_outputs=2) len=10
)
</pre></div>
</div>
<p>Then we need to define how to measure the generated code and pick a tuner.
Since our space is small, a random tuner is just okay.</p>
<p>We only make 10 trials in this tutorial for demonstration. In practice,
you can do more trials according to your time budget.
We will log the tuning results into a log file. This file can be
used to get the best config later.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="c1"># logging config (for printing tuning log to the screen)</span>
<span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="s1">&#39;autotvm&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">setLevel</span><span class="p">(</span><span class="n">logging</span><span class="o">.</span><span class="n">DEBUG</span><span class="p">)</span>
<span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="s1">&#39;autotvm&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">addHandler</span><span class="p">(</span><span class="n">logging</span><span class="o">.</span><span class="n">StreamHandler</span><span class="p">(</span><span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="p">))</span>

<span class="c1"># There are two steps for measuring a config: build and run.</span>
<span class="c1"># By default, we use all CPU cores to compile program. Then measure them sequentially.</span>
<span class="c1"># We measure 5 times and take average to reduce variance.</span>
<span class="n">measure_option</span> <span class="o">=</span> <span class="n">autotvm</span><span class="o">.</span><span class="n">measure_option</span><span class="p">(</span>
    <span class="n">builder</span><span class="o">=</span><span class="s1">&#39;local&#39;</span><span class="p">,</span>
    <span class="n">runner</span><span class="o">=</span><span class="n">autotvm</span><span class="o">.</span><span class="n">LocalRunner</span><span class="p">(</span><span class="n">number</span><span class="o">=</span><span class="mi">5</span><span class="p">))</span>

<span class="c1"># Begin tuning with RandomTuner, log records to file `matmul.log`</span>
<span class="c1"># You can use alternatives like XGBTuner.</span>
<span class="n">tuner</span> <span class="o">=</span> <a href="../../api/python/autotvm.html#tvm.autotvm.tuner.RandomTuner" title="View documentation for tvm.autotvm.tuner.RandomTuner"><span class="n">autotvm</span><span class="o">.</span><span class="n">tuner</span><span class="o">.</span><span class="n">RandomTuner</span></a><span class="p">(</span><span class="n">task</span><span class="p">)</span>
<span class="n">tuner</span><span class="o">.</span><span class="n">tune</span><span class="p">(</span><span class="n">n_trial</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
           <span class="n">measure_option</span><span class="o">=</span><span class="n">measure_option</span><span class="p">,</span>
           <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">autotvm</span><span class="o">.</span><span class="n">callback</span><span class="o">.</span><span class="n">log_to_file</span><span class="p">(</span><span class="s1">&#39;matmul.log&#39;</span><span class="p">)])</span>
</pre></div>
</div>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre>Get devices for measurement successfully!
No: 1   GFLOPS: 6.96/6.96       result: MeasureResult(costs=(0.0385728382,), error_no=0, all_cost=0.823296308517456, timestamp=1585556397.3558123)      [(&#39;tile_y&#39;, [-1, 8]), (&#39;tile_x&#39;, [-1, 8])],None,33
No: 2   GFLOPS: 2.25/6.96       result: MeasureResult(costs=(0.1192342126,), error_no=0, all_cost=2.1185624599456787, timestamp=1585556399.5840642)     [(&#39;tile_y&#39;, [-1, 8]), (&#39;tile_x&#39;, [-1, 2])],None,13
No: 3   GFLOPS: 7.27/7.27       result: MeasureResult(costs=(0.0369096948,), error_no=0, all_cost=1.1788554191589355, timestamp=1585556400.4997094)     [(&#39;tile_y&#39;, [-1, 16]), (&#39;tile_x&#39;, [-1, 128])],None,74
No: 4   GFLOPS: 4.35/7.27       result: MeasureResult(costs=(0.061714442800000005,), error_no=0, all_cost=1.3026938438415527, timestamp=1585556401.8039923)     [(&#39;tile_y&#39;, [-1, 16]), (&#39;tile_x&#39;, [-1, 32])],None,54
No: 5   GFLOPS: 6.01/7.27       result: MeasureResult(costs=(0.0446915612,), error_no=0, all_cost=0.986182689666748, timestamp=1585556402.8620286)      [(&#39;tile_y&#39;, [-1, 128]), (&#39;tile_x&#39;, [-1, 8])],None,37
No: 6   GFLOPS: 6.50/7.27       result: MeasureResult(costs=(0.0412838544,), error_no=0, all_cost=1.0038743019104004, timestamp=1585556403.8686693)     [(&#39;tile_y&#39;, [-1, 64]), (&#39;tile_x&#39;, [-1, 8])],None,36
No: 7   GFLOPS: 22.93/22.93     result: MeasureResult(costs=(0.0117043134,), error_no=0, all_cost=0.5391783714294434, timestamp=1585556404.3909621)     [(&#39;tile_y&#39;, [-1, 1]), (&#39;tile_x&#39;, [-1, 128])],None,70
No: 8   GFLOPS: 20.32/22.93     result: MeasureResult(costs=(0.0132121842,), error_no=0, all_cost=0.4541635513305664, timestamp=1585556404.9171762)     [(&#39;tile_y&#39;, [-1, 4]), (&#39;tile_x&#39;, [-1, 512])],None,92
No: 9   GFLOPS: 0.80/22.93      result: MeasureResult(costs=(0.3345709118,), error_no=0, all_cost=5.640729188919067, timestamp=1585556410.6114697)      [(&#39;tile_y&#39;, [-1, 512]), (&#39;tile_x&#39;, [-1, 2])],None,19
No: 10  GFLOPS: 0.00/22.93      result: MeasureResult(costs=(RuntimeError(&#39;Traceback (most recent call last):\n  [bt] (3) /workspace/build/libtvm.so(TVMFuncCall+0x61) [0x7fd8bb1b9741]\n  [bt] (2) /workspace/build/libtvm.so(std::_Function_handler&lt;void (tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*), tvm::runtime::RPCModuleNode::WrapRemote(void*)::{lambda(tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)#1}&gt;::_M_invoke(std::_Any_data const&amp;, tvm::runtime::TVMArgs&amp;&amp;, tvm::runtime::TVMRetValue*&amp;&amp;)+0x41) [0x7fd8bb1daa41]\n  [bt] (1) /workspace/build/libtvm.so(tvm::runtime::RPCSession::CallFunc(void*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*, void* (*)(int, tvm::runtime::TVMArgValue const&amp;), tvm::runtime::PackedFunc const*)+0x167) [0x7fd8bb1f5ee7]\n  [bt] (0) /workspace/build/libtvm.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x32) [0x7fd8ba912f12]\n  File &quot;/workspace/src/runtime/rpc/rpc_session.cc&quot;, line 993\nTVMError: Check failed: code == RPCCode: :kReturn: code=4&#39;,),), error_no=4, all_cost=10.234127521514893, timestamp=1585556420.9343731)     [(&#39;tile_y&#39;, [-1, 512]), (&#39;tile_x&#39;, [-1, 1])],None,9
</pre></div>
</div>
<p>Finally we apply history best from the cache file and check its correctness.
We can call the function <code class="code docutils literal notranslate"><span class="pre">matmul</span></code> directly under the
<a class="reference internal" href="../../api/python/autotvm.html#module-tvm.autotvm.apply_history_best" title="tvm.autotvm.apply_history_best"><code class="xref any py py-mod docutils literal notranslate"><span class="pre">autotvm.apply_history_best</span></code></a> context. When we call this function,
it will query the dispatch context with its argument and get the best config
with the same argument.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span class="c1"># apply history best from log file</span>
<span class="k">with</span> <a href="../../api/python/autotvm.html#module-tvm.autotvm.apply_history_best" title="View documentation for tvm.autotvm.apply_history_best"><span class="n">autotvm</span><span class="o">.</span><span class="n">apply_history_best</span></a><span class="p">(</span><span class="s1">&#39;matmul.log&#39;</span><span class="p">):</span>
    <span class="k">with</span> <a href="../../api/python/target.html#tvm.target.create" title="View documentation for tvm.target.create"><span class="n">tvm</span><span class="o">.</span><span class="n">target</span><span class="o">.</span><span class="n">create</span></a><span class="p">(</span><span class="s2">&quot;llvm&quot;</span><span class="p">):</span>
        <span class="n">s</span><span class="p">,</span> <span class="n">arg_bufs</span> <span class="o">=</span> <span class="n">matmul</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="s1">&#39;float32&#39;</span><span class="p">)</span>
        <span class="n">func</span> <span class="o">=</span> <a href="../../api/python/driver.html#tvm.build" title="View documentation for tvm.build"><span class="n">tvm</span><span class="o">.</span><span class="n">build</span></a><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">arg_bufs</span><span class="p">)</span>

<span class="c1"># check correctness</span>
<span class="n">a_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">L</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">b_np</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">M</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">c_np</span> <span class="o">=</span> <span class="n">a_np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">b_np</span><span class="p">)</span>

<span class="n">c_tvm</span> <span class="o">=</span> <a href="../../api/python/ndarray.html#tvm.nd.empty" title="View documentation for tvm.nd.empty"><span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">empty</span></a><span class="p">(</span><span class="n">c_np</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">func</span><span class="p">(</span><a href="../../api/python/ndarray.html#tvm.nd.array" title="View documentation for tvm.nd.array"><span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span></a><span class="p">(</span><span class="n">a_np</span><span class="p">),</span> <a href="../../api/python/ndarray.html#tvm.nd.array" title="View documentation for tvm.nd.array"><span class="n">tvm</span><span class="o">.</span><span class="n">nd</span><span class="o">.</span><span class="n">array</span></a><span class="p">(</span><span class="n">b_np</span><span class="p">),</span> <span class="n">c_tvm</span><span class="p">)</span>

<span class="n">tvm</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_allclose</span><span class="p">(</span><span class="n">c_np</span><span class="p">,</span> <span class="n">c_tvm</span><span class="o">.</span><span class="n">asnumpy</span><span class="p">(),</span> <span class="n">rtol</span><span class="o">=</span><span class="mi">1</span><span class="n">e</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  26.717 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-tutorials-autotvm-tune-simple-template-py">
<div class="sphx-glr-download docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/0bb862dbb3a4c434477f93fe2c147fbb/tune_simple_template.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">tune_simple_template.py</span></code></a></p>
</div>
<div class="sphx-glr-download docutils container">
<p><a class="reference download internal" download="" href="../../_downloads/0d95a85fc279fdff660608ef305b9107/tune_simple_template.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">tune_simple_template.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="tune_conv2d_cuda.html" class="btn btn-neutral float-right" title="Tuning High Performance Convolution on NVIDIA GPUs" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="../optimize/opt_matmul_auto_tensorcore.html" class="btn btn-neutral float-left" title="How to optimize matmul with Auto TensorCore CodeGen" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, Apache Software Foundation

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
    <!-- Theme Analytics -->
    <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-75982049-2', 'auto');
    ga('send', 'pageview');
    </script>

    
   

</body>
</html>