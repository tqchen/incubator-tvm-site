\hypertarget{operation_8h}{}\section{include/tvm/te/operation.h File Reference}
\label{operation_8h}\index{include/tvm/te/operation.\+h@{include/tvm/te/operation.\+h}}


Operation node can generate one or multiple Tensors.  


{\ttfamily \#include $<$tvm/arith/analyzer.\+h$>$}\\*
{\ttfamily \#include $<$tvm/te/tensor.\+h$>$}\\*
{\ttfamily \#include $<$tvm/te/schedule.\+h$>$}\\*
{\ttfamily \#include $<$tvm/tir/expr.\+h$>$}\\*
{\ttfamily \#include $<$tvm/tir/op.\+h$>$}\\*
{\ttfamily \#include $<$tvm/tir/buffer.\+h$>$}\\*
{\ttfamily \#include $<$string$>$}\\*
{\ttfamily \#include $<$vector$>$}\\*
{\ttfamily \#include $<$unordered\+\_\+map$>$}\\*
Include dependency graph for operation.\+h\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{operation_8h__incl}
\end{center}
\end{figure}
This graph shows which files directly or indirectly include this file\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=350pt]{operation_8h__dep__incl}
\end{center}
\end{figure}
\subsection*{Classes}
\begin{DoxyCompactItemize}
\item 
struct \hyperlink{structtvm_1_1te_1_1TensorDom}{tvm\+::te\+::\+Tensor\+Dom}
\begin{DoxyCompactList}\small\item\em Temporary data structure to store union of bounds of each axis of \hyperlink{classtvm_1_1te_1_1Tensor}{Tensor}. \end{DoxyCompactList}\item 
class \hyperlink{classtvm_1_1te_1_1OperationNode}{tvm\+::te\+::\+Operation\+Node}
\begin{DoxyCompactList}\small\item\em Base class of all operation nodes. \end{DoxyCompactList}\item 
class \hyperlink{classtvm_1_1te_1_1PlaceholderOpNode}{tvm\+::te\+::\+Placeholder\+Op\+Node}
\begin{DoxyCompactList}\small\item\em A placeholder op represents an input placeholder. \end{DoxyCompactList}\item 
class \hyperlink{classtvm_1_1te_1_1BaseComputeOpNode}{tvm\+::te\+::\+Base\+Compute\+Op\+Node}
\begin{DoxyCompactList}\small\item\em A Compute op that compute a tensor on certain domain. This is the base class for Compute\+Op (operating on a scalar at a time) and Tensor\+Compute\+Op (operating on a Tensor\+Slice at a time) \end{DoxyCompactList}\item 
class \hyperlink{classtvm_1_1te_1_1ComputeOpNode}{tvm\+::te\+::\+Compute\+Op\+Node}
\begin{DoxyCompactList}\small\item\em A Compute op that compute a tensor on certain domain. \end{DoxyCompactList}\item 
class \hyperlink{classtvm_1_1te_1_1TensorComputeOpNode}{tvm\+::te\+::\+Tensor\+Compute\+Op\+Node}
\begin{DoxyCompactList}\small\item\em A Tenor\+Compute op that compute a tensor with an tensor intrinsic. \end{DoxyCompactList}\item 
class \hyperlink{classtvm_1_1te_1_1ScanOpNode}{tvm\+::te\+::\+Scan\+Op\+Node}
\begin{DoxyCompactList}\small\item\em Symbolic scan. \end{DoxyCompactList}\item 
class \hyperlink{classtvm_1_1te_1_1ExternOpNode}{tvm\+::te\+::\+Extern\+Op\+Node}
\begin{DoxyCompactList}\small\item\em External computation that cannot be splitted. \end{DoxyCompactList}\item 
class \hyperlink{classtvm_1_1te_1_1HybridOpNode}{tvm\+::te\+::\+Hybrid\+Op\+Node}
\begin{DoxyCompactList}\small\item\em A computation operator that generated by hybrid script. \end{DoxyCompactList}\end{DoxyCompactItemize}
\subsection*{Namespaces}
\begin{DoxyCompactItemize}
\item 
 \hyperlink{namespacetvm}{tvm}
\item 
 \hyperlink{namespacetvm_1_1te}{tvm\+::te}
\begin{DoxyCompactList}\small\item\em \hyperlink{classtvm_1_1te_1_1Tensor}{Tensor} expression language D\+SL. \end{DoxyCompactList}\end{DoxyCompactItemize}
\subsection*{Typedefs}
\begin{DoxyCompactItemize}
\item 
using \hyperlink{namespacetvm_1_1te_a234ec7f58c22878752d476bd7e99bcea}{tvm\+::te\+::\+F\+Compute} = std\+::function$<$ Prim\+Expr(const Array$<$ Var $>$ \&i)$>$
\begin{DoxyCompactList}\small\item\em The compute function to specify the input source of a \hyperlink{classtvm_1_1te_1_1Tensor}{Tensor}. \end{DoxyCompactList}\item 
using \hyperlink{namespacetvm_1_1te_aabb227a4a0747faf17a2a8028f5430d5}{tvm\+::te\+::\+F\+Batch\+Compute} = std\+::function$<$ Array$<$ Prim\+Expr $>$(const Array$<$ Var $>$ \&i)$>$
\begin{DoxyCompactList}\small\item\em The compute function to specify the inputs source of Tensors. \end{DoxyCompactList}\end{DoxyCompactItemize}
\subsection*{Functions}
\begin{DoxyCompactItemize}
\item 
Var \hyperlink{namespacetvm_1_1te_ae0c71f84710b436cbe0b32289d0838f4}{tvm\+::te\+::var} (std\+::string name\+\_\+hint, Data\+Type t=Data\+Type\+::\+Int(32))
\begin{DoxyCompactList}\small\item\em Construct a new Var expression. \end{DoxyCompactList}\item 
Iter\+Var \hyperlink{namespacetvm_1_1te_aacca360b75a7db1eb79785bff8c6e205}{tvm\+::te\+::thread\+\_\+axis} (Range dom, std\+::string tag)
\begin{DoxyCompactList}\small\item\em Create a new Iter\+Var that represents an axis in thread. \end{DoxyCompactList}\item 
Iter\+Var \hyperlink{namespacetvm_1_1te_aae384e9b73c2271905486e4a74b69265}{tvm\+::te\+::reduce\+\_\+axis} (Range dom, std\+::string name=\char`\"{}rv\char`\"{})
\begin{DoxyCompactList}\small\item\em Create a new Iter\+Var for reduction operations. \end{DoxyCompactList}\item 
Tensor \hyperlink{namespacetvm_1_1te_a15a1cc6f7146730ec1f03210c81a8a3c}{tvm\+::te\+::placeholder} (Array$<$ Prim\+Expr $>$ shape, Data\+Type dtype=Data\+Type\+::\+Float(32), std\+::string name=\char`\"{}placeholder\char`\"{})
\begin{DoxyCompactList}\small\item\em create a place holder tensor. \end{DoxyCompactList}\item 
Tensor \hyperlink{namespacetvm_1_1te_aeacae1afc9dd1267cbb5779f9daa4671}{tvm\+::te\+::compute} (Array$<$ Prim\+Expr $>$ shape, F\+Compute fcompute, std\+::string name=\char`\"{}tensor\char`\"{}, std\+::string tag=\char`\"{}\char`\"{}, Map$<$ std\+::string, Object\+Ref $>$ attrs=\{\})
\begin{DoxyCompactList}\small\item\em Construct a new tensor by computing over shape, using the computation rule\+: result\+\_\+tensor\mbox{[}axis\mbox{]} = fcompute(axis) \end{DoxyCompactList}\item 
Array$<$ Tensor $>$ \hyperlink{namespacetvm_1_1te_aecda635ef665a59178b464d7ac6f55c8}{tvm\+::te\+::compute} (Array$<$ Prim\+Expr $>$ shape, F\+Batch\+Compute fcompute, std\+::string name=\char`\"{}tensor\char`\"{}, std\+::string tag=\char`\"{}\char`\"{}, Map$<$ std\+::string, Object\+Ref $>$ attrs=\{\})
\begin{DoxyCompactList}\small\item\em Construct a new tensor by computing over shape, using the computation rule\+: result\+\_\+tensor\mbox{[}axis\mbox{]} = fcompute(axis) \end{DoxyCompactList}\item 
Array$<$ Tensor $>$ \hyperlink{namespacetvm_1_1te_ad78173237a27f7145c6b198be85b1f0d}{tvm\+::te\+::scan} (Array$<$ Tensor $>$ init, Array$<$ Tensor $>$ update, Array$<$ Tensor $>$ state\+\_\+placeholder, Array$<$ Tensor $>$ inputs=Array$<$ Tensor $>$(), std\+::string name=\char`\"{}scan\char`\"{}, std\+::string tag=\char`\"{}\char`\"{}, Map$<$ std\+::string, Object\+Ref $>$ attrs=\{\})
\begin{DoxyCompactList}\small\item\em Construct new tensors by scan. \end{DoxyCompactList}\item 
Tensor \hyperlink{namespacetvm_1_1te_aa7dcf52a4277350f202a9103e6ad9d17}{tvm\+::te\+::compute} (Array$<$ Prim\+Expr $>$ shape, std\+::function$<$ Prim\+Expr(Var)$>$ f, std\+::string name=\char`\"{}tensor\char`\"{}, std\+::string tag=\char`\"{}\char`\"{}, Map$<$ std\+::string, Object\+Ref $>$ attrs=\{\})
\item 
Tensor \hyperlink{namespacetvm_1_1te_a44dae0ad08627ceebe2d0d3f45daa388}{tvm\+::te\+::compute} (Array$<$ Prim\+Expr $>$ shape, std\+::function$<$ Prim\+Expr(Var, Var)$>$ f, std\+::string name=\char`\"{}tensor\char`\"{}, std\+::string tag=\char`\"{}\char`\"{}, Map$<$ std\+::string, Object\+Ref $>$ attrs=\{\})
\item 
Tensor \hyperlink{namespacetvm_1_1te_a37b573ec96a0c47ff16719bcd13d7531}{tvm\+::te\+::compute} (Array$<$ Prim\+Expr $>$ shape, std\+::function$<$ Prim\+Expr(Var, Var, Var)$>$ f, std\+::string name=\char`\"{}tensor\char`\"{}, std\+::string tag=\char`\"{}\char`\"{}, Map$<$ std\+::string, Object\+Ref $>$ attrs=\{\})
\item 
Tensor \hyperlink{namespacetvm_1_1te_aaf04658c5295c3ccebaed3f7b824a841}{tvm\+::te\+::compute} (Array$<$ Prim\+Expr $>$ shape, std\+::function$<$ Prim\+Expr(Var, Var, Var, Var)$>$ f, std\+::string name=\char`\"{}tensor\char`\"{}, std\+::string tag=\char`\"{}\char`\"{}, Map$<$ std\+::string, Object\+Ref $>$ attrs=\{\})
\end{DoxyCompactItemize}


\subsection{Detailed Description}
Operation node can generate one or multiple Tensors. 

