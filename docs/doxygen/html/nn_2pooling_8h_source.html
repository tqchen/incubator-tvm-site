<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.11"/>
<title>tvm: topi/include/topi/nn/pooling.h Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { init_search(); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">tvm
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.11 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li class="current"><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="files.html"><span>File&#160;List</span></a></li>
      <li><a href="globals.html"><span>File&#160;Members</span></a></li>
    </ul>
  </div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="dir_a99f4dc995763900c0e382b7dd5d0038.html">topi</a></li><li class="navelem"><a class="el" href="dir_e79ffd3285e304ad4c501fa62028ed74.html">include</a></li><li class="navelem"><a class="el" href="dir_85f3d6180da4edc5eb489febd20e807a.html">topi</a></li><li class="navelem"><a class="el" href="dir_501163e255a572c2b8f8622055dcc830.html">nn</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">pooling.h</div>  </div>
</div><!--header-->
<div class="contents">
<a href="nn_2pooling_8h.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;<span class="comment">/*</span></div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;<span class="comment"> * Licensed to the Apache Software Foundation (ASF) under one</span></div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;<span class="comment"> * or more contributor license agreements.  See the NOTICE file</span></div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;<span class="comment"> * distributed with this work for additional information</span></div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;<span class="comment"> * regarding copyright ownership.  The ASF licenses this file</span></div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;<span class="comment"> * to you under the Apache License, Version 2.0 (the</span></div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;<span class="comment"> * &quot;License&quot;); you may not use this file except in compliance</span></div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;<span class="comment"> * with the License.  You may obtain a copy of the License at</span></div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;<span class="comment"> *   http://www.apache.org/licenses/LICENSE-2.0</span></div><div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;<span class="comment"> * Unless required by applicable law or agreed to in writing,</span></div><div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;<span class="comment"> * software distributed under the License is distributed on an</span></div><div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;<span class="comment"> * &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY</span></div><div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;<span class="comment"> * KIND, either express or implied.  See the License for the</span></div><div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;<span class="comment"> * specific language governing permissions and limitations</span></div><div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;<span class="comment"> * under the License.</span></div><div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;</div><div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;<span class="preprocessor">#ifndef TOPI_NN_POOLING_H_</span></div><div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;<span class="preprocessor">#define TOPI_NN_POOLING_H_</span></div><div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160;</div><div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;<span class="preprocessor">#include &lt;<a class="code" href="pad__utils_8h.html">topi/detail/pad_utils.h</a>&gt;</span></div><div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;<span class="preprocessor">#include &lt;<a class="code" href="topi_2include_2topi_2nn_8h.html">topi/nn.h</a>&gt;</span></div><div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;<span class="preprocessor">#include &lt;<a class="code" href="reduction_8h.html">topi/reduction.h</a>&gt;</span></div><div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;<span class="preprocessor">#include &lt;<a class="code" href="tags_8h.html">topi/tags.h</a>&gt;</span></div><div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;<span class="preprocessor">#include &lt;<a class="code" href="ir__pass_8h.html">tvm/tir/ir_pass.h</a>&gt;</span></div><div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;</div><div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;<span class="preprocessor">#include &lt;algorithm&gt;</span></div><div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;<span class="preprocessor">#include &lt;string&gt;</span></div><div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;<span class="preprocessor">#include &lt;vector&gt;</span></div><div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;</div><div class="line"><a name="l00037"></a><span class="lineno">   37</span>&#160;<span class="keyword">namespace </span><a class="code" href="namespacetopi.html">topi</a> {</div><div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;<span class="keyword">namespace </span>nn {</div><div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;<span class="keyword">using namespace </span><a class="code" href="namespacetvm.html">tvm</a>;</div><div class="line"><a name="l00040"></a><span class="lineno">   40</span>&#160;<span class="keyword">using namespace </span><a class="code" href="namespacetvm_1_1te.html">tvm::te</a>;</div><div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;</div><div class="line"><a name="l00043"></a><span class="lineno"><a class="line" href="namespacetopi_1_1nn.html#ac531cfce9c3a031fa25cfb6ed1f9b95b">   43</a></span>&#160;<span class="keyword">enum</span> <a class="code" href="namespacetopi_1_1nn.html#ac531cfce9c3a031fa25cfb6ed1f9b95b">PoolType</a> : <span class="keywordtype">int</span> {</div><div class="line"><a name="l00044"></a><span class="lineno"><a class="line" href="namespacetopi_1_1nn.html#ac531cfce9c3a031fa25cfb6ed1f9b95babbfb6c4315c8b57e558600af1515d3d8">   44</a></span>&#160;  <a class="code" href="namespacetopi_1_1nn.html#ac531cfce9c3a031fa25cfb6ed1f9b95babbfb6c4315c8b57e558600af1515d3d8">kAvgPool</a>,</div><div class="line"><a name="l00045"></a><span class="lineno"><a class="line" href="namespacetopi_1_1nn.html#ac531cfce9c3a031fa25cfb6ed1f9b95ba3a406a1361a3c7ca311d3c514842c2f4">   45</a></span>&#160;  <a class="code" href="namespacetopi_1_1nn.html#ac531cfce9c3a031fa25cfb6ed1f9b95ba3a406a1361a3c7ca311d3c514842c2f4">kMaxPool</a>,</div><div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160;};</div><div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;</div><div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;</div><div class="line"><a name="l00064"></a><span class="lineno"><a class="line" href="namespacetopi_1_1nn.html#ad51533b09956d7bc8de2537adf3b6b77">   64</a></span>&#160;<span class="keyword">inline</span> <a class="code" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> <a class="code" href="namespacetopi_1_1nn.html#ad51533b09956d7bc8de2537adf3b6b77">pool_impl</a>(<span class="keyword">const</span> <a class="code" href="classtvm_1_1te_1_1Tensor.html">Tensor</a>&amp; x,</div><div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;                        <span class="keyword">const</span> <a class="code" href="classtvm_1_1Array.html">Array&lt;PrimExpr&gt;</a>&amp; kernel_size,</div><div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;                        <span class="keyword">const</span> <a class="code" href="classtvm_1_1Array.html">Array&lt;PrimExpr&gt;</a>&amp; stride_size,</div><div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;                        <span class="keyword">const</span> <a class="code" href="classtvm_1_1Array.html">Array&lt;PrimExpr&gt;</a>&amp; padding_size,</div><div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;                        <a class="code" href="namespacetopi_1_1nn.html#ac531cfce9c3a031fa25cfb6ed1f9b95b">PoolType</a> pool_type,</div><div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;                        <span class="keywordtype">bool</span> ceil_mode,</div><div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;                        <span class="keyword">const</span> <span class="keywordtype">size_t</span> height_axis,</div><div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;                        <span class="keyword">const</span> <span class="keywordtype">size_t</span> width_axis,</div><div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;                        <span class="keywordtype">bool</span> count_include_pad) {</div><div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;  CHECK(x-&gt;<a class="code" href="classtvm_1_1te_1_1TensorNode.html#a0ba732bc2def0d467854585752911351">shape</a>.size() &gt;= 2) &lt;&lt; <span class="stringliteral">&quot;Pooling input must &gt;= 2-D (H, W)&quot;</span>;</div><div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;  CHECK_EQ(kernel_size.<a class="code" href="classtvm_1_1Array.html#a6c150ee7d3e46117b099d2052b19aec5">size</a>(), 2) &lt;&lt; <span class="stringliteral">&quot;Pooling kernel_size must have 2 elements&quot;</span>;</div><div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160;  CHECK_EQ(stride_size.<a class="code" href="classtvm_1_1Array.html#a6c150ee7d3e46117b099d2052b19aec5">size</a>(), 2) &lt;&lt; <span class="stringliteral">&quot;Pooling stride_size must have 2 elements&quot;</span>;</div><div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160;  CHECK_EQ(padding_size.<a class="code" href="classtvm_1_1Array.html#a6c150ee7d3e46117b099d2052b19aec5">size</a>(), 4) &lt;&lt; <span class="stringliteral">&quot;Pooling padding_size must have 4 elements&quot;</span>;</div><div class="line"><a name="l00077"></a><span class="lineno">   77</span>&#160;</div><div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;  <span class="keyword">auto</span> kernel_height = <a class="code" href="namespacetopi.html#acfc3df84ca997ccac0f57d50e96c1c06">cast</a>(DataType::DataType::Int(32), kernel_size[0]);</div><div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;  <span class="keyword">auto</span> kernel_width = <a class="code" href="namespacetopi.html#acfc3df84ca997ccac0f57d50e96c1c06">cast</a>(DataType::DataType::Int(32), kernel_size[1]);</div><div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;  <span class="keyword">auto</span> stride_height = <a class="code" href="namespacetopi.html#acfc3df84ca997ccac0f57d50e96c1c06">cast</a>(DataType::DataType::Int(32), stride_size[0]);</div><div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;  <span class="keyword">auto</span> stride_width = <a class="code" href="namespacetopi.html#acfc3df84ca997ccac0f57d50e96c1c06">cast</a>(DataType::DataType::Int(32), stride_size[1]);</div><div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;</div><div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160;  <span class="keyword">auto</span> height = x-&gt;<a class="code" href="classtvm_1_1te_1_1TensorNode.html#a0ba732bc2def0d467854585752911351">shape</a>[height_axis];</div><div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;  <span class="keyword">auto</span> width = x-&gt;<a class="code" href="classtvm_1_1te_1_1TensorNode.html#a0ba732bc2def0d467854585752911351">shape</a>[width_axis];</div><div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160;</div><div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;  <span class="keyword">auto</span> pad_top = <a class="code" href="namespacetopi.html#acfc3df84ca997ccac0f57d50e96c1c06">cast</a>(DataType::DataType::Int(32), padding_size[0]);</div><div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;  <span class="keyword">auto</span> pad_left = <a class="code" href="namespacetopi.html#acfc3df84ca997ccac0f57d50e96c1c06">cast</a>(DataType::DataType::Int(32), padding_size[1]);</div><div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160;  <span class="keyword">auto</span> pad_bottom = <a class="code" href="namespacetopi.html#acfc3df84ca997ccac0f57d50e96c1c06">cast</a>(DataType::DataType::Int(32), padding_size[2]);</div><div class="line"><a name="l00089"></a><span class="lineno">   89</span>&#160;  <span class="keyword">auto</span> pad_right = <a class="code" href="namespacetopi.html#acfc3df84ca997ccac0f57d50e96c1c06">cast</a>(DataType::DataType::Int(32), padding_size[3]);</div><div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;</div><div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160;  <span class="keywordflow">if</span> (ceil_mode) {</div><div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;    <span class="comment">// Additional padding to ensure we do ceil instead of floor when</span></div><div class="line"><a name="l00093"></a><span class="lineno">   93</span>&#160;    <span class="comment">// dividing by stride.</span></div><div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;    pad_bottom += stride_height - 1;</div><div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;    pad_right += stride_width - 1;</div><div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;  }</div><div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160;</div><div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;  <a class="code" href="classtvm_1_1Array.html">Array&lt;PrimExpr&gt;</a> pad_before(std::vector&lt;PrimExpr&gt;(x-&gt;<a class="code" href="classtvm_1_1te_1_1TensorNode.html#a0ba732bc2def0d467854585752911351">shape</a>.size(), 0));</div><div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;  pad_before.<a class="code" href="classtvm_1_1Array.html#ab3db968deb4be7a51767f22d267eb7af">Set</a>(height_axis, pad_top);</div><div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;  pad_before.<a class="code" href="classtvm_1_1Array.html#ab3db968deb4be7a51767f22d267eb7af">Set</a>(width_axis, pad_left);</div><div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160;</div><div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160;  <a class="code" href="classtvm_1_1Array.html">Array&lt;PrimExpr&gt;</a> pad_after(std::vector&lt;PrimExpr&gt;(x-&gt;<a class="code" href="classtvm_1_1te_1_1TensorNode.html#a0ba732bc2def0d467854585752911351">shape</a>.size(), 0));</div><div class="line"><a name="l00103"></a><span class="lineno">  103</span>&#160;  pad_after.<a class="code" href="classtvm_1_1Array.html#ab3db968deb4be7a51767f22d267eb7af">Set</a>(height_axis, pad_bottom);</div><div class="line"><a name="l00104"></a><span class="lineno">  104</span>&#160;  pad_after.<a class="code" href="classtvm_1_1Array.html#ab3db968deb4be7a51767f22d267eb7af">Set</a>(width_axis, pad_right);</div><div class="line"><a name="l00105"></a><span class="lineno">  105</span>&#160;</div><div class="line"><a name="l00106"></a><span class="lineno">  106</span>&#160;  <span class="keyword">auto</span> out_height = <a class="code" href="namespacetvm_1_1tir.html#a923d1bb833c984008772782e90cda37a">tvm::tir::Simplify</a>(</div><div class="line"><a name="l00107"></a><span class="lineno">  107</span>&#160;      <a class="code" href="namespacetvm.html#a8203d70a5ebf3532370264b000d0d276">indexdiv</a>(height - kernel_height + pad_top + pad_bottom, stride_height) + 1);</div><div class="line"><a name="l00108"></a><span class="lineno">  108</span>&#160;  <span class="keyword">auto</span> out_width = <a class="code" href="namespacetvm_1_1tir.html#a923d1bb833c984008772782e90cda37a">tvm::tir::Simplify</a>(</div><div class="line"><a name="l00109"></a><span class="lineno">  109</span>&#160;      <a class="code" href="namespacetvm.html#a8203d70a5ebf3532370264b000d0d276">indexdiv</a>(width - kernel_width + pad_left + pad_right, stride_width) + 1);</div><div class="line"><a name="l00110"></a><span class="lineno">  110</span>&#160;</div><div class="line"><a name="l00111"></a><span class="lineno">  111</span>&#160;  <span class="keyword">auto</span> dheight = <a class="code" href="namespacetvm_1_1te.html#aae384e9b73c2271905486e4a74b69265">tvm::te::reduce_axis</a>(<a class="code" href="classtvm_1_1Range.html">Range</a>(0, kernel_height));</div><div class="line"><a name="l00112"></a><span class="lineno">  112</span>&#160;  <span class="keyword">auto</span> dwidth = <a class="code" href="namespacetvm_1_1te.html#aae384e9b73c2271905486e4a74b69265">tvm::te::reduce_axis</a>(<a class="code" href="classtvm_1_1Range.html">Range</a>(0, kernel_width));</div><div class="line"><a name="l00113"></a><span class="lineno">  113</span>&#160;</div><div class="line"><a name="l00114"></a><span class="lineno">  114</span>&#160;  <a class="code" href="classtvm_1_1Array.html">Array&lt;PrimExpr&gt;</a> out_shape = x-&gt;<a class="code" href="classtvm_1_1te_1_1TensorNode.html#a0ba732bc2def0d467854585752911351">shape</a>;</div><div class="line"><a name="l00115"></a><span class="lineno">  115</span>&#160;  out_shape.<a class="code" href="classtvm_1_1Array.html#ab3db968deb4be7a51767f22d267eb7af">Set</a>(height_axis, out_height);</div><div class="line"><a name="l00116"></a><span class="lineno">  116</span>&#160;  out_shape.<a class="code" href="classtvm_1_1Array.html#ab3db968deb4be7a51767f22d267eb7af">Set</a>(width_axis, out_width);</div><div class="line"><a name="l00117"></a><span class="lineno">  117</span>&#160;</div><div class="line"><a name="l00118"></a><span class="lineno">  118</span>&#160;  <span class="keyword">const</span> int64_t *padding_h0 = <a class="code" href="namespacetvm_1_1tir.html#acbe8f225faaf34c540194921a7ee6a66">as_const_int</a>(pad_top);</div><div class="line"><a name="l00119"></a><span class="lineno">  119</span>&#160;  <span class="keyword">const</span> int64_t *padding_w0 = <a class="code" href="namespacetvm_1_1tir.html#acbe8f225faaf34c540194921a7ee6a66">as_const_int</a>(pad_left);</div><div class="line"><a name="l00120"></a><span class="lineno">  120</span>&#160;  <span class="keyword">const</span> int64_t *padding_h1 = <a class="code" href="namespacetvm_1_1tir.html#acbe8f225faaf34c540194921a7ee6a66">as_const_int</a>(pad_bottom);</div><div class="line"><a name="l00121"></a><span class="lineno">  121</span>&#160;  <span class="keyword">const</span> int64_t *padding_w1 = <a class="code" href="namespacetvm_1_1tir.html#acbe8f225faaf34c540194921a7ee6a66">as_const_int</a>(pad_right);</div><div class="line"><a name="l00122"></a><span class="lineno">  122</span>&#160;  <span class="keyword">const</span> <span class="keywordtype">bool</span> do_pad = ((padding_h0 &amp;&amp; *padding_h0) || (padding_w0 &amp;&amp; *padding_w0)) ||</div><div class="line"><a name="l00123"></a><span class="lineno">  123</span>&#160;                      ((padding_h1 &amp;&amp; *padding_h1) || (padding_w1 &amp;&amp; *padding_w1));</div><div class="line"><a name="l00124"></a><span class="lineno">  124</span>&#160;</div><div class="line"><a name="l00125"></a><span class="lineno">  125</span>&#160;  <span class="keywordflow">if</span> (pool_type == <a class="code" href="namespacetopi_1_1nn.html#ac531cfce9c3a031fa25cfb6ed1f9b95ba3a406a1361a3c7ca311d3c514842c2f4">kMaxPool</a>) {</div><div class="line"><a name="l00126"></a><span class="lineno">  126</span>&#160;    <span class="keyword">auto</span> temp = do_pad ? <a class="code" href="namespacetopi.html#a7d9e2d0f526ff451b6df91c6a673f440">pad</a>(</div><div class="line"><a name="l00127"></a><span class="lineno">  127</span>&#160;        x, pad_before, pad_after, <a class="code" href="namespacetvm.html#a9c126a8dde0d4079713969ca574f172e">tvm::min_value</a>(x-&gt;<a class="code" href="classtvm_1_1te_1_1TensorNode.html#a4c0b6e32a09ab6ea6b869de45394294d">dtype</a>), <span class="stringliteral">&quot;pad_temp&quot;</span>) : x;</div><div class="line"><a name="l00128"></a><span class="lineno">  128</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="namespacetvm_1_1te.html#aeacae1afc9dd1267cbb5779f9daa4671">tvm::te::compute</a>(out_shape, [&amp;](<span class="keyword">const</span> <a class="code" href="classtvm_1_1Array.html">Array&lt;Var&gt;</a>&amp; output) {</div><div class="line"><a name="l00129"></a><span class="lineno">  129</span>&#160;      <a class="code" href="classtvm_1_1Array.html">Array&lt;PrimExpr&gt;</a> indices;</div><div class="line"><a name="l00130"></a><span class="lineno">  130</span>&#160;      <span class="keywordflow">for</span> (<span class="keyword">const</span> <a class="code" href="classtvm_1_1tir_1_1Var.html">Var</a>&amp; <a class="code" href="namespacetvm_1_1te.html#ae0c71f84710b436cbe0b32289d0838f4">var</a> : output) indices.<a class="code" href="classtvm_1_1Array.html#a24d5ac1f6730d46cb1a6d16729f0a7bb">push_back</a>(<a class="code" href="namespacetvm_1_1te.html#ae0c71f84710b436cbe0b32289d0838f4">var</a>);</div><div class="line"><a name="l00131"></a><span class="lineno">  131</span>&#160;      indices.<a class="code" href="classtvm_1_1Array.html#ab3db968deb4be7a51767f22d267eb7af">Set</a>(height_axis, output[height_axis] * stride_height + dheight);</div><div class="line"><a name="l00132"></a><span class="lineno">  132</span>&#160;      indices.<a class="code" href="classtvm_1_1Array.html#ab3db968deb4be7a51767f22d267eb7af">Set</a>(width_axis, output[width_axis] * stride_width + dwidth);</div><div class="line"><a name="l00133"></a><span class="lineno">  133</span>&#160;      <span class="keywordflow">return</span> <a class="code" href="namespacetvm.html#ab49bad0808ba033343e72ba37b39af2e">tvm::max</a>(temp(indices), { dheight, dwidth });</div><div class="line"><a name="l00134"></a><span class="lineno">  134</span>&#160;    }, <span class="stringliteral">&quot;tensor&quot;</span>, <span class="stringliteral">&quot;pool_max&quot;</span>);</div><div class="line"><a name="l00135"></a><span class="lineno">  135</span>&#160;  } <span class="keywordflow">else</span> <span class="keywordflow">if</span> (pool_type == <a class="code" href="namespacetopi_1_1nn.html#ac531cfce9c3a031fa25cfb6ed1f9b95babbfb6c4315c8b57e558600af1515d3d8">kAvgPool</a>) {</div><div class="line"><a name="l00136"></a><span class="lineno">  136</span>&#160;    <span class="comment">// Pad the inputs</span></div><div class="line"><a name="l00137"></a><span class="lineno">  137</span>&#160;    <span class="keyword">auto</span> temp = do_pad ? <a class="code" href="namespacetopi.html#a7d9e2d0f526ff451b6df91c6a673f440">pad</a>(x, pad_before, pad_after, 0, <span class="stringliteral">&quot;pad_temp&quot;</span>) : x;</div><div class="line"><a name="l00138"></a><span class="lineno">  138</span>&#160;</div><div class="line"><a name="l00139"></a><span class="lineno">  139</span>&#160;    <span class="comment">// TVM compute for summing the pooling window.</span></div><div class="line"><a name="l00140"></a><span class="lineno">  140</span>&#160;    <span class="keyword">auto</span> pool_sum = <a class="code" href="namespacetvm_1_1te.html#aeacae1afc9dd1267cbb5779f9daa4671">tvm::te::compute</a>(out_shape,</div><div class="line"><a name="l00141"></a><span class="lineno">  141</span>&#160;    [&amp;](<span class="keyword">const</span> <a class="code" href="classtvm_1_1Array.html">Array&lt;Var&gt;</a>&amp; output) {</div><div class="line"><a name="l00142"></a><span class="lineno">  142</span>&#160;      <a class="code" href="classtvm_1_1Array.html">Array&lt;PrimExpr&gt;</a> indices;</div><div class="line"><a name="l00143"></a><span class="lineno">  143</span>&#160;      <span class="keywordflow">for</span> (<span class="keyword">const</span> <a class="code" href="classtvm_1_1tir_1_1Var.html">Var</a>&amp; <a class="code" href="namespacetvm_1_1te.html#ae0c71f84710b436cbe0b32289d0838f4">var</a> : output) indices.<a class="code" href="classtvm_1_1Array.html#a24d5ac1f6730d46cb1a6d16729f0a7bb">push_back</a>(<a class="code" href="namespacetvm_1_1te.html#ae0c71f84710b436cbe0b32289d0838f4">var</a>);</div><div class="line"><a name="l00144"></a><span class="lineno">  144</span>&#160;      indices.<a class="code" href="classtvm_1_1Array.html#ab3db968deb4be7a51767f22d267eb7af">Set</a>(height_axis, output[height_axis] * stride_height + dheight);</div><div class="line"><a name="l00145"></a><span class="lineno">  145</span>&#160;      indices.<a class="code" href="classtvm_1_1Array.html#ab3db968deb4be7a51767f22d267eb7af">Set</a>(width_axis, output[width_axis] * stride_width + dwidth);</div><div class="line"><a name="l00146"></a><span class="lineno">  146</span>&#160;      <span class="keywordflow">return</span> <a class="code" href="namespacetvm.html#a5cea5eb708bfbfa08e285092e5afdc33">tvm::sum</a>(temp(indices), { dheight, dwidth });</div><div class="line"><a name="l00147"></a><span class="lineno">  147</span>&#160;    }, <span class="stringliteral">&quot;tensor&quot;</span>, <span class="stringliteral">&quot;pool_sum&quot;</span>);</div><div class="line"><a name="l00148"></a><span class="lineno">  148</span>&#160;</div><div class="line"><a name="l00149"></a><span class="lineno">  149</span>&#160;    <span class="comment">// TVM compute for dividing the reduced window sum by kernel size.</span></div><div class="line"><a name="l00150"></a><span class="lineno">  150</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="namespacetvm_1_1te.html#aeacae1afc9dd1267cbb5779f9daa4671">tvm::te::compute</a>(out_shape,</div><div class="line"><a name="l00151"></a><span class="lineno">  151</span>&#160;    [&amp;](<span class="keyword">const</span> <a class="code" href="classtvm_1_1Array.html">Array&lt;Var&gt;</a>&amp; output) {</div><div class="line"><a name="l00152"></a><span class="lineno">  152</span>&#160;      <a class="code" href="classtvm_1_1Array.html">Array&lt;PrimExpr&gt;</a> indices;</div><div class="line"><a name="l00153"></a><span class="lineno">  153</span>&#160;      <span class="keywordflow">for</span> (<span class="keyword">const</span> <a class="code" href="classtvm_1_1tir_1_1Var.html">Var</a>&amp; <a class="code" href="namespacetvm_1_1te.html#ae0c71f84710b436cbe0b32289d0838f4">var</a> : output) indices.<a class="code" href="classtvm_1_1Array.html#a24d5ac1f6730d46cb1a6d16729f0a7bb">push_back</a>(<a class="code" href="namespacetvm_1_1te.html#ae0c71f84710b436cbe0b32289d0838f4">var</a>);</div><div class="line"><a name="l00154"></a><span class="lineno">  154</span>&#160;      <span class="keywordflow">if</span> (count_include_pad) {</div><div class="line"><a name="l00155"></a><span class="lineno">  155</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="namespacetvm.html#a40fcc9952e1ff01a76f3b75dbd368fc1">div</a>(pool_sum(indices), (kernel_height * kernel_width));</div><div class="line"><a name="l00156"></a><span class="lineno">  156</span>&#160;      } <span class="keywordflow">else</span> {</div><div class="line"><a name="l00157"></a><span class="lineno">  157</span>&#160;        <a class="code" href="classtvm_1_1PrimExpr.html">PrimExpr</a> h_start = output[height_axis] * stride_height - pad_top;</div><div class="line"><a name="l00158"></a><span class="lineno">  158</span>&#160;        <a class="code" href="classtvm_1_1PrimExpr.html">PrimExpr</a> w_start = output[width_axis] * stride_width - pad_left;</div><div class="line"><a name="l00159"></a><span class="lineno">  159</span>&#160;        <a class="code" href="classtvm_1_1PrimExpr.html">PrimExpr</a> h_end = <a class="code" href="classtvm_1_1tir_1_1BinaryOpNode.html#afb3a9f4de76865880cc9f19ebcc75ea0">tir::MinNode::make</a>(h_start + kernel_height, height);</div><div class="line"><a name="l00160"></a><span class="lineno">  160</span>&#160;        <a class="code" href="classtvm_1_1PrimExpr.html">PrimExpr</a> w_end = <a class="code" href="classtvm_1_1tir_1_1BinaryOpNode.html#afb3a9f4de76865880cc9f19ebcc75ea0">tir::MinNode::make</a>(w_start + kernel_width, width);</div><div class="line"><a name="l00161"></a><span class="lineno">  161</span>&#160;        h_start = <a class="code" href="classtvm_1_1tir_1_1BinaryOpNode.html#afb3a9f4de76865880cc9f19ebcc75ea0">tir::MaxNode::make</a>(h_start, <a class="code" href="namespacetvm_1_1tir.html#a4ea566597880d04bd62fbec687e338b5">make_const</a>(DataType::DataType::Int(32), 0));</div><div class="line"><a name="l00162"></a><span class="lineno">  162</span>&#160;        w_start = <a class="code" href="classtvm_1_1tir_1_1BinaryOpNode.html#afb3a9f4de76865880cc9f19ebcc75ea0">tir::MaxNode::make</a>(w_start, <a class="code" href="namespacetvm_1_1tir.html#a4ea566597880d04bd62fbec687e338b5">make_const</a>(DataType::DataType::Int(32), 0));</div><div class="line"><a name="l00163"></a><span class="lineno">  163</span>&#160;        <a class="code" href="classtvm_1_1PrimExpr.html">PrimExpr</a> divide_factor = <a class="code" href="classtvm_1_1tir_1_1BinaryOpNode.html#afb3a9f4de76865880cc9f19ebcc75ea0">tir::MaxNode::make</a>((h_end - h_start) * (w_end - w_start),</div><div class="line"><a name="l00164"></a><span class="lineno">  164</span>&#160;                                           <a class="code" href="namespacetvm_1_1tir.html#a4ea566597880d04bd62fbec687e338b5">make_const</a>(DataType::DataType::Int(32), 1));</div><div class="line"><a name="l00165"></a><span class="lineno">  165</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="namespacetvm.html#a40fcc9952e1ff01a76f3b75dbd368fc1">div</a>(pool_sum(indices), divide_factor);</div><div class="line"><a name="l00166"></a><span class="lineno">  166</span>&#160;      }</div><div class="line"><a name="l00167"></a><span class="lineno">  167</span>&#160;    }, <span class="stringliteral">&quot;tensor&quot;</span>, <a class="code" href="namespacetopi.html#ac1b34ed59d38a5f5338bee6b2cad42be">kElementWise</a>);</div><div class="line"><a name="l00168"></a><span class="lineno">  168</span>&#160;  } <span class="keywordflow">else</span> {</div><div class="line"><a name="l00169"></a><span class="lineno">  169</span>&#160;    LOG(ERROR) &lt;&lt; <span class="stringliteral">&quot;Unrecognized pool_type: &quot;</span> &lt;&lt; pool_type;</div><div class="line"><a name="l00170"></a><span class="lineno">  170</span>&#160;    <span class="keywordflow">return</span> x;</div><div class="line"><a name="l00171"></a><span class="lineno">  171</span>&#160;  }</div><div class="line"><a name="l00172"></a><span class="lineno">  172</span>&#160;}</div><div class="line"><a name="l00173"></a><span class="lineno">  173</span>&#160;</div><div class="line"><a name="l00174"></a><span class="lineno"><a class="line" href="namespacetopi_1_1nn.html#af2c25e8b3ab3cac1c2896cb750838337">  174</a></span>&#160;<span class="keyword">inline</span> <a class="code" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> <a class="code" href="namespacetopi_1_1nn.html#af2c25e8b3ab3cac1c2896cb750838337">pool_grad_impl</a>(<span class="keyword">const</span> <a class="code" href="classtvm_1_1te_1_1Tensor.html">Tensor</a>&amp; out_grad,</div><div class="line"><a name="l00175"></a><span class="lineno">  175</span>&#160;                             <span class="keyword">const</span> <a class="code" href="classtvm_1_1te_1_1Tensor.html">Tensor</a>&amp; x,</div><div class="line"><a name="l00176"></a><span class="lineno">  176</span>&#160;                             <span class="keyword">const</span> <a class="code" href="classtvm_1_1Array.html">Array&lt;PrimExpr&gt;</a>&amp; kernel_size,</div><div class="line"><a name="l00177"></a><span class="lineno">  177</span>&#160;                             <span class="keyword">const</span> <a class="code" href="classtvm_1_1Array.html">Array&lt;PrimExpr&gt;</a>&amp; stride_size,</div><div class="line"><a name="l00178"></a><span class="lineno">  178</span>&#160;                             <span class="keyword">const</span> <a class="code" href="classtvm_1_1Array.html">Array&lt;PrimExpr&gt;</a>&amp; padding_size,</div><div class="line"><a name="l00179"></a><span class="lineno">  179</span>&#160;                             <a class="code" href="namespacetopi_1_1nn.html#ac531cfce9c3a031fa25cfb6ed1f9b95b">PoolType</a> pool_type, <span class="keywordtype">bool</span> ceil_mode,</div><div class="line"><a name="l00180"></a><span class="lineno">  180</span>&#160;                             <span class="keyword">const</span> <span class="keywordtype">size_t</span> height_axis, <span class="keyword">const</span> <span class="keywordtype">size_t</span> width_axis,</div><div class="line"><a name="l00181"></a><span class="lineno">  181</span>&#160;                             <span class="keywordtype">bool</span> count_include_pad) {</div><div class="line"><a name="l00182"></a><span class="lineno">  182</span>&#160;  CHECK(out_grad-&gt;<a class="code" href="classtvm_1_1te_1_1TensorNode.html#a0ba732bc2def0d467854585752911351">shape</a>.size() &gt;= 2) &lt;&lt; <span class="stringliteral">&quot;Pooling grad output must &gt;= 2-D (H, W)&quot;</span>;</div><div class="line"><a name="l00183"></a><span class="lineno">  183</span>&#160;  CHECK(x-&gt;<a class="code" href="classtvm_1_1te_1_1TensorNode.html#a0ba732bc2def0d467854585752911351">shape</a>.size() &gt;= 2) &lt;&lt; <span class="stringliteral">&quot;Pooling input must &gt;= 2-D (H, W)&quot;</span>;</div><div class="line"><a name="l00184"></a><span class="lineno">  184</span>&#160;  CHECK_EQ(kernel_size.<a class="code" href="classtvm_1_1Array.html#a6c150ee7d3e46117b099d2052b19aec5">size</a>(), 2) &lt;&lt; <span class="stringliteral">&quot;Pooling kernel_size must have 2 elements&quot;</span>;</div><div class="line"><a name="l00185"></a><span class="lineno">  185</span>&#160;  CHECK_EQ(stride_size.<a class="code" href="classtvm_1_1Array.html#a6c150ee7d3e46117b099d2052b19aec5">size</a>(), 2) &lt;&lt; <span class="stringliteral">&quot;Pooling stride_size must have 2 elements&quot;</span>;</div><div class="line"><a name="l00186"></a><span class="lineno">  186</span>&#160;  CHECK_EQ(padding_size.<a class="code" href="classtvm_1_1Array.html#a6c150ee7d3e46117b099d2052b19aec5">size</a>(), 4) &lt;&lt; <span class="stringliteral">&quot;Pooling padding_size must have 4 elements&quot;</span>;</div><div class="line"><a name="l00187"></a><span class="lineno">  187</span>&#160;</div><div class="line"><a name="l00188"></a><span class="lineno">  188</span>&#160;  <span class="keyword">auto</span> kernel_height = <a class="code" href="namespacetopi.html#acfc3df84ca997ccac0f57d50e96c1c06">cast</a>(DataType::DataType::Int(32), kernel_size[0]);</div><div class="line"><a name="l00189"></a><span class="lineno">  189</span>&#160;  <span class="keyword">auto</span> kernel_width = <a class="code" href="namespacetopi.html#acfc3df84ca997ccac0f57d50e96c1c06">cast</a>(DataType::DataType::Int(32), kernel_size[1]);</div><div class="line"><a name="l00190"></a><span class="lineno">  190</span>&#160;  <span class="keyword">auto</span> stride_height = <a class="code" href="namespacetopi.html#acfc3df84ca997ccac0f57d50e96c1c06">cast</a>(DataType::DataType::Int(32), stride_size[0]);</div><div class="line"><a name="l00191"></a><span class="lineno">  191</span>&#160;  <span class="keyword">auto</span> stride_width = <a class="code" href="namespacetopi.html#acfc3df84ca997ccac0f57d50e96c1c06">cast</a>(DataType::DataType::Int(32), stride_size[1]);</div><div class="line"><a name="l00192"></a><span class="lineno">  192</span>&#160;</div><div class="line"><a name="l00193"></a><span class="lineno">  193</span>&#160;  <span class="keyword">auto</span> height = x-&gt;<a class="code" href="classtvm_1_1te_1_1TensorNode.html#a0ba732bc2def0d467854585752911351">shape</a>[height_axis];</div><div class="line"><a name="l00194"></a><span class="lineno">  194</span>&#160;  <span class="keyword">auto</span> width = x-&gt;<a class="code" href="classtvm_1_1te_1_1TensorNode.html#a0ba732bc2def0d467854585752911351">shape</a>[width_axis];</div><div class="line"><a name="l00195"></a><span class="lineno">  195</span>&#160;</div><div class="line"><a name="l00196"></a><span class="lineno">  196</span>&#160;  <span class="keyword">auto</span> pad_top = <a class="code" href="namespacetopi.html#acfc3df84ca997ccac0f57d50e96c1c06">cast</a>(DataType::DataType::Int(32), padding_size[0]);</div><div class="line"><a name="l00197"></a><span class="lineno">  197</span>&#160;  <span class="keyword">auto</span> pad_left = <a class="code" href="namespacetopi.html#acfc3df84ca997ccac0f57d50e96c1c06">cast</a>(DataType::DataType::Int(32), padding_size[1]);</div><div class="line"><a name="l00198"></a><span class="lineno">  198</span>&#160;  <span class="keyword">auto</span> pad_bottom = <a class="code" href="namespacetopi.html#acfc3df84ca997ccac0f57d50e96c1c06">cast</a>(DataType::DataType::Int(32), padding_size[2]);</div><div class="line"><a name="l00199"></a><span class="lineno">  199</span>&#160;  <span class="keyword">auto</span> pad_right = <a class="code" href="namespacetopi.html#acfc3df84ca997ccac0f57d50e96c1c06">cast</a>(DataType::DataType::Int(32), padding_size[3]);</div><div class="line"><a name="l00200"></a><span class="lineno">  200</span>&#160;</div><div class="line"><a name="l00201"></a><span class="lineno">  201</span>&#160;  <span class="keywordflow">if</span> (ceil_mode) {</div><div class="line"><a name="l00202"></a><span class="lineno">  202</span>&#160;    <span class="comment">// Additional padding to ensure we do ceil instead of floor when</span></div><div class="line"><a name="l00203"></a><span class="lineno">  203</span>&#160;    <span class="comment">// dividing by stride.</span></div><div class="line"><a name="l00204"></a><span class="lineno">  204</span>&#160;    pad_bottom += stride_height - 1;</div><div class="line"><a name="l00205"></a><span class="lineno">  205</span>&#160;    pad_right += stride_width - 1;</div><div class="line"><a name="l00206"></a><span class="lineno">  206</span>&#160;  }</div><div class="line"><a name="l00207"></a><span class="lineno">  207</span>&#160;</div><div class="line"><a name="l00208"></a><span class="lineno">  208</span>&#160;  <a class="code" href="classtvm_1_1Array.html">Array&lt;PrimExpr&gt;</a> pad_before(std::vector&lt;PrimExpr&gt;(x-&gt;<a class="code" href="classtvm_1_1te_1_1TensorNode.html#a0ba732bc2def0d467854585752911351">shape</a>.size(), 0));</div><div class="line"><a name="l00209"></a><span class="lineno">  209</span>&#160;  pad_before.<a class="code" href="classtvm_1_1Array.html#ab3db968deb4be7a51767f22d267eb7af">Set</a>(height_axis, pad_top);</div><div class="line"><a name="l00210"></a><span class="lineno">  210</span>&#160;  pad_before.<a class="code" href="classtvm_1_1Array.html#ab3db968deb4be7a51767f22d267eb7af">Set</a>(width_axis, pad_left);</div><div class="line"><a name="l00211"></a><span class="lineno">  211</span>&#160;</div><div class="line"><a name="l00212"></a><span class="lineno">  212</span>&#160;  <a class="code" href="classtvm_1_1Array.html">Array&lt;PrimExpr&gt;</a> pad_after(std::vector&lt;PrimExpr&gt;(x-&gt;<a class="code" href="classtvm_1_1te_1_1TensorNode.html#a0ba732bc2def0d467854585752911351">shape</a>.size(), 0));</div><div class="line"><a name="l00213"></a><span class="lineno">  213</span>&#160;  pad_after.<a class="code" href="classtvm_1_1Array.html#ab3db968deb4be7a51767f22d267eb7af">Set</a>(height_axis, pad_bottom);</div><div class="line"><a name="l00214"></a><span class="lineno">  214</span>&#160;  pad_after.<a class="code" href="classtvm_1_1Array.html#ab3db968deb4be7a51767f22d267eb7af">Set</a>(width_axis, pad_right);</div><div class="line"><a name="l00215"></a><span class="lineno">  215</span>&#160;</div><div class="line"><a name="l00216"></a><span class="lineno">  216</span>&#160;  <span class="keyword">auto</span> out_height =</div><div class="line"><a name="l00217"></a><span class="lineno">  217</span>&#160;      <a class="code" href="namespacetvm_1_1tir.html#a923d1bb833c984008772782e90cda37a">tvm::tir::Simplify</a>((height - kernel_height + pad_top + pad_bottom) / stride_height + 1);</div><div class="line"><a name="l00218"></a><span class="lineno">  218</span>&#160;  <span class="keyword">auto</span> out_width =</div><div class="line"><a name="l00219"></a><span class="lineno">  219</span>&#160;      <a class="code" href="namespacetvm_1_1tir.html#a923d1bb833c984008772782e90cda37a">tvm::tir::Simplify</a>((width - kernel_width + pad_left + pad_right) / stride_width + 1);</div><div class="line"><a name="l00220"></a><span class="lineno">  220</span>&#160;</div><div class="line"><a name="l00221"></a><span class="lineno">  221</span>&#160;  <span class="keyword">auto</span> dheight = <a class="code" href="namespacetvm_1_1te.html#aae384e9b73c2271905486e4a74b69265">tvm::te::reduce_axis</a>(<a class="code" href="classtvm_1_1Range.html">Range</a>(0, kernel_height));</div><div class="line"><a name="l00222"></a><span class="lineno">  222</span>&#160;  <span class="keyword">auto</span> dwidth = <a class="code" href="namespacetvm_1_1te.html#aae384e9b73c2271905486e4a74b69265">tvm::te::reduce_axis</a>(<a class="code" href="classtvm_1_1Range.html">Range</a>(0, kernel_width));</div><div class="line"><a name="l00223"></a><span class="lineno">  223</span>&#160;</div><div class="line"><a name="l00224"></a><span class="lineno">  224</span>&#160;  <a class="code" href="classtvm_1_1Array.html">Array&lt;PrimExpr&gt;</a> out_shape = x-&gt;<a class="code" href="classtvm_1_1te_1_1TensorNode.html#a0ba732bc2def0d467854585752911351">shape</a>;</div><div class="line"><a name="l00225"></a><span class="lineno">  225</span>&#160;  out_shape.<a class="code" href="classtvm_1_1Array.html#ab3db968deb4be7a51767f22d267eb7af">Set</a>(height_axis, out_height);</div><div class="line"><a name="l00226"></a><span class="lineno">  226</span>&#160;  out_shape.<a class="code" href="classtvm_1_1Array.html#ab3db968deb4be7a51767f22d267eb7af">Set</a>(width_axis, out_width);</div><div class="line"><a name="l00227"></a><span class="lineno">  227</span>&#160;</div><div class="line"><a name="l00228"></a><span class="lineno">  228</span>&#160;  <span class="keyword">const</span> int64_t* padding_h0 = <a class="code" href="namespacetvm_1_1tir.html#acbe8f225faaf34c540194921a7ee6a66">as_const_int</a>(pad_top);</div><div class="line"><a name="l00229"></a><span class="lineno">  229</span>&#160;  <span class="keyword">const</span> int64_t* padding_w0 = <a class="code" href="namespacetvm_1_1tir.html#acbe8f225faaf34c540194921a7ee6a66">as_const_int</a>(pad_left);</div><div class="line"><a name="l00230"></a><span class="lineno">  230</span>&#160;  <span class="keyword">const</span> int64_t* padding_h1 = <a class="code" href="namespacetvm_1_1tir.html#acbe8f225faaf34c540194921a7ee6a66">as_const_int</a>(pad_bottom);</div><div class="line"><a name="l00231"></a><span class="lineno">  231</span>&#160;  <span class="keyword">const</span> int64_t* padding_w1 = <a class="code" href="namespacetvm_1_1tir.html#acbe8f225faaf34c540194921a7ee6a66">as_const_int</a>(pad_right);</div><div class="line"><a name="l00232"></a><span class="lineno">  232</span>&#160;  <span class="keyword">const</span> <span class="keywordtype">bool</span> do_pad = ((padding_h0 &amp;&amp; *padding_h0) || (padding_w0 &amp;&amp; *padding_w0)) ||</div><div class="line"><a name="l00233"></a><span class="lineno">  233</span>&#160;                      ((padding_h1 &amp;&amp; *padding_h1) || (padding_w1 &amp;&amp; *padding_w1));</div><div class="line"><a name="l00234"></a><span class="lineno">  234</span>&#160;</div><div class="line"><a name="l00235"></a><span class="lineno">  235</span>&#160;  <span class="keywordflow">if</span> (pool_type == <a class="code" href="namespacetopi_1_1nn.html#ac531cfce9c3a031fa25cfb6ed1f9b95ba3a406a1361a3c7ca311d3c514842c2f4">kMaxPool</a>) {</div><div class="line"><a name="l00236"></a><span class="lineno">  236</span>&#160;    <a class="code" href="classtvm_1_1Array.html">Array&lt;PrimExpr&gt;</a> ravel_shape{x-&gt;<a class="code" href="classtvm_1_1te_1_1TensorNode.html#a0ba732bc2def0d467854585752911351">shape</a>.begin(), x-&gt;<a class="code" href="classtvm_1_1te_1_1TensorNode.html#a0ba732bc2def0d467854585752911351">shape</a>.end()};</div><div class="line"><a name="l00237"></a><span class="lineno">  237</span>&#160;    ravel_shape.Set(height_axis, ravel_shape[height_axis] + pad_top + pad_bottom);</div><div class="line"><a name="l00238"></a><span class="lineno">  238</span>&#160;    ravel_shape.Set(width_axis, ravel_shape[width_axis] + pad_left + pad_right);</div><div class="line"><a name="l00239"></a><span class="lineno">  239</span>&#160;</div><div class="line"><a name="l00240"></a><span class="lineno">  240</span>&#160;    <span class="keyword">auto</span> windowh = <a class="code" href="namespacetvm_1_1te.html#aae384e9b73c2271905486e4a74b69265">tvm::te::reduce_axis</a>(</div><div class="line"><a name="l00241"></a><span class="lineno">  241</span>&#160;        <a class="code" href="classtvm_1_1Range.html">Range</a>(0, (kernel_height + stride_height - 1) / stride_height));</div><div class="line"><a name="l00242"></a><span class="lineno">  242</span>&#160;    <span class="keyword">auto</span> windoww = <a class="code" href="namespacetvm_1_1te.html#aae384e9b73c2271905486e4a74b69265">tvm::te::reduce_axis</a>(</div><div class="line"><a name="l00243"></a><span class="lineno">  243</span>&#160;        <a class="code" href="classtvm_1_1Range.html">Range</a>(0, (kernel_width + stride_width - 1) / stride_width));</div><div class="line"><a name="l00244"></a><span class="lineno">  244</span>&#160;</div><div class="line"><a name="l00245"></a><span class="lineno">  245</span>&#160;    <span class="keyword">auto</span> <a class="code" href="namespacetopi.html#a94f412c82e4225050328fae33a3342f2">argmax</a> = <a class="code" href="namespacetopi.html#af82f23bc79d3ecca9919b45568192d07">MakeArgmaxReducer</a>();</div><div class="line"><a name="l00246"></a><span class="lineno">  246</span>&#160;    <span class="keyword">auto</span> pad_x = do_pad ? <a class="code" href="namespacetopi.html#a7d9e2d0f526ff451b6df91c6a673f440">pad</a>(</div><div class="line"><a name="l00247"></a><span class="lineno">  247</span>&#160;        x, pad_before, pad_after, <a class="code" href="namespacetvm.html#a9c126a8dde0d4079713969ca574f172e">tvm::min_value</a>(x-&gt;<a class="code" href="classtvm_1_1te_1_1TensorNode.html#a4c0b6e32a09ab6ea6b869de45394294d">dtype</a>), <span class="stringliteral">&quot;pad_temp&quot;</span>) : x;</div><div class="line"><a name="l00248"></a><span class="lineno">  248</span>&#160;</div><div class="line"><a name="l00249"></a><span class="lineno">  249</span>&#160;    <span class="keyword">auto</span> mp_argmax =</div><div class="line"><a name="l00250"></a><span class="lineno">  250</span>&#160;        <a class="code" href="namespacetvm_1_1te.html#aeacae1afc9dd1267cbb5779f9daa4671">tvm::te::compute</a>(</div><div class="line"><a name="l00251"></a><span class="lineno">  251</span>&#160;            out_shape,</div><div class="line"><a name="l00252"></a><span class="lineno">  252</span>&#160;            [&amp;](<span class="keyword">const</span> <a class="code" href="classtvm_1_1Array.html">Array&lt;Var&gt;</a>&amp; inds) {</div><div class="line"><a name="l00253"></a><span class="lineno">  253</span>&#160;              <a class="code" href="classtvm_1_1Array.html">Array&lt;PrimExpr&gt;</a> window_inds{inds.<a class="code" href="classtvm_1_1Array.html#a5db0d3faad39ca865162e50d555a25fa">begin</a>(), inds.<a class="code" href="classtvm_1_1Array.html#a6f05e6a14eca3ea865da0f293b4a5325">end</a>()};</div><div class="line"><a name="l00254"></a><span class="lineno">  254</span>&#160;              window_inds.Set(height_axis, inds[height_axis] * stride_height + dheight);</div><div class="line"><a name="l00255"></a><span class="lineno">  255</span>&#160;              window_inds.Set(width_axis, inds[width_axis] * stride_width + dwidth);</div><div class="line"><a name="l00256"></a><span class="lineno">  256</span>&#160;              <span class="keyword">auto</span> idx = detail::RavelIndex(window_inds, ravel_shape);</div><div class="line"><a name="l00257"></a><span class="lineno">  257</span>&#160;              <span class="keywordflow">return</span> <a class="code" href="namespacetopi.html#a94f412c82e4225050328fae33a3342f2">argmax</a>({idx, pad_x(window_inds)}, {dheight, dwidth}, <span class="keyword">nullptr</span>);</div><div class="line"><a name="l00258"></a><span class="lineno">  258</span>&#160;            },</div><div class="line"><a name="l00259"></a><span class="lineno">  259</span>&#160;            <span class="stringliteral">&quot;maxpool_grad_argmax&quot;</span>, <a class="code" href="namespacetopi.html#aaf18db0af5abc7dd13818115bac402bc">kCommReduceIdx</a>);</div><div class="line"><a name="l00260"></a><span class="lineno">  260</span>&#160;</div><div class="line"><a name="l00261"></a><span class="lineno">  261</span>&#160;    <span class="keyword">auto</span> mp_inds = mp_argmax[0];</div><div class="line"><a name="l00262"></a><span class="lineno">  262</span>&#160;</div><div class="line"><a name="l00263"></a><span class="lineno">  263</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="namespacetvm_1_1te.html#aeacae1afc9dd1267cbb5779f9daa4671">tvm::te::compute</a>(</div><div class="line"><a name="l00264"></a><span class="lineno">  264</span>&#160;        x-&gt;<a class="code" href="classtvm_1_1te_1_1TensorNode.html#a0ba732bc2def0d467854585752911351">shape</a>,</div><div class="line"><a name="l00265"></a><span class="lineno">  265</span>&#160;        [&amp;](<span class="keyword">const</span> <a class="code" href="classtvm_1_1Array.html">Array&lt;Var&gt;</a>&amp; inds) {</div><div class="line"><a name="l00266"></a><span class="lineno">  266</span>&#160;          Array&lt;PrimExpr&gt; pad_inds {inds.begin(), inds.end()};</div><div class="line"><a name="l00267"></a><span class="lineno">  267</span>&#160;          pad_inds.Set(height_axis, pad_inds[height_axis] + pad_top);</div><div class="line"><a name="l00268"></a><span class="lineno">  268</span>&#160;          pad_inds.Set(width_axis, pad_inds[width_axis] + pad_left);</div><div class="line"><a name="l00269"></a><span class="lineno">  269</span>&#160;          <span class="keyword">auto</span> idx = detail::RavelIndex(pad_inds, ravel_shape);</div><div class="line"><a name="l00270"></a><span class="lineno">  270</span>&#160;</div><div class="line"><a name="l00271"></a><span class="lineno">  271</span>&#160;          <a class="code" href="classtvm_1_1Array.html">Array&lt;PrimExpr&gt;</a> out_idx {inds.<a class="code" href="classtvm_1_1Array.html#a5db0d3faad39ca865162e50d555a25fa">begin</a>(), inds.<a class="code" href="classtvm_1_1Array.html#a6f05e6a14eca3ea865da0f293b4a5325">end</a>()};</div><div class="line"><a name="l00272"></a><span class="lineno">  272</span>&#160;          out_idx.Set(height_axis, (inds[height_axis] + pad_top) / stride_height - windowh);</div><div class="line"><a name="l00273"></a><span class="lineno">  273</span>&#160;          out_idx.Set(width_axis, (inds[width_axis] + pad_left) / stride_width - windoww);</div><div class="line"><a name="l00274"></a><span class="lineno">  274</span>&#160;</div><div class="line"><a name="l00275"></a><span class="lineno">  275</span>&#160;          <a class="code" href="classtvm_1_1PrimExpr.html">PrimExpr</a> out_idx_lower_h = <a class="code" href="classtvm_1_1tir_1_1SelectNode.html#ae0809a88c56d20faceba05184b6e793b">tir::SelectNode::make</a>(</div><div class="line"><a name="l00276"></a><span class="lineno">  276</span>&#160;              pad_inds[height_axis] &lt; kernel_height, <a class="code" href="namespacetvm_1_1tir.html#a4ea566597880d04bd62fbec687e338b5">make_const</a>(DataType::DataType::Int(32), 0),</div><div class="line"><a name="l00277"></a><span class="lineno">  277</span>&#160;              (pad_inds[height_axis] - kernel_height) / stride_height + 1);</div><div class="line"><a name="l00278"></a><span class="lineno">  278</span>&#160;          <a class="code" href="classtvm_1_1PrimExpr.html">PrimExpr</a> out_idx_lower_w = <a class="code" href="classtvm_1_1tir_1_1SelectNode.html#ae0809a88c56d20faceba05184b6e793b">tir::SelectNode::make</a>(</div><div class="line"><a name="l00279"></a><span class="lineno">  279</span>&#160;              pad_inds[width_axis] &lt; kernel_width, <a class="code" href="namespacetvm_1_1tir.html#a4ea566597880d04bd62fbec687e338b5">make_const</a>(DataType::DataType::Int(32), 0),</div><div class="line"><a name="l00280"></a><span class="lineno">  280</span>&#160;              (pad_inds[width_axis] - kernel_width) / stride_width + 1);</div><div class="line"><a name="l00281"></a><span class="lineno">  281</span>&#160;</div><div class="line"><a name="l00282"></a><span class="lineno">  282</span>&#160;          <span class="keywordflow">return</span> <a class="code" href="namespacetvm.html#a5cea5eb708bfbfa08e285092e5afdc33">tvm::sum</a>(</div><div class="line"><a name="l00283"></a><span class="lineno">  283</span>&#160;              <a class="code" href="namespacetvm.html#ad400409d87dc337f8b5fe13e18d363f9">tvm::if_then_else</a>(<a class="code" href="classtvm_1_1tir_1_1AndNode.html#aeb51390ed2566af9393d94d915e56d50">tir::AndNode::make</a>(</div><div class="line"><a name="l00284"></a><span class="lineno">  284</span>&#160;                  <a class="code" href="classtvm_1_1tir_1_1AndNode.html#aeb51390ed2566af9393d94d915e56d50">tir::AndNode::make</a>(out_idx[height_axis] &gt;= out_idx_lower_h,</div><div class="line"><a name="l00285"></a><span class="lineno">  285</span>&#160;                                out_idx[width_axis] &gt;= out_idx_lower_w),</div><div class="line"><a name="l00286"></a><span class="lineno">  286</span>&#160;                  mp_inds(out_idx) == idx),</div><div class="line"><a name="l00287"></a><span class="lineno">  287</span>&#160;                  out_grad(out_idx), <a class="code" href="namespacetvm_1_1tir.html#a4ea566597880d04bd62fbec687e338b5">make_const</a>(x-&gt;<a class="code" href="classtvm_1_1te_1_1TensorNode.html#a4c0b6e32a09ab6ea6b869de45394294d">dtype</a>, 0)),</div><div class="line"><a name="l00288"></a><span class="lineno">  288</span>&#160;              {windowh, windoww});</div><div class="line"><a name="l00289"></a><span class="lineno">  289</span>&#160;        },</div><div class="line"><a name="l00290"></a><span class="lineno">  290</span>&#160;        <span class="stringliteral">&quot;T_pool_grad&quot;</span>, <span class="stringliteral">&quot;pool_grad_max&quot;</span>);</div><div class="line"><a name="l00291"></a><span class="lineno">  291</span>&#160;  } <span class="keywordflow">else</span> <span class="keywordflow">if</span> (pool_type == <a class="code" href="namespacetopi_1_1nn.html#ac531cfce9c3a031fa25cfb6ed1f9b95babbfb6c4315c8b57e558600af1515d3d8">kAvgPool</a>) {</div><div class="line"><a name="l00292"></a><span class="lineno">  292</span>&#160;    <span class="keyword">auto</span> windowh = <a class="code" href="namespacetvm_1_1te.html#aae384e9b73c2271905486e4a74b69265">tvm::te::reduce_axis</a>(</div><div class="line"><a name="l00293"></a><span class="lineno">  293</span>&#160;        <a class="code" href="classtvm_1_1Range.html">Range</a>(0, (kernel_height + stride_height - 1) / stride_height));</div><div class="line"><a name="l00294"></a><span class="lineno">  294</span>&#160;    <span class="keyword">auto</span> windoww = <a class="code" href="namespacetvm_1_1te.html#aae384e9b73c2271905486e4a74b69265">tvm::te::reduce_axis</a>(</div><div class="line"><a name="l00295"></a><span class="lineno">  295</span>&#160;        <a class="code" href="classtvm_1_1Range.html">Range</a>(0, (kernel_width + stride_width - 1) / stride_width));</div><div class="line"><a name="l00296"></a><span class="lineno">  296</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="namespacetvm_1_1te.html#aeacae1afc9dd1267cbb5779f9daa4671">tvm::te::compute</a>(</div><div class="line"><a name="l00297"></a><span class="lineno">  297</span>&#160;        x-&gt;shape,</div><div class="line"><a name="l00298"></a><span class="lineno">  298</span>&#160;        [&amp;](<span class="keyword">const</span> <a class="code" href="classtvm_1_1Array.html">Array&lt;Var&gt;</a>&amp; inds) {</div><div class="line"><a name="l00299"></a><span class="lineno">  299</span>&#160;          PrimExpr pad_h_idx = inds[height_axis] + pad_top;</div><div class="line"><a name="l00300"></a><span class="lineno">  300</span>&#160;          PrimExpr pad_w_idx = inds[width_axis] + pad_left;</div><div class="line"><a name="l00301"></a><span class="lineno">  301</span>&#160;</div><div class="line"><a name="l00302"></a><span class="lineno">  302</span>&#160;          <span class="comment">// output indices whose pooling windows cover current input element (can be out-of-bound)</span></div><div class="line"><a name="l00303"></a><span class="lineno">  303</span>&#160;          Array&lt;PrimExpr&gt; out_idx{inds.begin(), inds.end()};</div><div class="line"><a name="l00304"></a><span class="lineno">  304</span>&#160;          out_idx.Set(height_axis, (pad_h_idx / stride_height - windowh));</div><div class="line"><a name="l00305"></a><span class="lineno">  305</span>&#160;          out_idx.Set(width_axis, (pad_w_idx / stride_width - windoww));</div><div class="line"><a name="l00306"></a><span class="lineno">  306</span>&#160;</div><div class="line"><a name="l00307"></a><span class="lineno">  307</span>&#160;          <a class="code" href="classtvm_1_1PrimExpr.html">PrimExpr</a> out_idx_lower_h = <a class="code" href="classtvm_1_1tir_1_1SelectNode.html#ae0809a88c56d20faceba05184b6e793b">tir::SelectNode::make</a>(</div><div class="line"><a name="l00308"></a><span class="lineno">  308</span>&#160;              pad_h_idx &lt; kernel_height, <a class="code" href="namespacetvm_1_1tir.html#a4ea566597880d04bd62fbec687e338b5">make_const</a>(<a class="code" href="classtvm_1_1runtime_1_1DataType.html#ab45f13dd70d982d9f977c79b6f7fac98">DataType::Int</a>(32), 0),</div><div class="line"><a name="l00309"></a><span class="lineno">  309</span>&#160;              (pad_h_idx - kernel_height) / stride_height + 1);</div><div class="line"><a name="l00310"></a><span class="lineno">  310</span>&#160;          <a class="code" href="classtvm_1_1PrimExpr.html">PrimExpr</a> out_idx_lower_w = <a class="code" href="classtvm_1_1tir_1_1SelectNode.html#ae0809a88c56d20faceba05184b6e793b">tir::SelectNode::make</a>(</div><div class="line"><a name="l00311"></a><span class="lineno">  311</span>&#160;              pad_w_idx &lt; kernel_width, <a class="code" href="namespacetvm_1_1tir.html#a4ea566597880d04bd62fbec687e338b5">make_const</a>(<a class="code" href="classtvm_1_1runtime_1_1DataType.html#ab45f13dd70d982d9f977c79b6f7fac98">DataType::Int</a>(32), 0),</div><div class="line"><a name="l00312"></a><span class="lineno">  312</span>&#160;              (pad_w_idx - kernel_width) / stride_width + 1);</div><div class="line"><a name="l00313"></a><span class="lineno">  313</span>&#160;</div><div class="line"><a name="l00314"></a><span class="lineno">  314</span>&#160;          <a class="code" href="classtvm_1_1PrimExpr.html">PrimExpr</a> divide_factor;  <span class="comment">// number of pooled elements</span></div><div class="line"><a name="l00315"></a><span class="lineno">  315</span>&#160;          <span class="keywordflow">if</span> (count_include_pad) {</div><div class="line"><a name="l00316"></a><span class="lineno">  316</span>&#160;            divide_factor = kernel_height * kernel_width;</div><div class="line"><a name="l00317"></a><span class="lineno">  317</span>&#160;          } <span class="keywordflow">else</span> {</div><div class="line"><a name="l00318"></a><span class="lineno">  318</span>&#160;            <a class="code" href="classtvm_1_1PrimExpr.html">PrimExpr</a> h_start = out_idx[height_axis] * stride_height - pad_top;</div><div class="line"><a name="l00319"></a><span class="lineno">  319</span>&#160;            <a class="code" href="classtvm_1_1PrimExpr.html">PrimExpr</a> w_start = out_idx[width_axis] * stride_width - pad_left;</div><div class="line"><a name="l00320"></a><span class="lineno">  320</span>&#160;            <a class="code" href="classtvm_1_1PrimExpr.html">PrimExpr</a> h_end = <a class="code" href="classtvm_1_1tir_1_1BinaryOpNode.html#afb3a9f4de76865880cc9f19ebcc75ea0">tir::MinNode::make</a>(h_start + kernel_height, height);</div><div class="line"><a name="l00321"></a><span class="lineno">  321</span>&#160;            <a class="code" href="classtvm_1_1PrimExpr.html">PrimExpr</a> w_end = <a class="code" href="classtvm_1_1tir_1_1BinaryOpNode.html#afb3a9f4de76865880cc9f19ebcc75ea0">tir::MinNode::make</a>(w_start + kernel_width, width);</div><div class="line"><a name="l00322"></a><span class="lineno">  322</span>&#160;            h_start = <a class="code" href="classtvm_1_1tir_1_1BinaryOpNode.html#afb3a9f4de76865880cc9f19ebcc75ea0">tir::MaxNode::make</a>(h_start, <a class="code" href="namespacetvm_1_1tir.html#a4ea566597880d04bd62fbec687e338b5">make_const</a>(<a class="code" href="classtvm_1_1runtime_1_1DataType.html#ab45f13dd70d982d9f977c79b6f7fac98">DataType::Int</a>(32), 0));</div><div class="line"><a name="l00323"></a><span class="lineno">  323</span>&#160;            w_start = <a class="code" href="classtvm_1_1tir_1_1BinaryOpNode.html#afb3a9f4de76865880cc9f19ebcc75ea0">tir::MaxNode::make</a>(w_start, <a class="code" href="namespacetvm_1_1tir.html#a4ea566597880d04bd62fbec687e338b5">make_const</a>(<a class="code" href="classtvm_1_1runtime_1_1DataType.html#ab45f13dd70d982d9f977c79b6f7fac98">DataType::Int</a>(32), 0));</div><div class="line"><a name="l00324"></a><span class="lineno">  324</span>&#160;            divide_factor =</div><div class="line"><a name="l00325"></a><span class="lineno">  325</span>&#160;                <a class="code" href="classtvm_1_1tir_1_1BinaryOpNode.html#afb3a9f4de76865880cc9f19ebcc75ea0">tir::MaxNode::make</a>((h_end - h_start) * (w_end - w_start),</div><div class="line"><a name="l00326"></a><span class="lineno">  326</span>&#160;                              <a class="code" href="namespacetvm_1_1tir.html#a4ea566597880d04bd62fbec687e338b5">make_const</a>(<a class="code" href="classtvm_1_1runtime_1_1DataType.html#ab45f13dd70d982d9f977c79b6f7fac98">DataType::Int</a>(32), 1));</div><div class="line"><a name="l00327"></a><span class="lineno">  327</span>&#160;          }</div><div class="line"><a name="l00328"></a><span class="lineno">  328</span>&#160;          <span class="keywordflow">return</span> <a class="code" href="namespacetvm.html#a5cea5eb708bfbfa08e285092e5afdc33">tvm::sum</a>(<a class="code" href="namespacetvm.html#ad400409d87dc337f8b5fe13e18d363f9">tvm::if_then_else</a>(</div><div class="line"><a name="l00329"></a><span class="lineno">  329</span>&#160;              <a class="code" href="classtvm_1_1tir_1_1AndNode.html#aeb51390ed2566af9393d94d915e56d50">tir::AndNode::make</a>(</div><div class="line"><a name="l00330"></a><span class="lineno">  330</span>&#160;                <a class="code" href="classtvm_1_1tir_1_1AndNode.html#aeb51390ed2566af9393d94d915e56d50">tir::AndNode::make</a>(out_idx[height_axis] &gt;= out_idx_lower_h,</div><div class="line"><a name="l00331"></a><span class="lineno">  331</span>&#160;                              out_idx[height_axis] &lt; out_height),</div><div class="line"><a name="l00332"></a><span class="lineno">  332</span>&#160;                <a class="code" href="classtvm_1_1tir_1_1AndNode.html#aeb51390ed2566af9393d94d915e56d50">tir::AndNode::make</a>(out_idx[width_axis] &gt;= out_idx_lower_w,</div><div class="line"><a name="l00333"></a><span class="lineno">  333</span>&#160;                              out_idx[width_axis] &lt; out_width)),</div><div class="line"><a name="l00334"></a><span class="lineno">  334</span>&#160;              out_grad(out_idx) / divide_factor, <a class="code" href="namespacetvm_1_1tir.html#a4ea566597880d04bd62fbec687e338b5">make_const</a>(out_grad-&gt;dtype, 0)),</div><div class="line"><a name="l00335"></a><span class="lineno">  335</span>&#160;              {windowh, windoww});</div><div class="line"><a name="l00336"></a><span class="lineno">  336</span>&#160;        },</div><div class="line"><a name="l00337"></a><span class="lineno">  337</span>&#160;        <span class="stringliteral">&quot;T_pool_grad&quot;</span>, <span class="stringliteral">&quot;pool_grad_avg&quot;</span>);</div><div class="line"><a name="l00338"></a><span class="lineno">  338</span>&#160;  } <span class="keywordflow">else</span> {</div><div class="line"><a name="l00339"></a><span class="lineno">  339</span>&#160;    LOG(ERROR) &lt;&lt; <span class="stringliteral">&quot;Unrecognized pool_type: &quot;</span> &lt;&lt; pool_type;</div><div class="line"><a name="l00340"></a><span class="lineno">  340</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="classtvm_1_1te_1_1Tensor.html">Tensor</a>();</div><div class="line"><a name="l00341"></a><span class="lineno">  341</span>&#160;  }</div><div class="line"><a name="l00342"></a><span class="lineno">  342</span>&#160;}</div><div class="line"><a name="l00343"></a><span class="lineno">  343</span>&#160;</div><div class="line"><a name="l00344"></a><span class="lineno"><a class="line" href="namespacetopi_1_1nn.html#a2e81a7938a1e3f273e184e2373d9138d">  344</a></span>&#160;<span class="keyword">inline</span> <span class="keywordtype">bool</span> <a class="code" href="namespacetopi_1_1nn.html#a2e81a7938a1e3f273e184e2373d9138d">find_depth_height_width</a>(<span class="keyword">const</span> std::string&amp; layout,</div><div class="line"><a name="l00345"></a><span class="lineno">  345</span>&#160;                                    <span class="keywordtype">int</span>* depth_axis,</div><div class="line"><a name="l00346"></a><span class="lineno">  346</span>&#160;                                    <span class="keywordtype">int</span>* height_axis,</div><div class="line"><a name="l00347"></a><span class="lineno">  347</span>&#160;                                    <span class="keywordtype">int</span>* width_axis) {</div><div class="line"><a name="l00348"></a><span class="lineno">  348</span>&#160;  *depth_axis = -1, *height_axis = -1, *width_axis = -1;</div><div class="line"><a name="l00349"></a><span class="lineno">  349</span>&#160;  <span class="keywordtype">int</span> curr_idx = 0;</div><div class="line"><a name="l00350"></a><span class="lineno">  350</span>&#160;  <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; layout.size(); ++i) {</div><div class="line"><a name="l00351"></a><span class="lineno">  351</span>&#160;    <span class="keywordflow">if</span> ((layout[i] &gt;= <span class="charliteral">&#39;A&#39;</span> &amp;&amp; layout[i] &lt;= <span class="charliteral">&#39;Z&#39;</span>) ||</div><div class="line"><a name="l00352"></a><span class="lineno">  352</span>&#160;        (layout[i] &gt;= <span class="charliteral">&#39;a&#39;</span> &amp;&amp; layout[i] &lt;= <span class="charliteral">&#39;z&#39;</span>)) {</div><div class="line"><a name="l00353"></a><span class="lineno">  353</span>&#160;      <span class="keywordflow">if</span> (layout[i] == <span class="charliteral">&#39;D&#39;</span>) {</div><div class="line"><a name="l00354"></a><span class="lineno">  354</span>&#160;        <span class="keywordflow">if</span> (*depth_axis != -1) <span class="keywordflow">return</span> <span class="keyword">false</span>;</div><div class="line"><a name="l00355"></a><span class="lineno">  355</span>&#160;        *depth_axis = curr_idx;</div><div class="line"><a name="l00356"></a><span class="lineno">  356</span>&#160;      } <span class="keywordflow">else</span> <span class="keywordflow">if</span> (layout[i] == <span class="charliteral">&#39;H&#39;</span>) {</div><div class="line"><a name="l00357"></a><span class="lineno">  357</span>&#160;        <span class="keywordflow">if</span> (*height_axis != -1) <span class="keywordflow">return</span> <span class="keyword">false</span>;</div><div class="line"><a name="l00358"></a><span class="lineno">  358</span>&#160;        *height_axis = curr_idx;</div><div class="line"><a name="l00359"></a><span class="lineno">  359</span>&#160;      } <span class="keywordflow">else</span> <span class="keywordflow">if</span> (layout[i] == <span class="charliteral">&#39;W&#39;</span>) {</div><div class="line"><a name="l00360"></a><span class="lineno">  360</span>&#160;        <span class="keywordflow">if</span> (*width_axis != -1) <span class="keywordflow">return</span> <span class="keyword">false</span>;</div><div class="line"><a name="l00361"></a><span class="lineno">  361</span>&#160;        *width_axis = curr_idx;</div><div class="line"><a name="l00362"></a><span class="lineno">  362</span>&#160;      } <span class="keywordflow">else</span> <span class="keywordflow">if</span> (layout[i] == <span class="charliteral">&#39;d&#39;</span> || layout[i] == <span class="charliteral">&#39;h&#39;</span> || layout[i] == <span class="charliteral">&#39;w&#39;</span>) {</div><div class="line"><a name="l00363"></a><span class="lineno">  363</span>&#160;        <span class="comment">// do not support split on height or width, e.g., NCHW16w</span></div><div class="line"><a name="l00364"></a><span class="lineno">  364</span>&#160;        <span class="keywordflow">return</span> <span class="keyword">false</span>;</div><div class="line"><a name="l00365"></a><span class="lineno">  365</span>&#160;      }</div><div class="line"><a name="l00366"></a><span class="lineno">  366</span>&#160;      ++curr_idx;</div><div class="line"><a name="l00367"></a><span class="lineno">  367</span>&#160;    }</div><div class="line"><a name="l00368"></a><span class="lineno">  368</span>&#160;  }</div><div class="line"><a name="l00369"></a><span class="lineno">  369</span>&#160;  <span class="keywordflow">if</span> (*depth_axis == -1 || *height_axis == -1 || *width_axis == -1) <span class="keywordflow">return</span> <span class="keyword">false</span>;</div><div class="line"><a name="l00370"></a><span class="lineno">  370</span>&#160;  <span class="keywordflow">return</span> <span class="keyword">true</span>;</div><div class="line"><a name="l00371"></a><span class="lineno">  371</span>&#160;}</div><div class="line"><a name="l00372"></a><span class="lineno">  372</span>&#160;</div><div class="line"><a name="l00373"></a><span class="lineno"><a class="line" href="namespacetopi_1_1nn.html#a428e0ba6800ef89b8c1f97f0245e244d">  373</a></span>&#160;<span class="keyword">inline</span> <span class="keywordtype">bool</span> <a class="code" href="namespacetopi_1_1nn.html#a428e0ba6800ef89b8c1f97f0245e244d">find_height_width</a>(<span class="keyword">const</span> std::string&amp; layout,</div><div class="line"><a name="l00374"></a><span class="lineno">  374</span>&#160;                              <span class="keywordtype">int</span>* height_axis,</div><div class="line"><a name="l00375"></a><span class="lineno">  375</span>&#160;                              <span class="keywordtype">int</span>* width_axis) {</div><div class="line"><a name="l00376"></a><span class="lineno">  376</span>&#160;  <span class="keywordtype">int</span> dummy;</div><div class="line"><a name="l00377"></a><span class="lineno">  377</span>&#160;  CHECK_EQ(<a class="code" href="namespacetopi_1_1nn.html#a2e81a7938a1e3f273e184e2373d9138d">find_depth_height_width</a>(layout, &amp;dummy, height_axis, width_axis),  <span class="keyword">false</span>);</div><div class="line"><a name="l00378"></a><span class="lineno">  378</span>&#160;  <span class="keywordflow">if</span> (*height_axis != -1 &amp;&amp; *width_axis != -1) {</div><div class="line"><a name="l00379"></a><span class="lineno">  379</span>&#160;    <span class="keywordflow">return</span> <span class="keyword">true</span>;</div><div class="line"><a name="l00380"></a><span class="lineno">  380</span>&#160;  }</div><div class="line"><a name="l00381"></a><span class="lineno">  381</span>&#160;  <span class="keywordflow">return</span> <span class="keyword">false</span>;</div><div class="line"><a name="l00382"></a><span class="lineno">  382</span>&#160;}</div><div class="line"><a name="l00383"></a><span class="lineno">  383</span>&#160;</div><div class="line"><a name="l00384"></a><span class="lineno"><a class="line" href="namespacetopi_1_1nn.html#ab1f1f9f86723b30bb8997615e1d63ca8">  384</a></span>&#160;<span class="keyword">inline</span> <span class="keywordtype">bool</span> <a class="code" href="namespacetopi_1_1nn.html#ab1f1f9f86723b30bb8997615e1d63ca8">find_width</a>(<span class="keyword">const</span> std::string&amp; layout,</div><div class="line"><a name="l00385"></a><span class="lineno">  385</span>&#160;                       <span class="keywordtype">int</span>* width_axis) {</div><div class="line"><a name="l00386"></a><span class="lineno">  386</span>&#160;  <span class="keywordtype">int</span> dummy;</div><div class="line"><a name="l00387"></a><span class="lineno">  387</span>&#160;  CHECK_EQ(<a class="code" href="namespacetopi_1_1nn.html#a2e81a7938a1e3f273e184e2373d9138d">find_depth_height_width</a>(layout, &amp;dummy, &amp;dummy, width_axis),  <span class="keyword">false</span>);</div><div class="line"><a name="l00388"></a><span class="lineno">  388</span>&#160;  <span class="keywordflow">if</span> (*width_axis != -1) {</div><div class="line"><a name="l00389"></a><span class="lineno">  389</span>&#160;    <span class="keywordflow">return</span> <span class="keyword">true</span>;</div><div class="line"><a name="l00390"></a><span class="lineno">  390</span>&#160;  }</div><div class="line"><a name="l00391"></a><span class="lineno">  391</span>&#160;  <span class="keywordflow">return</span> <span class="keyword">false</span>;</div><div class="line"><a name="l00392"></a><span class="lineno">  392</span>&#160;}</div><div class="line"><a name="l00393"></a><span class="lineno">  393</span>&#160;</div><div class="line"><a name="l00423"></a><span class="lineno"><a class="line" href="namespacetopi_1_1nn.html#ac1708b3aa1a677f56a4063a568945d98">  423</a></span>&#160;<span class="keyword">inline</span> <a class="code" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> <a class="code" href="namespacetopi_1_1nn.html#ac1708b3aa1a677f56a4063a568945d98">pool</a>(<span class="keyword">const</span> <a class="code" href="classtvm_1_1te_1_1Tensor.html">Tensor</a>&amp; x,</div><div class="line"><a name="l00424"></a><span class="lineno">  424</span>&#160;                   <span class="keyword">const</span> <a class="code" href="classtvm_1_1Array.html">Array&lt;PrimExpr&gt;</a>&amp; kernel_size,</div><div class="line"><a name="l00425"></a><span class="lineno">  425</span>&#160;                   <span class="keyword">const</span> <a class="code" href="classtvm_1_1Array.html">Array&lt;PrimExpr&gt;</a>&amp; stride_size,</div><div class="line"><a name="l00426"></a><span class="lineno">  426</span>&#160;                   <span class="keyword">const</span> <a class="code" href="classtvm_1_1Array.html">Array&lt;PrimExpr&gt;</a>&amp; padding_size,</div><div class="line"><a name="l00427"></a><span class="lineno">  427</span>&#160;                   <a class="code" href="namespacetopi_1_1nn.html#ac531cfce9c3a031fa25cfb6ed1f9b95b">PoolType</a> pool_type,</div><div class="line"><a name="l00428"></a><span class="lineno">  428</span>&#160;                   <span class="keywordtype">bool</span> ceil_mode,</div><div class="line"><a name="l00429"></a><span class="lineno">  429</span>&#160;                   <span class="keyword">const</span> std::string&amp; layout = <span class="stringliteral">&quot;NCHW&quot;</span>,</div><div class="line"><a name="l00430"></a><span class="lineno">  430</span>&#160;                   <span class="keywordtype">bool</span> count_include_pad = <span class="keyword">true</span>) {</div><div class="line"><a name="l00431"></a><span class="lineno">  431</span>&#160;  <span class="keywordtype">int</span> height_axis = -1, width_axis = -1;</div><div class="line"><a name="l00432"></a><span class="lineno">  432</span>&#160;  CHECK(<a class="code" href="namespacetopi_1_1nn.html#a428e0ba6800ef89b8c1f97f0245e244d">find_height_width</a>(layout, &amp;height_axis, &amp;width_axis))</div><div class="line"><a name="l00433"></a><span class="lineno">  433</span>&#160;    &lt;&lt; <span class="stringliteral">&quot;Unsupported layout &quot;</span> &lt;&lt; layout;</div><div class="line"><a name="l00434"></a><span class="lineno">  434</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="namespacetopi_1_1nn.html#ad51533b09956d7bc8de2537adf3b6b77">pool_impl</a>(x, kernel_size, stride_size, padding_size,</div><div class="line"><a name="l00435"></a><span class="lineno">  435</span>&#160;                   pool_type, ceil_mode, height_axis, width_axis,</div><div class="line"><a name="l00436"></a><span class="lineno">  436</span>&#160;                   count_include_pad);</div><div class="line"><a name="l00437"></a><span class="lineno">  437</span>&#160;}</div><div class="line"><a name="l00438"></a><span class="lineno">  438</span>&#160;</div><div class="line"><a name="l00469"></a><span class="lineno"><a class="line" href="namespacetopi_1_1nn.html#a4f915567f195ade4a17743a5e7654e88">  469</a></span>&#160;<span class="keyword">inline</span> <a class="code" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> <a class="code" href="namespacetopi_1_1nn.html#a4f915567f195ade4a17743a5e7654e88">pool_grad</a>(<span class="keyword">const</span> <a class="code" href="classtvm_1_1te_1_1Tensor.html">Tensor</a>&amp; out_grad, <span class="keyword">const</span> <a class="code" href="classtvm_1_1te_1_1Tensor.html">Tensor</a>&amp; x, <span class="keyword">const</span> <a class="code" href="classtvm_1_1Array.html">Array&lt;PrimExpr&gt;</a>&amp; kernel_size,</div><div class="line"><a name="l00470"></a><span class="lineno">  470</span>&#160;                        <span class="keyword">const</span> <a class="code" href="classtvm_1_1Array.html">Array&lt;PrimExpr&gt;</a>&amp; stride_size, <span class="keyword">const</span> <a class="code" href="classtvm_1_1Array.html">Array&lt;PrimExpr&gt;</a>&amp; padding_size,</div><div class="line"><a name="l00471"></a><span class="lineno">  471</span>&#160;                        <a class="code" href="namespacetopi_1_1nn.html#ac531cfce9c3a031fa25cfb6ed1f9b95b">PoolType</a> pool_type, <span class="keywordtype">bool</span> ceil_mode, <span class="keyword">const</span> std::string&amp; layout = <span class="stringliteral">&quot;NCHW&quot;</span>,</div><div class="line"><a name="l00472"></a><span class="lineno">  472</span>&#160;                        <span class="keywordtype">bool</span> count_include_pad = <span class="keyword">true</span>) {</div><div class="line"><a name="l00473"></a><span class="lineno">  473</span>&#160;  <span class="keywordtype">int</span> height_axis = -1, width_axis = -1;</div><div class="line"><a name="l00474"></a><span class="lineno">  474</span>&#160;  CHECK(<a class="code" href="namespacetopi_1_1nn.html#a428e0ba6800ef89b8c1f97f0245e244d">find_height_width</a>(layout, &amp;height_axis, &amp;width_axis)) &lt;&lt; <span class="stringliteral">&quot;Unsupported layout &quot;</span> &lt;&lt; layout;</div><div class="line"><a name="l00475"></a><span class="lineno">  475</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="namespacetopi_1_1nn.html#af2c25e8b3ab3cac1c2896cb750838337">pool_grad_impl</a>(out_grad, x, kernel_size, stride_size, padding_size, pool_type, ceil_mode,</div><div class="line"><a name="l00476"></a><span class="lineno">  476</span>&#160;                        height_axis, width_axis, count_include_pad);</div><div class="line"><a name="l00477"></a><span class="lineno">  477</span>&#160;}</div><div class="line"><a name="l00478"></a><span class="lineno">  478</span>&#160;</div><div class="line"><a name="l00479"></a><span class="lineno"><a class="line" href="namespacetopi_1_1nn.html#a91b52c68356d23123474ebf10f9b0140">  479</a></span>&#160;<span class="keyword">inline</span> <a class="code" href="classtvm_1_1PrimExpr.html">PrimExpr</a> <a class="code" href="namespacetopi_1_1nn.html#a91b52c68356d23123474ebf10f9b0140">start_index</a>(<span class="keyword">const</span> <a class="code" href="classtvm_1_1tir_1_1Var.html">Var</a>&amp; out_index,</div><div class="line"><a name="l00480"></a><span class="lineno">  480</span>&#160;                        <span class="keyword">const</span> <a class="code" href="classtvm_1_1PrimExpr.html">PrimExpr</a>&amp; odim,</div><div class="line"><a name="l00481"></a><span class="lineno">  481</span>&#160;                        <span class="keyword">const</span> <a class="code" href="classtvm_1_1PrimExpr.html">PrimExpr</a>&amp; idim) {</div><div class="line"><a name="l00482"></a><span class="lineno">  482</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="namespacetvm.html#a8203d70a5ebf3532370264b000d0d276">indexdiv</a>(out_index * idim, odim);</div><div class="line"><a name="l00483"></a><span class="lineno">  483</span>&#160;}</div><div class="line"><a name="l00484"></a><span class="lineno">  484</span>&#160;</div><div class="line"><a name="l00485"></a><span class="lineno"><a class="line" href="namespacetopi_1_1nn.html#aadbaaec56f0b485262bf5199bbe3dcb3">  485</a></span>&#160;<span class="keyword">inline</span> <a class="code" href="classtvm_1_1PrimExpr.html">PrimExpr</a> <a class="code" href="namespacetopi_1_1nn.html#aadbaaec56f0b485262bf5199bbe3dcb3">end_index</a>(<span class="keyword">const</span> <a class="code" href="classtvm_1_1tir_1_1Var.html">Var</a>&amp; out_index,</div><div class="line"><a name="l00486"></a><span class="lineno">  486</span>&#160;                      <span class="keyword">const</span> <a class="code" href="classtvm_1_1PrimExpr.html">PrimExpr</a>&amp; odim,</div><div class="line"><a name="l00487"></a><span class="lineno">  487</span>&#160;                      <span class="keyword">const</span> <a class="code" href="classtvm_1_1PrimExpr.html">PrimExpr</a>&amp; idim) {</div><div class="line"><a name="l00488"></a><span class="lineno">  488</span>&#160;  <a class="code" href="classtvm_1_1PrimExpr.html">PrimExpr</a> tmp = <a class="code" href="namespacetvm.html#a8203d70a5ebf3532370264b000d0d276">indexdiv</a>((out_index + 1) * idim, odim);</div><div class="line"><a name="l00489"></a><span class="lineno">  489</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="classtvm_1_1tir_1_1SelectNode.html#ae0809a88c56d20faceba05184b6e793b">tvm::tir::SelectNode::make</a>(<a class="code" href="namespacetvm.html#a857781b7243b2f90018f7fe6baf9c30e">indexmod</a>((out_index + 1) * idim, odim) == 0,</div><div class="line"><a name="l00490"></a><span class="lineno">  490</span>&#160;                               tmp, tmp + 1);</div><div class="line"><a name="l00491"></a><span class="lineno">  491</span>&#160;}</div><div class="line"><a name="l00492"></a><span class="lineno">  492</span>&#160;</div><div class="line"><a name="l00503"></a><span class="lineno"><a class="line" href="namespacetopi_1_1nn.html#ad4f34df5cfa8dc75843116bc39f06066">  503</a></span>&#160;<span class="keyword">inline</span> <a class="code" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> <a class="code" href="namespacetopi_1_1nn.html#ad4f34df5cfa8dc75843116bc39f06066">adaptive_pool_impl</a>(<span class="keyword">const</span> <a class="code" href="classtvm_1_1te_1_1Tensor.html">Tensor</a>&amp; x,</div><div class="line"><a name="l00504"></a><span class="lineno">  504</span>&#160;                                 <span class="keyword">const</span> <a class="code" href="classtvm_1_1Array.html">Array&lt;PrimExpr&gt;</a>&amp; output_size,</div><div class="line"><a name="l00505"></a><span class="lineno">  505</span>&#160;                                 <a class="code" href="namespacetopi_1_1nn.html#ac531cfce9c3a031fa25cfb6ed1f9b95b">PoolType</a> pool_type,</div><div class="line"><a name="l00506"></a><span class="lineno">  506</span>&#160;                                 <span class="keyword">const</span> std::vector&lt;int&gt;&amp; axes) {</div><div class="line"><a name="l00507"></a><span class="lineno">  507</span>&#160;  <span class="keyword">const</span> <span class="keyword">auto</span> n_dim = output_size.<a class="code" href="classtvm_1_1Array.html#a6c150ee7d3e46117b099d2052b19aec5">size</a>();</div><div class="line"><a name="l00508"></a><span class="lineno">  508</span>&#160;  CHECK_EQ(axes.size(), n_dim) &lt;&lt; <span class="stringliteral">&quot;The number of axes not equal to the in/out dimension&quot;</span>;</div><div class="line"><a name="l00509"></a><span class="lineno">  509</span>&#160;</div><div class="line"><a name="l00510"></a><span class="lineno">  510</span>&#160;  <a class="code" href="classtvm_1_1Array.html">Array&lt;PrimExpr&gt;</a> out_shape = x-&gt;<a class="code" href="classtvm_1_1te_1_1TensorNode.html#a0ba732bc2def0d467854585752911351">shape</a>;</div><div class="line"><a name="l00511"></a><span class="lineno">  511</span>&#160;  <a class="code" href="classtvm_1_1Array.html">Array&lt;PrimExpr&gt;</a> in_size, out_size;</div><div class="line"><a name="l00512"></a><span class="lineno">  512</span>&#160;  <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; n_dim; ++i) {</div><div class="line"><a name="l00513"></a><span class="lineno">  513</span>&#160;    in_size.<a class="code" href="classtvm_1_1Array.html#a24d5ac1f6730d46cb1a6d16729f0a7bb">push_back</a>(x-&gt;<a class="code" href="classtvm_1_1te_1_1TensorNode.html#a0ba732bc2def0d467854585752911351">shape</a>[axes[i]]);</div><div class="line"><a name="l00514"></a><span class="lineno">  514</span>&#160;    out_size.<a class="code" href="classtvm_1_1Array.html#a24d5ac1f6730d46cb1a6d16729f0a7bb">push_back</a>(<a class="code" href="namespacetopi.html#acfc3df84ca997ccac0f57d50e96c1c06">cast</a>(<a class="code" href="classtvm_1_1runtime_1_1DataType.html#ab45f13dd70d982d9f977c79b6f7fac98">DataType::Int</a>(32), output_size[i]));</div><div class="line"><a name="l00515"></a><span class="lineno">  515</span>&#160;    out_shape.Set(axes[i], out_size[i]);</div><div class="line"><a name="l00516"></a><span class="lineno">  516</span>&#160;  }</div><div class="line"><a name="l00517"></a><span class="lineno">  517</span>&#160;</div><div class="line"><a name="l00518"></a><span class="lineno">  518</span>&#160;  <span class="keyword">auto</span> get_iter_vars = [=](<span class="keyword">const</span> <a class="code" href="classtvm_1_1Array.html">Array&lt;Var&gt;</a>&amp; output, <span class="keywordtype">bool</span> reduce_indices) {</div><div class="line"><a name="l00519"></a><span class="lineno">  519</span>&#160;    <a class="code" href="classtvm_1_1Array.html">Array&lt;PrimExpr&gt;</a> indices;</div><div class="line"><a name="l00520"></a><span class="lineno">  520</span>&#160;    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; output.<a class="code" href="classtvm_1_1Array.html#a6c150ee7d3e46117b099d2052b19aec5">size</a>(); ++i) indices.<a class="code" href="classtvm_1_1Array.html#a24d5ac1f6730d46cb1a6d16729f0a7bb">push_back</a>(output[i]);</div><div class="line"><a name="l00521"></a><span class="lineno">  521</span>&#160;    <a class="code" href="classtvm_1_1Array.html">Array&lt;tir::IterVar&gt;</a> reduce_axes;</div><div class="line"><a name="l00522"></a><span class="lineno">  522</span>&#160;    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; n_dim; ++i) {</div><div class="line"><a name="l00523"></a><span class="lineno">  523</span>&#160;      <span class="keyword">auto</span> i_start = <a class="code" href="namespacetopi_1_1nn.html#a91b52c68356d23123474ebf10f9b0140">start_index</a>(output[axes[i]], out_size[i], in_size[i]);</div><div class="line"><a name="l00524"></a><span class="lineno">  524</span>&#160;      <span class="keyword">auto</span> i_end = <a class="code" href="namespacetopi_1_1nn.html#aadbaaec56f0b485262bf5199bbe3dcb3">end_index</a>(output[axes[i]], out_size[i], in_size[i]);</div><div class="line"><a name="l00525"></a><span class="lineno">  525</span>&#160;      <span class="keyword">auto</span> rv_name = <span class="stringliteral">&quot;rv&quot;</span> + std::to_string(i);</div><div class="line"><a name="l00526"></a><span class="lineno">  526</span>&#160;      <span class="keyword">auto</span> rv_axis = <a class="code" href="namespacetvm_1_1te.html#aae384e9b73c2271905486e4a74b69265">tvm::te::reduce_axis</a>(<a class="code" href="classtvm_1_1Range.html">Range</a>(0, i_end - i_start), rv_name);</div><div class="line"><a name="l00527"></a><span class="lineno">  527</span>&#160;      reduce_axes.<a class="code" href="classtvm_1_1Array.html#a24d5ac1f6730d46cb1a6d16729f0a7bb">push_back</a>(rv_axis);</div><div class="line"><a name="l00528"></a><span class="lineno">  528</span>&#160;      <span class="keywordflow">if</span> (reduce_indices) {</div><div class="line"><a name="l00529"></a><span class="lineno">  529</span>&#160;        indices.<a class="code" href="classtvm_1_1Array.html#ab3db968deb4be7a51767f22d267eb7af">Set</a>(axes[i], i_start + rv_axis);</div><div class="line"><a name="l00530"></a><span class="lineno">  530</span>&#160;      }</div><div class="line"><a name="l00531"></a><span class="lineno">  531</span>&#160;    }</div><div class="line"><a name="l00532"></a><span class="lineno">  532</span>&#160;    <span class="keywordflow">return</span> std::make_tuple(indices, reduce_axes);</div><div class="line"><a name="l00533"></a><span class="lineno">  533</span>&#160;  };</div><div class="line"><a name="l00534"></a><span class="lineno">  534</span>&#160;</div><div class="line"><a name="l00535"></a><span class="lineno">  535</span>&#160;  <span class="keywordflow">if</span> (pool_type == <a class="code" href="namespacetopi_1_1nn.html#ac531cfce9c3a031fa25cfb6ed1f9b95ba3a406a1361a3c7ca311d3c514842c2f4">kMaxPool</a>) {</div><div class="line"><a name="l00536"></a><span class="lineno">  536</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="namespacetvm_1_1te.html#aeacae1afc9dd1267cbb5779f9daa4671">tvm::te::compute</a>(out_shape, [&amp;](<span class="keyword">const</span> <a class="code" href="classtvm_1_1Array.html">Array&lt;Var&gt;</a>&amp; output) {</div><div class="line"><a name="l00537"></a><span class="lineno">  537</span>&#160;      <a class="code" href="classtvm_1_1Array.html">Array&lt;PrimExpr&gt;</a> indices;</div><div class="line"><a name="l00538"></a><span class="lineno">  538</span>&#160;      <a class="code" href="classtvm_1_1Array.html">Array&lt;tir::IterVar&gt;</a> reduce_axes;</div><div class="line"><a name="l00539"></a><span class="lineno">  539</span>&#160;      std::tie(indices, reduce_axes) = get_iter_vars(output, <span class="keyword">true</span>);</div><div class="line"><a name="l00540"></a><span class="lineno">  540</span>&#160;      <span class="keywordflow">return</span> <a class="code" href="namespacetvm.html#ab49bad0808ba033343e72ba37b39af2e">tvm::max</a>(x(indices), reduce_axes);  <span class="comment">// NOLINT(*)</span></div><div class="line"><a name="l00541"></a><span class="lineno">  541</span>&#160;    }, <span class="stringliteral">&quot;tensor&quot;</span>, <span class="stringliteral">&quot;adaptive_pool_max&quot;</span>);</div><div class="line"><a name="l00542"></a><span class="lineno">  542</span>&#160;  } <span class="keywordflow">else</span> <span class="keywordflow">if</span> (pool_type == <a class="code" href="namespacetopi_1_1nn.html#ac531cfce9c3a031fa25cfb6ed1f9b95babbfb6c4315c8b57e558600af1515d3d8">kAvgPool</a>) {</div><div class="line"><a name="l00543"></a><span class="lineno">  543</span>&#160;    <span class="keyword">auto</span> pool_sum = <a class="code" href="namespacetvm_1_1te.html#aeacae1afc9dd1267cbb5779f9daa4671">tvm::te::compute</a>(out_shape, [&amp;](<span class="keyword">const</span> <a class="code" href="classtvm_1_1Array.html">Array&lt;Var&gt;</a>&amp; output) {</div><div class="line"><a name="l00544"></a><span class="lineno">  544</span>&#160;      <a class="code" href="classtvm_1_1Array.html">Array&lt;PrimExpr&gt;</a> indices;</div><div class="line"><a name="l00545"></a><span class="lineno">  545</span>&#160;      <a class="code" href="classtvm_1_1Array.html">Array&lt;tir::IterVar&gt;</a> reduce_axes;</div><div class="line"><a name="l00546"></a><span class="lineno">  546</span>&#160;      std::tie(indices, reduce_axes) = get_iter_vars(output, <span class="keyword">true</span>);</div><div class="line"><a name="l00547"></a><span class="lineno">  547</span>&#160;      <span class="keywordflow">return</span> <a class="code" href="namespacetvm.html#a5cea5eb708bfbfa08e285092e5afdc33">tvm::sum</a>(x(indices), reduce_axes);</div><div class="line"><a name="l00548"></a><span class="lineno">  548</span>&#160;    }, <span class="stringliteral">&quot;tensor&quot;</span>, <span class="stringliteral">&quot;adaptive_pool_sum&quot;</span>);</div><div class="line"><a name="l00549"></a><span class="lineno">  549</span>&#160;</div><div class="line"><a name="l00550"></a><span class="lineno">  550</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="namespacetvm_1_1te.html#aeacae1afc9dd1267cbb5779f9daa4671">tvm::te::compute</a>(out_shape, [&amp;](<span class="keyword">const</span> <a class="code" href="classtvm_1_1Array.html">Array&lt;Var&gt;</a>&amp; output) {</div><div class="line"><a name="l00551"></a><span class="lineno">  551</span>&#160;      <a class="code" href="classtvm_1_1Array.html">Array&lt;PrimExpr&gt;</a> indices;</div><div class="line"><a name="l00552"></a><span class="lineno">  552</span>&#160;      <a class="code" href="classtvm_1_1Array.html">Array&lt;tir::IterVar&gt;</a> reduce_axes;</div><div class="line"><a name="l00553"></a><span class="lineno">  553</span>&#160;      std::tie(indices, reduce_axes) = get_iter_vars(output, <span class="keyword">false</span>);</div><div class="line"><a name="l00554"></a><span class="lineno">  554</span>&#160;</div><div class="line"><a name="l00555"></a><span class="lineno">  555</span>&#160;      <a class="code" href="classtvm_1_1PrimExpr.html">PrimExpr</a> divide_factor = <a class="code" href="namespacetvm.html#aa058caeda9deceda3d6ffeda347be442">tvm::cast</a>(x-&gt;<a class="code" href="classtvm_1_1te_1_1TensorNode.html#a4c0b6e32a09ab6ea6b869de45394294d">dtype</a>, 1);</div><div class="line"><a name="l00556"></a><span class="lineno">  556</span>&#160;      <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; n_dim; ++i) {</div><div class="line"><a name="l00557"></a><span class="lineno">  557</span>&#160;        divide_factor *= <a class="code" href="namespacetvm.html#aa058caeda9deceda3d6ffeda347be442">tvm::cast</a>(x-&gt;<a class="code" href="classtvm_1_1te_1_1TensorNode.html#a4c0b6e32a09ab6ea6b869de45394294d">dtype</a>, reduce_axes[i]-&gt;dom-&gt;extent);</div><div class="line"><a name="l00558"></a><span class="lineno">  558</span>&#160;      }</div><div class="line"><a name="l00559"></a><span class="lineno">  559</span>&#160;</div><div class="line"><a name="l00560"></a><span class="lineno">  560</span>&#160;      <span class="keywordflow">return</span> <a class="code" href="namespacetvm.html#a40fcc9952e1ff01a76f3b75dbd368fc1">div</a>(pool_sum(indices), divide_factor);</div><div class="line"><a name="l00561"></a><span class="lineno">  561</span>&#160;    }, <span class="stringliteral">&quot;tensor&quot;</span>, <a class="code" href="namespacetopi.html#ac1b34ed59d38a5f5338bee6b2cad42be">kElementWise</a>);</div><div class="line"><a name="l00562"></a><span class="lineno">  562</span>&#160;  } <span class="keywordflow">else</span> {</div><div class="line"><a name="l00563"></a><span class="lineno">  563</span>&#160;    LOG(ERROR) &lt;&lt; <span class="stringliteral">&quot;Unrecognized pool_type: &quot;</span> &lt;&lt; pool_type;</div><div class="line"><a name="l00564"></a><span class="lineno">  564</span>&#160;    <span class="keywordflow">return</span> x;</div><div class="line"><a name="l00565"></a><span class="lineno">  565</span>&#160;  }</div><div class="line"><a name="l00566"></a><span class="lineno">  566</span>&#160;}</div><div class="line"><a name="l00567"></a><span class="lineno">  567</span>&#160;</div><div class="line"><a name="l00594"></a><span class="lineno"><a class="line" href="namespacetopi_1_1nn.html#af721a019c13f1f99dc43d5d49cc71388">  594</a></span>&#160;<span class="keyword">inline</span> <a class="code" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> <a class="code" href="namespacetopi_1_1nn.html#af721a019c13f1f99dc43d5d49cc71388">adaptive_pool</a>(<span class="keyword">const</span> <a class="code" href="classtvm_1_1te_1_1Tensor.html">Tensor</a>&amp; x,</div><div class="line"><a name="l00595"></a><span class="lineno">  595</span>&#160;                            <span class="keyword">const</span> <a class="code" href="classtvm_1_1Array.html">Array&lt;PrimExpr&gt;</a>&amp; output_size,</div><div class="line"><a name="l00596"></a><span class="lineno">  596</span>&#160;                            <a class="code" href="namespacetopi_1_1nn.html#ac531cfce9c3a031fa25cfb6ed1f9b95b">PoolType</a> pool_type,</div><div class="line"><a name="l00597"></a><span class="lineno">  597</span>&#160;                            <span class="keyword">const</span> std::string&amp; layout = <span class="stringliteral">&quot;NCHW&quot;</span>) {</div><div class="line"><a name="l00598"></a><span class="lineno">  598</span>&#160;  <span class="keywordtype">int</span> height_axis = -1, width_axis = -1;</div><div class="line"><a name="l00599"></a><span class="lineno">  599</span>&#160;  CHECK(<a class="code" href="namespacetopi_1_1nn.html#a428e0ba6800ef89b8c1f97f0245e244d">find_height_width</a>(layout, &amp;height_axis, &amp;width_axis))</div><div class="line"><a name="l00600"></a><span class="lineno">  600</span>&#160;    &lt;&lt; <span class="stringliteral">&quot;Unsupported layout &quot;</span> &lt;&lt; layout;</div><div class="line"><a name="l00601"></a><span class="lineno">  601</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="namespacetopi_1_1nn.html#ad4f34df5cfa8dc75843116bc39f06066">adaptive_pool_impl</a>(x, output_size, pool_type, {height_axis, width_axis});</div><div class="line"><a name="l00602"></a><span class="lineno">  602</span>&#160;}</div><div class="line"><a name="l00603"></a><span class="lineno">  603</span>&#160;</div><div class="line"><a name="l00612"></a><span class="lineno"><a class="line" href="namespacetopi_1_1nn.html#ad48c57c26ce6bb02576555a4cb11bcd3">  612</a></span>&#160;<span class="keyword">inline</span> <a class="code" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> <a class="code" href="namespacetopi_1_1nn.html#ad48c57c26ce6bb02576555a4cb11bcd3">adaptive_pool3d</a>(<span class="keyword">const</span> <a class="code" href="classtvm_1_1te_1_1Tensor.html">Tensor</a>&amp; x,</div><div class="line"><a name="l00613"></a><span class="lineno">  613</span>&#160;                              <span class="keyword">const</span> <a class="code" href="classtvm_1_1Array.html">Array&lt;PrimExpr&gt;</a>&amp; output_size,</div><div class="line"><a name="l00614"></a><span class="lineno">  614</span>&#160;                              <a class="code" href="namespacetopi_1_1nn.html#ac531cfce9c3a031fa25cfb6ed1f9b95b">PoolType</a> pool_type,</div><div class="line"><a name="l00615"></a><span class="lineno">  615</span>&#160;                              <span class="keyword">const</span> std::string&amp; layout = <span class="stringliteral">&quot;NCDHW&quot;</span>) {</div><div class="line"><a name="l00616"></a><span class="lineno">  616</span>&#160;  <span class="keywordtype">int</span> depth_axis = -1, height_axis = -1, width_axis = -1;</div><div class="line"><a name="l00617"></a><span class="lineno">  617</span>&#160;  CHECK(<a class="code" href="namespacetopi_1_1nn.html#a2e81a7938a1e3f273e184e2373d9138d">find_depth_height_width</a>(layout, &amp;depth_axis, &amp;height_axis, &amp;width_axis))</div><div class="line"><a name="l00618"></a><span class="lineno">  618</span>&#160;    &lt;&lt; <span class="stringliteral">&quot;Unsupported layout &quot;</span> &lt;&lt; layout;</div><div class="line"><a name="l00619"></a><span class="lineno">  619</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="namespacetopi_1_1nn.html#ad4f34df5cfa8dc75843116bc39f06066">adaptive_pool_impl</a>(x, output_size, pool_type, {depth_axis, height_axis, width_axis});</div><div class="line"><a name="l00620"></a><span class="lineno">  620</span>&#160;}</div><div class="line"><a name="l00621"></a><span class="lineno">  621</span>&#160;</div><div class="line"><a name="l00647"></a><span class="lineno"><a class="line" href="namespacetopi_1_1nn.html#ac5fe64687aa8bffee420bf282f2b8f8c">  647</a></span>&#160;<span class="keyword">inline</span> <a class="code" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> <a class="code" href="namespacetopi_1_1nn.html#ac5fe64687aa8bffee420bf282f2b8f8c">global_pool</a>(<span class="keyword">const</span> <a class="code" href="classtvm_1_1te_1_1Tensor.html">Tensor</a>&amp; x,</div><div class="line"><a name="l00648"></a><span class="lineno">  648</span>&#160;                          <a class="code" href="namespacetopi_1_1nn.html#ac531cfce9c3a031fa25cfb6ed1f9b95b">PoolType</a> pool_type,</div><div class="line"><a name="l00649"></a><span class="lineno">  649</span>&#160;                          <span class="keyword">const</span> std::string&amp; layout = <span class="stringliteral">&quot;NCHW&quot;</span>) {</div><div class="line"><a name="l00650"></a><span class="lineno">  650</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="namespacetopi_1_1nn.html#af721a019c13f1f99dc43d5d49cc71388">adaptive_pool</a>(x, <a class="code" href="classtvm_1_1Array.html">Array&lt;PrimExpr&gt;</a>{1, 1}, pool_type, layout);</div><div class="line"><a name="l00651"></a><span class="lineno">  651</span>&#160;}</div><div class="line"><a name="l00652"></a><span class="lineno">  652</span>&#160;</div><div class="line"><a name="l00668"></a><span class="lineno"><a class="line" href="namespacetopi_1_1nn.html#a0b2681e29b1f733835ffe2e6b3b69c13">  668</a></span>&#160;<span class="keyword">inline</span> <a class="code" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> <a class="code" href="namespacetopi_1_1nn.html#a0b2681e29b1f733835ffe2e6b3b69c13">pool_impl_nd</a>(<span class="keyword">const</span> <a class="code" href="classtvm_1_1te_1_1Tensor.html">Tensor</a>&amp; x,</div><div class="line"><a name="l00669"></a><span class="lineno">  669</span>&#160;                           <span class="keyword">const</span> <a class="code" href="classtvm_1_1Array.html">Array&lt;PrimExpr&gt;</a>&amp; kernel_size,</div><div class="line"><a name="l00670"></a><span class="lineno">  670</span>&#160;                           <span class="keyword">const</span> <a class="code" href="classtvm_1_1Array.html">Array&lt;PrimExpr&gt;</a>&amp; stride_size,</div><div class="line"><a name="l00671"></a><span class="lineno">  671</span>&#160;                           <span class="keyword">const</span> <a class="code" href="classtvm_1_1Array.html">Array&lt;PrimExpr&gt;</a>&amp; padding_size,</div><div class="line"><a name="l00672"></a><span class="lineno">  672</span>&#160;                           <a class="code" href="namespacetopi_1_1nn.html#ac531cfce9c3a031fa25cfb6ed1f9b95b">PoolType</a> pool_type,</div><div class="line"><a name="l00673"></a><span class="lineno">  673</span>&#160;                           <span class="keywordtype">bool</span> ceil_mode,</div><div class="line"><a name="l00674"></a><span class="lineno">  674</span>&#160;                           <span class="keyword">const</span> std::vector&lt;int&gt;&amp; axis,</div><div class="line"><a name="l00675"></a><span class="lineno">  675</span>&#160;                           <span class="keywordtype">bool</span> count_include_pad) {</div><div class="line"><a name="l00676"></a><span class="lineno">  676</span>&#160;  <span class="keywordtype">int</span> k_size = kernel_size.<a class="code" href="classtvm_1_1Array.html#a6c150ee7d3e46117b099d2052b19aec5">size</a>();</div><div class="line"><a name="l00677"></a><span class="lineno">  677</span>&#160;  <span class="keywordtype">int</span> x_size = x-&gt;<a class="code" href="classtvm_1_1te_1_1TensorNode.html#a0ba732bc2def0d467854585752911351">shape</a>.size();</div><div class="line"><a name="l00678"></a><span class="lineno">  678</span>&#160;  CHECK_EQ(stride_size.<a class="code" href="classtvm_1_1Array.html#a6c150ee7d3e46117b099d2052b19aec5">size</a>(), k_size) &lt;&lt; <span class="stringliteral">&quot;Pooling stride_size must have same elements as kernel&quot;</span>;</div><div class="line"><a name="l00679"></a><span class="lineno">  679</span>&#160;  CHECK_EQ(padding_size.<a class="code" href="classtvm_1_1Array.html#a6c150ee7d3e46117b099d2052b19aec5">size</a>(), k_size * 2) &lt;&lt; <span class="stringliteral">&quot;Pooling padding_size must has double elements of&quot;</span></div><div class="line"><a name="l00680"></a><span class="lineno">  680</span>&#160;           <span class="stringliteral">&quot; kernel&quot;</span>;</div><div class="line"><a name="l00681"></a><span class="lineno">  681</span>&#160;  CHECK_EQ(axis.size(), k_size) &lt;&lt; <span class="stringliteral">&quot;axis must have same elements as kernel&quot;</span>;</div><div class="line"><a name="l00682"></a><span class="lineno">  682</span>&#160;</div><div class="line"><a name="l00683"></a><span class="lineno">  683</span>&#160;  <a class="code" href="classtvm_1_1Array.html">Array&lt;IterVar&gt;</a> daxis;</div><div class="line"><a name="l00684"></a><span class="lineno">  684</span>&#160;  std::vector&lt;PrimExpr&gt; kernel(k_size);</div><div class="line"><a name="l00685"></a><span class="lineno">  685</span>&#160;  std::vector&lt;PrimExpr&gt; stride(k_size);</div><div class="line"><a name="l00686"></a><span class="lineno">  686</span>&#160;  std::vector&lt;PrimExpr&gt; pad_head(k_size);</div><div class="line"><a name="l00687"></a><span class="lineno">  687</span>&#160;  std::vector&lt;PrimExpr&gt; pad_tail(k_size);</div><div class="line"><a name="l00688"></a><span class="lineno">  688</span>&#160;  <a class="code" href="classtvm_1_1Array.html">Array&lt;PrimExpr&gt;</a> pad_before(std::vector&lt;PrimExpr&gt;(x_size, 0));</div><div class="line"><a name="l00689"></a><span class="lineno">  689</span>&#160;  <a class="code" href="classtvm_1_1Array.html">Array&lt;PrimExpr&gt;</a> pad_after(std::vector&lt;PrimExpr&gt;(x_size, 0));</div><div class="line"><a name="l00690"></a><span class="lineno">  690</span>&#160;  <a class="code" href="classtvm_1_1Array.html">Array&lt;PrimExpr&gt;</a> out_shape = x-&gt;<a class="code" href="classtvm_1_1te_1_1TensorNode.html#a0ba732bc2def0d467854585752911351">shape</a>;</div><div class="line"><a name="l00691"></a><span class="lineno">  691</span>&#160;</div><div class="line"><a name="l00692"></a><span class="lineno">  692</span>&#160;  <span class="keywordtype">bool</span> do_pad = <span class="keyword">false</span>;</div><div class="line"><a name="l00693"></a><span class="lineno">  693</span>&#160;  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; k_size; i++) {</div><div class="line"><a name="l00694"></a><span class="lineno">  694</span>&#160;    <span class="keywordtype">int</span> ii = axis[i];</div><div class="line"><a name="l00695"></a><span class="lineno">  695</span>&#160;    kernel[i] = <a class="code" href="namespacetopi.html#acfc3df84ca997ccac0f57d50e96c1c06">cast</a>(<a class="code" href="classtvm_1_1runtime_1_1DataType.html#ab45f13dd70d982d9f977c79b6f7fac98">DataType::Int</a>(32), kernel_size[i]);</div><div class="line"><a name="l00696"></a><span class="lineno">  696</span>&#160;    stride[i] = <a class="code" href="namespacetopi.html#acfc3df84ca997ccac0f57d50e96c1c06">cast</a>(<a class="code" href="classtvm_1_1runtime_1_1DataType.html#ab45f13dd70d982d9f977c79b6f7fac98">DataType::Int</a>(32), stride_size[i]);</div><div class="line"><a name="l00697"></a><span class="lineno">  697</span>&#160;    pad_head[i] = <a class="code" href="namespacetopi.html#acfc3df84ca997ccac0f57d50e96c1c06">cast</a>(<a class="code" href="classtvm_1_1runtime_1_1DataType.html#ab45f13dd70d982d9f977c79b6f7fac98">DataType::Int</a>(32), padding_size[i]);</div><div class="line"><a name="l00698"></a><span class="lineno">  698</span>&#160;    pad_tail[i] = <a class="code" href="namespacetopi.html#acfc3df84ca997ccac0f57d50e96c1c06">cast</a>(<a class="code" href="classtvm_1_1runtime_1_1DataType.html#ab45f13dd70d982d9f977c79b6f7fac98">DataType::Int</a>(32), padding_size[i + k_size]);</div><div class="line"><a name="l00699"></a><span class="lineno">  699</span>&#160;    <span class="keyword">const</span> int64_t *padding0 = <a class="code" href="namespacetvm_1_1tir.html#acbe8f225faaf34c540194921a7ee6a66">as_const_int</a>(pad_head[i]);</div><div class="line"><a name="l00700"></a><span class="lineno">  700</span>&#160;    <span class="keyword">const</span> int64_t *padding1 = <a class="code" href="namespacetvm_1_1tir.html#acbe8f225faaf34c540194921a7ee6a66">as_const_int</a>(pad_tail[i]);</div><div class="line"><a name="l00701"></a><span class="lineno">  701</span>&#160;    do_pad = (do_pad) ? do_pad : ((padding0 &amp;&amp; *padding0) || (padding1 &amp;&amp; *padding1));</div><div class="line"><a name="l00702"></a><span class="lineno">  702</span>&#160;</div><div class="line"><a name="l00703"></a><span class="lineno">  703</span>&#160;    <span class="keywordflow">if</span> (ceil_mode) {</div><div class="line"><a name="l00704"></a><span class="lineno">  704</span>&#160;      <span class="comment">// Additional padding to ensure we do ceil instead of floor when</span></div><div class="line"><a name="l00705"></a><span class="lineno">  705</span>&#160;      <span class="comment">// dividing by stride.</span></div><div class="line"><a name="l00706"></a><span class="lineno">  706</span>&#160;      pad_tail[i] += stride[i] - 1;</div><div class="line"><a name="l00707"></a><span class="lineno">  707</span>&#160;    }</div><div class="line"><a name="l00708"></a><span class="lineno">  708</span>&#160;</div><div class="line"><a name="l00709"></a><span class="lineno">  709</span>&#160;    daxis.push_back(<a class="code" href="namespacetvm_1_1te.html#aae384e9b73c2271905486e4a74b69265">tvm::te::reduce_axis</a>(<a class="code" href="classtvm_1_1Range.html">Range</a>(0, kernel[i])));</div><div class="line"><a name="l00710"></a><span class="lineno">  710</span>&#160;</div><div class="line"><a name="l00711"></a><span class="lineno">  711</span>&#160;    pad_before.<a class="code" href="classtvm_1_1Array.html#ab3db968deb4be7a51767f22d267eb7af">Set</a>(ii, pad_head[i]);</div><div class="line"><a name="l00712"></a><span class="lineno">  712</span>&#160;    pad_after.<a class="code" href="classtvm_1_1Array.html#ab3db968deb4be7a51767f22d267eb7af">Set</a>(ii, pad_tail[i]);</div><div class="line"><a name="l00713"></a><span class="lineno">  713</span>&#160;</div><div class="line"><a name="l00714"></a><span class="lineno">  714</span>&#160;    <span class="keyword">auto</span> out_dim = <a class="code" href="namespacetvm_1_1tir.html#a923d1bb833c984008772782e90cda37a">tvm::tir::Simplify</a>(</div><div class="line"><a name="l00715"></a><span class="lineno">  715</span>&#160;      <a class="code" href="namespacetvm.html#a8203d70a5ebf3532370264b000d0d276">indexdiv</a>(x-&gt;<a class="code" href="classtvm_1_1te_1_1TensorNode.html#a0ba732bc2def0d467854585752911351">shape</a>[ii] - kernel[i] + pad_head[i] + pad_tail[i], stride[i]) + 1);</div><div class="line"><a name="l00716"></a><span class="lineno">  716</span>&#160;</div><div class="line"><a name="l00717"></a><span class="lineno">  717</span>&#160;    out_shape.<a class="code" href="classtvm_1_1Array.html#ab3db968deb4be7a51767f22d267eb7af">Set</a>(ii, out_dim);</div><div class="line"><a name="l00718"></a><span class="lineno">  718</span>&#160;  }</div><div class="line"><a name="l00719"></a><span class="lineno">  719</span>&#160;</div><div class="line"><a name="l00720"></a><span class="lineno">  720</span>&#160;  <span class="keywordflow">if</span> (pool_type == <a class="code" href="namespacetopi_1_1nn.html#ac531cfce9c3a031fa25cfb6ed1f9b95ba3a406a1361a3c7ca311d3c514842c2f4">kMaxPool</a>) {</div><div class="line"><a name="l00721"></a><span class="lineno">  721</span>&#160;    <span class="keyword">auto</span> temp = do_pad ? <a class="code" href="namespacetopi.html#a7d9e2d0f526ff451b6df91c6a673f440">pad</a>(</div><div class="line"><a name="l00722"></a><span class="lineno">  722</span>&#160;        x, pad_before, pad_after, <a class="code" href="namespacetvm.html#a9c126a8dde0d4079713969ca574f172e">tvm::min_value</a>(x-&gt;<a class="code" href="classtvm_1_1te_1_1TensorNode.html#a4c0b6e32a09ab6ea6b869de45394294d">dtype</a>), <span class="stringliteral">&quot;pad_temp&quot;</span>) : x;</div><div class="line"><a name="l00723"></a><span class="lineno">  723</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="namespacetvm_1_1te.html#aeacae1afc9dd1267cbb5779f9daa4671">tvm::te::compute</a>(out_shape, [&amp;](<span class="keyword">const</span> <a class="code" href="classtvm_1_1Array.html">Array&lt;Var&gt;</a>&amp; output) {</div><div class="line"><a name="l00724"></a><span class="lineno">  724</span>&#160;      <a class="code" href="classtvm_1_1Array.html">Array&lt;PrimExpr&gt;</a> indices;</div><div class="line"><a name="l00725"></a><span class="lineno">  725</span>&#160;      <span class="keywordflow">for</span> (<span class="keyword">const</span> <a class="code" href="classtvm_1_1tir_1_1Var.html">Var</a>&amp; <a class="code" href="namespacetvm_1_1te.html#ae0c71f84710b436cbe0b32289d0838f4">var</a> : output) indices.<a class="code" href="classtvm_1_1Array.html#a24d5ac1f6730d46cb1a6d16729f0a7bb">push_back</a>(<a class="code" href="namespacetvm_1_1te.html#ae0c71f84710b436cbe0b32289d0838f4">var</a>);</div><div class="line"><a name="l00726"></a><span class="lineno">  726</span>&#160;</div><div class="line"><a name="l00727"></a><span class="lineno">  727</span>&#160;      <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; k_size; i++) {</div><div class="line"><a name="l00728"></a><span class="lineno">  728</span>&#160;        <span class="keywordtype">int</span> ii = axis[i];</div><div class="line"><a name="l00729"></a><span class="lineno">  729</span>&#160;        indices.<a class="code" href="classtvm_1_1Array.html#ab3db968deb4be7a51767f22d267eb7af">Set</a>(ii, output[ii] * stride[i] + daxis[i]);</div><div class="line"><a name="l00730"></a><span class="lineno">  730</span>&#160;      }</div><div class="line"><a name="l00731"></a><span class="lineno">  731</span>&#160;</div><div class="line"><a name="l00732"></a><span class="lineno">  732</span>&#160;      <span class="keywordflow">return</span> <a class="code" href="namespacetvm.html#ab49bad0808ba033343e72ba37b39af2e">tvm::max</a>(temp(indices), daxis);</div><div class="line"><a name="l00733"></a><span class="lineno">  733</span>&#160;    }, <span class="stringliteral">&quot;tensor&quot;</span>, <span class="stringliteral">&quot;pool_max&quot;</span>);</div><div class="line"><a name="l00734"></a><span class="lineno">  734</span>&#160;  } <span class="keywordflow">else</span> <span class="keywordflow">if</span> (pool_type == <a class="code" href="namespacetopi_1_1nn.html#ac531cfce9c3a031fa25cfb6ed1f9b95babbfb6c4315c8b57e558600af1515d3d8">kAvgPool</a>) {</div><div class="line"><a name="l00735"></a><span class="lineno">  735</span>&#160;    <span class="comment">// Pad the inputs</span></div><div class="line"><a name="l00736"></a><span class="lineno">  736</span>&#160;    <span class="keyword">auto</span> temp = do_pad ? <a class="code" href="namespacetopi.html#a7d9e2d0f526ff451b6df91c6a673f440">pad</a>(x, pad_before, pad_after, 0, <span class="stringliteral">&quot;pad_temp&quot;</span>) : x;</div><div class="line"><a name="l00737"></a><span class="lineno">  737</span>&#160;</div><div class="line"><a name="l00738"></a><span class="lineno">  738</span>&#160;    <span class="comment">// TVM compute for summing the pooling window.</span></div><div class="line"><a name="l00739"></a><span class="lineno">  739</span>&#160;    <span class="keyword">auto</span> pool_sum = <a class="code" href="namespacetvm_1_1te.html#aeacae1afc9dd1267cbb5779f9daa4671">tvm::te::compute</a>(out_shape,</div><div class="line"><a name="l00740"></a><span class="lineno">  740</span>&#160;    [&amp;](<span class="keyword">const</span> <a class="code" href="classtvm_1_1Array.html">Array&lt;Var&gt;</a>&amp; output) {</div><div class="line"><a name="l00741"></a><span class="lineno">  741</span>&#160;      <a class="code" href="classtvm_1_1Array.html">Array&lt;PrimExpr&gt;</a> indices;</div><div class="line"><a name="l00742"></a><span class="lineno">  742</span>&#160;      <span class="keywordflow">for</span> (<span class="keyword">const</span> <a class="code" href="classtvm_1_1tir_1_1Var.html">Var</a>&amp; <a class="code" href="namespacetvm_1_1te.html#ae0c71f84710b436cbe0b32289d0838f4">var</a> : output) indices.<a class="code" href="classtvm_1_1Array.html#a24d5ac1f6730d46cb1a6d16729f0a7bb">push_back</a>(<a class="code" href="namespacetvm_1_1te.html#ae0c71f84710b436cbe0b32289d0838f4">var</a>);</div><div class="line"><a name="l00743"></a><span class="lineno">  743</span>&#160;</div><div class="line"><a name="l00744"></a><span class="lineno">  744</span>&#160;      <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; k_size; i++) {</div><div class="line"><a name="l00745"></a><span class="lineno">  745</span>&#160;        <span class="keywordtype">int</span> ii = axis[i];</div><div class="line"><a name="l00746"></a><span class="lineno">  746</span>&#160;        indices.<a class="code" href="classtvm_1_1Array.html#ab3db968deb4be7a51767f22d267eb7af">Set</a>(ii, output[ii] * stride[i] + daxis[i]);</div><div class="line"><a name="l00747"></a><span class="lineno">  747</span>&#160;      }</div><div class="line"><a name="l00748"></a><span class="lineno">  748</span>&#160;      <span class="keywordflow">return</span> <a class="code" href="namespacetvm.html#a5cea5eb708bfbfa08e285092e5afdc33">tvm::sum</a>(temp(indices), daxis);</div><div class="line"><a name="l00749"></a><span class="lineno">  749</span>&#160;    }, <span class="stringliteral">&quot;tensor&quot;</span>, <span class="stringliteral">&quot;pool_sum&quot;</span>);</div><div class="line"><a name="l00750"></a><span class="lineno">  750</span>&#160;</div><div class="line"><a name="l00751"></a><span class="lineno">  751</span>&#160;    <span class="comment">// TVM compute for dividing the reduced window sum by kernel size.</span></div><div class="line"><a name="l00752"></a><span class="lineno">  752</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="namespacetvm_1_1te.html#aeacae1afc9dd1267cbb5779f9daa4671">tvm::te::compute</a>(out_shape,</div><div class="line"><a name="l00753"></a><span class="lineno">  753</span>&#160;    [&amp;](<span class="keyword">const</span> <a class="code" href="classtvm_1_1Array.html">Array&lt;Var&gt;</a>&amp; output) {</div><div class="line"><a name="l00754"></a><span class="lineno">  754</span>&#160;      <a class="code" href="classtvm_1_1Array.html">Array&lt;PrimExpr&gt;</a> indices;</div><div class="line"><a name="l00755"></a><span class="lineno">  755</span>&#160;      <span class="keywordflow">for</span> (<span class="keyword">const</span> <a class="code" href="classtvm_1_1tir_1_1Var.html">Var</a>&amp; <a class="code" href="namespacetvm_1_1te.html#ae0c71f84710b436cbe0b32289d0838f4">var</a> : output) indices.<a class="code" href="classtvm_1_1Array.html#a24d5ac1f6730d46cb1a6d16729f0a7bb">push_back</a>(<a class="code" href="namespacetvm_1_1te.html#ae0c71f84710b436cbe0b32289d0838f4">var</a>);</div><div class="line"><a name="l00756"></a><span class="lineno">  756</span>&#160;      <span class="keywordflow">if</span> (count_include_pad) {</div><div class="line"><a name="l00757"></a><span class="lineno">  757</span>&#160;        <span class="keyword">auto</span> kernel_size = <a class="code" href="namespacetvm_1_1tir.html#a4ea566597880d04bd62fbec687e338b5">make_const</a>(<a class="code" href="classtvm_1_1runtime_1_1DataType.html#ab45f13dd70d982d9f977c79b6f7fac98">DataType::Int</a>(32), 1);</div><div class="line"><a name="l00758"></a><span class="lineno">  758</span>&#160;        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; k_size; i++) {</div><div class="line"><a name="l00759"></a><span class="lineno">  759</span>&#160;          kernel_size *= kernel[i];</div><div class="line"><a name="l00760"></a><span class="lineno">  760</span>&#160;        }</div><div class="line"><a name="l00761"></a><span class="lineno">  761</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="namespacetvm.html#a40fcc9952e1ff01a76f3b75dbd368fc1">div</a>(pool_sum(indices), kernel_size);</div><div class="line"><a name="l00762"></a><span class="lineno">  762</span>&#160;      } <span class="keywordflow">else</span> {</div><div class="line"><a name="l00763"></a><span class="lineno">  763</span>&#160;        std::vector&lt;PrimExpr&gt; start(k_size);</div><div class="line"><a name="l00764"></a><span class="lineno">  764</span>&#160;        std::vector&lt;PrimExpr&gt; end(k_size);</div><div class="line"><a name="l00765"></a><span class="lineno">  765</span>&#160;        <span class="keyword">auto</span> kernel_size = <a class="code" href="namespacetvm_1_1tir.html#a4ea566597880d04bd62fbec687e338b5">make_const</a>(<a class="code" href="classtvm_1_1runtime_1_1DataType.html#ab45f13dd70d982d9f977c79b6f7fac98">DataType::Int</a>(32), 1);</div><div class="line"><a name="l00766"></a><span class="lineno">  766</span>&#160;        <span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; k_size; i++) {</div><div class="line"><a name="l00767"></a><span class="lineno">  767</span>&#160;          <span class="keywordtype">int</span> ii = axis[i];</div><div class="line"><a name="l00768"></a><span class="lineno">  768</span>&#160;          start[i] = output[ii] * stride[i] - pad_head[i];</div><div class="line"><a name="l00769"></a><span class="lineno">  769</span>&#160;          end[i] = <a class="code" href="classtvm_1_1tir_1_1BinaryOpNode.html#afb3a9f4de76865880cc9f19ebcc75ea0">tir::MinNode::make</a>(start[i] + kernel[i], x-&gt;<a class="code" href="classtvm_1_1te_1_1TensorNode.html#a0ba732bc2def0d467854585752911351">shape</a>[ii]);</div><div class="line"><a name="l00770"></a><span class="lineno">  770</span>&#160;          start[i] = <a class="code" href="classtvm_1_1tir_1_1BinaryOpNode.html#afb3a9f4de76865880cc9f19ebcc75ea0">tir::MaxNode::make</a>(start[i], <a class="code" href="namespacetvm_1_1tir.html#a4ea566597880d04bd62fbec687e338b5">make_const</a>(<a class="code" href="classtvm_1_1runtime_1_1DataType.html#ab45f13dd70d982d9f977c79b6f7fac98">DataType::Int</a>(32), 0));</div><div class="line"><a name="l00771"></a><span class="lineno">  771</span>&#160;          kernel_size *= (end[i] - start[i]);</div><div class="line"><a name="l00772"></a><span class="lineno">  772</span>&#160;        }</div><div class="line"><a name="l00773"></a><span class="lineno">  773</span>&#160;</div><div class="line"><a name="l00774"></a><span class="lineno">  774</span>&#160;        <a class="code" href="classtvm_1_1PrimExpr.html">PrimExpr</a> divide_factor = <a class="code" href="classtvm_1_1tir_1_1BinaryOpNode.html#afb3a9f4de76865880cc9f19ebcc75ea0">tir::MaxNode::make</a>(kernel_size, <a class="code" href="namespacetvm_1_1tir.html#a4ea566597880d04bd62fbec687e338b5">make_const</a>(<a class="code" href="classtvm_1_1runtime_1_1DataType.html#ab45f13dd70d982d9f977c79b6f7fac98">DataType::Int</a>(32), 1));</div><div class="line"><a name="l00775"></a><span class="lineno">  775</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="namespacetvm.html#a40fcc9952e1ff01a76f3b75dbd368fc1">div</a>(pool_sum(indices), divide_factor);</div><div class="line"><a name="l00776"></a><span class="lineno">  776</span>&#160;      }</div><div class="line"><a name="l00777"></a><span class="lineno">  777</span>&#160;    }, <span class="stringliteral">&quot;tensor&quot;</span>, <a class="code" href="namespacetopi.html#ac1b34ed59d38a5f5338bee6b2cad42be">kElementWise</a>);</div><div class="line"><a name="l00778"></a><span class="lineno">  778</span>&#160;  } <span class="keywordflow">else</span> {</div><div class="line"><a name="l00779"></a><span class="lineno">  779</span>&#160;    LOG(ERROR) &lt;&lt; <span class="stringliteral">&quot;Unrecognized pool_type: &quot;</span> &lt;&lt; pool_type;</div><div class="line"><a name="l00780"></a><span class="lineno">  780</span>&#160;    <span class="keywordflow">return</span> x;</div><div class="line"><a name="l00781"></a><span class="lineno">  781</span>&#160;  }</div><div class="line"><a name="l00782"></a><span class="lineno">  782</span>&#160;}</div><div class="line"><a name="l00783"></a><span class="lineno">  783</span>&#160;</div><div class="line"><a name="l00813"></a><span class="lineno"><a class="line" href="namespacetopi_1_1nn.html#a379dfcc1d33774fb4ce998550dda187c">  813</a></span>&#160;<span class="keyword">inline</span> <a class="code" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> <a class="code" href="namespacetopi_1_1nn.html#a379dfcc1d33774fb4ce998550dda187c">pool1d</a>(<span class="keyword">const</span> <a class="code" href="classtvm_1_1te_1_1Tensor.html">Tensor</a>&amp; x,</div><div class="line"><a name="l00814"></a><span class="lineno">  814</span>&#160;                     <span class="keyword">const</span> <a class="code" href="classtvm_1_1Array.html">Array&lt;PrimExpr&gt;</a>&amp; kernel_size,</div><div class="line"><a name="l00815"></a><span class="lineno">  815</span>&#160;                     <span class="keyword">const</span> <a class="code" href="classtvm_1_1Array.html">Array&lt;PrimExpr&gt;</a>&amp; stride_size,</div><div class="line"><a name="l00816"></a><span class="lineno">  816</span>&#160;                     <span class="keyword">const</span> <a class="code" href="classtvm_1_1Array.html">Array&lt;PrimExpr&gt;</a>&amp; padding_size,</div><div class="line"><a name="l00817"></a><span class="lineno">  817</span>&#160;                     <a class="code" href="namespacetopi_1_1nn.html#ac531cfce9c3a031fa25cfb6ed1f9b95b">PoolType</a> pool_type,</div><div class="line"><a name="l00818"></a><span class="lineno">  818</span>&#160;                     <span class="keywordtype">bool</span> ceil_mode,</div><div class="line"><a name="l00819"></a><span class="lineno">  819</span>&#160;                     <span class="keyword">const</span> std::string&amp; layout = <span class="stringliteral">&quot;NCW&quot;</span>,</div><div class="line"><a name="l00820"></a><span class="lineno">  820</span>&#160;                     <span class="keywordtype">bool</span> count_include_pad = <span class="keyword">true</span>) {</div><div class="line"><a name="l00821"></a><span class="lineno">  821</span>&#160;  <span class="keywordtype">int</span> width_axis = -1;</div><div class="line"><a name="l00822"></a><span class="lineno">  822</span>&#160;  CHECK(<a class="code" href="namespacetopi_1_1nn.html#ab1f1f9f86723b30bb8997615e1d63ca8">find_width</a>(layout, &amp;width_axis))</div><div class="line"><a name="l00823"></a><span class="lineno">  823</span>&#160;    &lt;&lt; <span class="stringliteral">&quot;Unsupported layout &quot;</span> &lt;&lt; layout;</div><div class="line"><a name="l00824"></a><span class="lineno">  824</span>&#160;  std::vector&lt;int&gt; axis = {width_axis};</div><div class="line"><a name="l00825"></a><span class="lineno">  825</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="namespacetopi_1_1nn.html#a0b2681e29b1f733835ffe2e6b3b69c13">pool_impl_nd</a>(x, kernel_size, stride_size, padding_size,</div><div class="line"><a name="l00826"></a><span class="lineno">  826</span>&#160;                   pool_type, ceil_mode, axis, count_include_pad);</div><div class="line"><a name="l00827"></a><span class="lineno">  827</span>&#160;}</div><div class="line"><a name="l00828"></a><span class="lineno">  828</span>&#160;</div><div class="line"><a name="l00859"></a><span class="lineno"><a class="line" href="namespacetopi_1_1nn.html#af84c2ac0c1fd4ec7db5c9bc661bd5aab">  859</a></span>&#160;<span class="keyword">inline</span> <a class="code" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> <a class="code" href="namespacetopi_1_1nn.html#af84c2ac0c1fd4ec7db5c9bc661bd5aab">pool3d</a>(<span class="keyword">const</span> <a class="code" href="classtvm_1_1te_1_1Tensor.html">Tensor</a>&amp; x,</div><div class="line"><a name="l00860"></a><span class="lineno">  860</span>&#160;                     <span class="keyword">const</span> <a class="code" href="classtvm_1_1Array.html">Array&lt;PrimExpr&gt;</a>&amp; kernel_size,</div><div class="line"><a name="l00861"></a><span class="lineno">  861</span>&#160;                     <span class="keyword">const</span> <a class="code" href="classtvm_1_1Array.html">Array&lt;PrimExpr&gt;</a>&amp; stride_size,</div><div class="line"><a name="l00862"></a><span class="lineno">  862</span>&#160;                     <span class="keyword">const</span> <a class="code" href="classtvm_1_1Array.html">Array&lt;PrimExpr&gt;</a>&amp; padding_size,</div><div class="line"><a name="l00863"></a><span class="lineno">  863</span>&#160;                     <a class="code" href="namespacetopi_1_1nn.html#ac531cfce9c3a031fa25cfb6ed1f9b95b">PoolType</a> pool_type,</div><div class="line"><a name="l00864"></a><span class="lineno">  864</span>&#160;                     <span class="keywordtype">bool</span> ceil_mode,</div><div class="line"><a name="l00865"></a><span class="lineno">  865</span>&#160;                     <span class="keyword">const</span> std::string&amp; layout = <span class="stringliteral">&quot;NCDHW&quot;</span>,</div><div class="line"><a name="l00866"></a><span class="lineno">  866</span>&#160;                     <span class="keywordtype">bool</span> count_include_pad = <span class="keyword">true</span>) {</div><div class="line"><a name="l00867"></a><span class="lineno">  867</span>&#160;  <span class="keywordtype">int</span> depth_axis = -1, height_axis = -1, width_axis = -1;</div><div class="line"><a name="l00868"></a><span class="lineno">  868</span>&#160;  CHECK(<a class="code" href="namespacetopi_1_1nn.html#a2e81a7938a1e3f273e184e2373d9138d">find_depth_height_width</a>(layout, &amp;depth_axis, &amp;height_axis, &amp;width_axis))</div><div class="line"><a name="l00869"></a><span class="lineno">  869</span>&#160;    &lt;&lt; <span class="stringliteral">&quot;Unsupported layout &quot;</span> &lt;&lt; layout;</div><div class="line"><a name="l00870"></a><span class="lineno">  870</span>&#160;  std::vector&lt;int&gt; axis = {depth_axis, height_axis, width_axis};</div><div class="line"><a name="l00871"></a><span class="lineno">  871</span>&#160;  <span class="keywordflow">return</span> <a class="code" href="namespacetopi_1_1nn.html#a0b2681e29b1f733835ffe2e6b3b69c13">pool_impl_nd</a>(x, kernel_size, stride_size, padding_size,</div><div class="line"><a name="l00872"></a><span class="lineno">  872</span>&#160;                   pool_type, ceil_mode, axis, count_include_pad);</div><div class="line"><a name="l00873"></a><span class="lineno">  873</span>&#160;}</div><div class="line"><a name="l00874"></a><span class="lineno">  874</span>&#160;</div><div class="line"><a name="l00875"></a><span class="lineno">  875</span>&#160;}  <span class="comment">// namespace nn</span></div><div class="line"><a name="l00876"></a><span class="lineno">  876</span>&#160;}  <span class="comment">// namespace topi</span></div><div class="line"><a name="l00877"></a><span class="lineno">  877</span>&#160;<span class="preprocessor">#endif  // TOPI_NN_POOLING_H_</span></div><div class="ttc" id="namespacetvm_html_a9c126a8dde0d4079713969ca574f172e"><div class="ttname"><a href="namespacetvm.html#a9c126a8dde0d4079713969ca574f172e">tvm::min_value</a></div><div class="ttdeci">PrimExpr min_value(const DataType &amp;dtype)</div></div>
<div class="ttc" id="classtvm_1_1Array_html_a6f05e6a14eca3ea865da0f293b4a5325"><div class="ttname"><a href="classtvm_1_1Array.html#a6f05e6a14eca3ea865da0f293b4a5325">tvm::Array::end</a></div><div class="ttdeci">iterator end() const </div><div class="ttdef"><b>Definition:</b> container.h:358</div></div>
<div class="ttc" id="namespacetopi_1_1nn_html_ad51533b09956d7bc8de2537adf3b6b77"><div class="ttname"><a href="namespacetopi_1_1nn.html#ad51533b09956d7bc8de2537adf3b6b77">topi::nn::pool_impl</a></div><div class="ttdeci">Tensor pool_impl(const Tensor &amp;x, const Array&lt; PrimExpr &gt; &amp;kernel_size, const Array&lt; PrimExpr &gt; &amp;stride_size, const Array&lt; PrimExpr &gt; &amp;padding_size, PoolType pool_type, bool ceil_mode, const size_t height_axis, const size_t width_axis, bool count_include_pad)</div><div class="ttdoc">Perform pooling on height and width dimension of data. </div><div class="ttdef"><b>Definition:</b> pooling.h:64</div></div>
<div class="ttc" id="classtvm_1_1Array_html_a6c150ee7d3e46117b099d2052b19aec5"><div class="ttname"><a href="classtvm_1_1Array.html#a6c150ee7d3e46117b099d2052b19aec5">tvm::Array::size</a></div><div class="ttdeci">size_t size() const </div><div class="ttdef"><b>Definition:</b> container.h:246</div></div>
<div class="ttc" id="namespacetvm_html"><div class="ttname"><a href="namespacetvm.html">tvm</a></div><div class="ttdef"><b>Definition:</b> analyzer.h:36</div></div>
<div class="ttc" id="classtvm_1_1Array_html_a24d5ac1f6730d46cb1a6d16729f0a7bb"><div class="ttname"><a href="classtvm_1_1Array.html#a24d5ac1f6730d46cb1a6d16729f0a7bb">tvm::Array::push_back</a></div><div class="ttdeci">void push_back(const T &amp;item)</div><div class="ttdoc">push a new item to the back of the list </div><div class="ttdef"><b>Definition:</b> container.h:270</div></div>
<div class="ttc" id="namespacetvm_1_1te_html"><div class="ttname"><a href="namespacetvm_1_1te.html">tvm::te</a></div><div class="ttdoc">Tensor expression language DSL. </div><div class="ttdef"><b>Definition:</b> bound.h:36</div></div>
<div class="ttc" id="namespacetopi_html_a94f412c82e4225050328fae33a3342f2"><div class="ttname"><a href="namespacetopi.html#a94f412c82e4225050328fae33a3342f2">topi::argmax</a></div><div class="ttdeci">Tensor argmax(const Tensor &amp;data, const Array&lt; Integer &gt; &amp;axis, bool keepdims=false, bool atleast1d=false)</div><div class="ttdoc">Creates an operation that finds the indices of the maximum values over a given axis. </div><div class="ttdef"><b>Definition:</b> reduction.h:519</div></div>
<div class="ttc" id="namespacetvm_1_1te_html_aeacae1afc9dd1267cbb5779f9daa4671"><div class="ttname"><a href="namespacetvm_1_1te.html#aeacae1afc9dd1267cbb5779f9daa4671">tvm::te::compute</a></div><div class="ttdeci">Tensor compute(Array&lt; PrimExpr &gt; shape, FCompute fcompute, std::string name=&quot;tensor&quot;, std::string tag=&quot;&quot;, Map&lt; std::string, ObjectRef &gt; attrs={})</div><div class="ttdoc">Construct a new tensor by computing over shape, using the computation rule: result_tensor[axis] = fco...</div></div>
<div class="ttc" id="classtvm_1_1tir_1_1Var_html"><div class="ttname"><a href="classtvm_1_1tir_1_1Var.html">tvm::tir::Var</a></div><div class="ttdoc">a named variable in TVM </div><div class="ttdef"><b>Definition:</b> expr.h:95</div></div>
<div class="ttc" id="reduction_8h_html"><div class="ttname"><a href="reduction_8h.html">reduction.h</a></div><div class="ttdoc">Reduction op constructors. </div></div>
<div class="ttc" id="namespacetopi_html_ac1b34ed59d38a5f5338bee6b2cad42be"><div class="ttname"><a href="namespacetopi.html#ac1b34ed59d38a5f5338bee6b2cad42be">topi::kElementWise</a></div><div class="ttdeci">constexpr auto kElementWise</div><div class="ttdef"><b>Definition:</b> tags.h:31</div></div>
<div class="ttc" id="namespacetvm_html_aa058caeda9deceda3d6ffeda347be442"><div class="ttname"><a href="namespacetvm.html#aa058caeda9deceda3d6ffeda347be442">tvm::cast</a></div><div class="ttdeci">PrimExpr cast(const DataType &amp;t, PrimExpr value)</div><div class="ttdoc">cast value to type. </div></div>
<div class="ttc" id="classtvm_1_1te_1_1TensorNode_html_a0ba732bc2def0d467854585752911351"><div class="ttname"><a href="classtvm_1_1te_1_1TensorNode.html#a0ba732bc2def0d467854585752911351">tvm::te::TensorNode::shape</a></div><div class="ttdeci">Array&lt; PrimExpr &gt; shape</div><div class="ttdoc">The shape of the tensor. </div><div class="ttdef"><b>Definition:</b> tensor.h:167</div></div>
<div class="ttc" id="namespacetvm_1_1tir_html_acbe8f225faaf34c540194921a7ee6a66"><div class="ttname"><a href="namespacetvm_1_1tir.html#acbe8f225faaf34c540194921a7ee6a66">tvm::tir::as_const_int</a></div><div class="ttdeci">const int64_t * as_const_int(const PrimExpr &amp;x)</div><div class="ttdoc">Get x as constant int expression. </div><div class="ttdef"><b>Definition:</b> op.h:614</div></div>
<div class="ttc" id="classtvm_1_1tir_1_1AndNode_html_aeb51390ed2566af9393d94d915e56d50"><div class="ttname"><a href="classtvm_1_1tir_1_1AndNode.html#aeb51390ed2566af9393d94d915e56d50">tvm::tir::AndNode::make</a></div><div class="ttdeci">static PrimExpr make(PrimExpr a, PrimExpr b)</div></div>
<div class="ttc" id="namespacetopi_1_1nn_html_af2c25e8b3ab3cac1c2896cb750838337"><div class="ttname"><a href="namespacetopi_1_1nn.html#af2c25e8b3ab3cac1c2896cb750838337">topi::nn::pool_grad_impl</a></div><div class="ttdeci">Tensor pool_grad_impl(const Tensor &amp;out_grad, const Tensor &amp;x, const Array&lt; PrimExpr &gt; &amp;kernel_size, const Array&lt; PrimExpr &gt; &amp;stride_size, const Array&lt; PrimExpr &gt; &amp;padding_size, PoolType pool_type, bool ceil_mode, const size_t height_axis, const size_t width_axis, bool count_include_pad)</div><div class="ttdef"><b>Definition:</b> pooling.h:174</div></div>
<div class="ttc" id="namespacetopi_1_1nn_html_ac5fe64687aa8bffee420bf282f2b8f8c"><div class="ttname"><a href="namespacetopi_1_1nn.html#ac5fe64687aa8bffee420bf282f2b8f8c">topi::nn::global_pool</a></div><div class="ttdeci">Tensor global_pool(const Tensor &amp;x, PoolType pool_type, const std::string &amp;layout=&quot;NCHW&quot;)</div><div class="ttdoc">Perform global pooling on height and width dimension of data. It decides the height and width dimensi...</div><div class="ttdef"><b>Definition:</b> pooling.h:647</div></div>
<div class="ttc" id="namespacetvm_html_a5cea5eb708bfbfa08e285092e5afdc33"><div class="ttname"><a href="namespacetvm.html#a5cea5eb708bfbfa08e285092e5afdc33">tvm::sum</a></div><div class="ttdeci">PrimExpr sum(PrimExpr source, Array&lt; tir::IterVar &gt; axis)</div><div class="ttdoc">sum of of source expression over axis </div></div>
<div class="ttc" id="namespacetopi_html_a7d9e2d0f526ff451b6df91c6a673f440"><div class="ttname"><a href="namespacetopi.html#a7d9e2d0f526ff451b6df91c6a673f440">topi::pad</a></div><div class="ttdeci">tvm::te::Tensor pad(const tvm::te::Tensor &amp;t, const tvm::Array&lt; tvm::PrimExpr &gt; &amp;pad_before, tvm::Array&lt; tvm::PrimExpr &gt; pad_after=tvm::Array&lt; tvm::PrimExpr &gt;(), PrimExpr pad_value=PrimExpr(), std::string name=&quot;T_pad&quot;, std::string tag=kElementWise, std::string pad_mode=&quot;constant&quot;)</div><div class="ttdoc">Creates an operation that performs padding. </div><div class="ttdef"><b>Definition:</b> nn.h:175</div></div>
<div class="ttc" id="namespacetopi_html"><div class="ttname"><a href="namespacetopi.html">topi</a></div><div class="ttdef"><b>Definition:</b> broadcast.h:34</div></div>
<div class="ttc" id="classtvm_1_1tir_1_1BinaryOpNode_html_afb3a9f4de76865880cc9f19ebcc75ea0"><div class="ttname"><a href="classtvm_1_1tir_1_1BinaryOpNode.html#afb3a9f4de76865880cc9f19ebcc75ea0">tvm::tir::BinaryOpNode&lt; MinNode &gt;::make</a></div><div class="ttdeci">static PrimExpr make(PrimExpr a, PrimExpr b)</div><div class="ttdef"><b>Definition:</b> expr.h:445</div></div>
<div class="ttc" id="classtvm_1_1Range_html"><div class="ttname"><a href="classtvm_1_1Range.html">tvm::Range</a></div><div class="ttdoc">Range constainer. </div><div class="ttdef"><b>Definition:</b> expr.h:404</div></div>
<div class="ttc" id="namespacetopi_1_1nn_html_aadbaaec56f0b485262bf5199bbe3dcb3"><div class="ttname"><a href="namespacetopi_1_1nn.html#aadbaaec56f0b485262bf5199bbe3dcb3">topi::nn::end_index</a></div><div class="ttdeci">PrimExpr end_index(const Var &amp;out_index, const PrimExpr &amp;odim, const PrimExpr &amp;idim)</div><div class="ttdef"><b>Definition:</b> pooling.h:485</div></div>
<div class="ttc" id="namespacetopi_1_1nn_html_ac531cfce9c3a031fa25cfb6ed1f9b95babbfb6c4315c8b57e558600af1515d3d8"><div class="ttname"><a href="namespacetopi_1_1nn.html#ac531cfce9c3a031fa25cfb6ed1f9b95babbfb6c4315c8b57e558600af1515d3d8">topi::nn::kAvgPool</a></div><div class="ttdef"><b>Definition:</b> pooling.h:44</div></div>
<div class="ttc" id="classtvm_1_1Array_html"><div class="ttname"><a href="classtvm_1_1Array.html">tvm::Array</a></div><div class="ttdoc">Array container of NodeRef in DSL graph. Array implements copy on write semantics, which means array is mutable but copy will happen when array is referenced in more than two places. </div><div class="ttdef"><b>Definition:</b> container.h:141</div></div>
<div class="ttc" id="namespacetopi_1_1nn_html_a428e0ba6800ef89b8c1f97f0245e244d"><div class="ttname"><a href="namespacetopi_1_1nn.html#a428e0ba6800ef89b8c1f97f0245e244d">topi::nn::find_height_width</a></div><div class="ttdeci">bool find_height_width(const std::string &amp;layout, int *height_axis, int *width_axis)</div><div class="ttdef"><b>Definition:</b> pooling.h:373</div></div>
<div class="ttc" id="pad__utils_8h_html"><div class="ttname"><a href="pad__utils_8h.html">pad_utils.h</a></div><div class="ttdoc">Padding helpers. </div></div>
<div class="ttc" id="namespacetvm_html_a8203d70a5ebf3532370264b000d0d276"><div class="ttname"><a href="namespacetvm.html#a8203d70a5ebf3532370264b000d0d276">tvm::indexdiv</a></div><div class="ttdeci">PrimExpr indexdiv(PrimExpr a, PrimExpr b)</div><div class="ttdoc">compute floor(a / b) where a and b are non-negative. </div></div>
<div class="ttc" id="classtvm_1_1Array_html_ab3db968deb4be7a51767f22d267eb7af"><div class="ttname"><a href="classtvm_1_1Array.html#ab3db968deb4be7a51767f22d267eb7af">tvm::Array::Set</a></div><div class="ttdeci">void Set(size_t i, const T &amp;value)</div><div class="ttdoc">set i-th element of the array. </div><div class="ttdef"><b>Definition:</b> container.h:287</div></div>
<div class="ttc" id="namespacetvm_1_1tir_html_a4ea566597880d04bd62fbec687e338b5"><div class="ttname"><a href="namespacetvm_1_1tir.html#a4ea566597880d04bd62fbec687e338b5">tvm::tir::make_const</a></div><div class="ttdeci">PrimExpr make_const(DataType t, ValueType value)</div><div class="ttdoc">Make a const value with certain data type. </div><div class="ttdef"><b>Definition:</b> op.h:755</div></div>
<div class="ttc" id="namespacetvm_html_a40fcc9952e1ff01a76f3b75dbd368fc1"><div class="ttname"><a href="namespacetvm.html#a40fcc9952e1ff01a76f3b75dbd368fc1">tvm::div</a></div><div class="ttdeci">PrimExpr div(PrimExpr a, PrimExpr b)</div><div class="ttdoc">compute division in C semantics. </div></div>
<div class="ttc" id="namespacetopi_1_1nn_html_ac1708b3aa1a677f56a4063a568945d98"><div class="ttname"><a href="namespacetopi_1_1nn.html#ac1708b3aa1a677f56a4063a568945d98">topi::nn::pool</a></div><div class="ttdeci">Tensor pool(const Tensor &amp;x, const Array&lt; PrimExpr &gt; &amp;kernel_size, const Array&lt; PrimExpr &gt; &amp;stride_size, const Array&lt; PrimExpr &gt; &amp;padding_size, PoolType pool_type, bool ceil_mode, const std::string &amp;layout=&quot;NCHW&quot;, bool count_include_pad=true)</div><div class="ttdoc">Perform pooling on height and width dimension of data. It decides the height and width dimension acco...</div><div class="ttdef"><b>Definition:</b> pooling.h:423</div></div>
<div class="ttc" id="namespacetopi_1_1nn_html_ad48c57c26ce6bb02576555a4cb11bcd3"><div class="ttname"><a href="namespacetopi_1_1nn.html#ad48c57c26ce6bb02576555a4cb11bcd3">topi::nn::adaptive_pool3d</a></div><div class="ttdeci">Tensor adaptive_pool3d(const Tensor &amp;x, const Array&lt; PrimExpr &gt; &amp;output_size, PoolType pool_type, const std::string &amp;layout=&quot;NCDHW&quot;)</div><div class="ttdoc">Adaptively perform pooling on three dimensional data. See the two dimensional version above for detai...</div><div class="ttdef"><b>Definition:</b> pooling.h:612</div></div>
<div class="ttc" id="namespacetvm_1_1te_html_aae384e9b73c2271905486e4a74b69265"><div class="ttname"><a href="namespacetvm_1_1te.html#aae384e9b73c2271905486e4a74b69265">tvm::te::reduce_axis</a></div><div class="ttdeci">IterVar reduce_axis(Range dom, std::string name=&quot;rv&quot;)</div><div class="ttdoc">Create a new IterVar for reduction operations. </div></div>
<div class="ttc" id="namespacetopi_1_1nn_html_af721a019c13f1f99dc43d5d49cc71388"><div class="ttname"><a href="namespacetopi_1_1nn.html#af721a019c13f1f99dc43d5d49cc71388">topi::nn::adaptive_pool</a></div><div class="ttdeci">Tensor adaptive_pool(const Tensor &amp;x, const Array&lt; PrimExpr &gt; &amp;output_size, PoolType pool_type, const std::string &amp;layout=&quot;NCHW&quot;)</div><div class="ttdoc">Adaptively perform pooling on height and width dimension of data. The pooling kernel and stride sizes...</div><div class="ttdef"><b>Definition:</b> pooling.h:594</div></div>
<div class="ttc" id="namespacetopi_1_1nn_html_ac531cfce9c3a031fa25cfb6ed1f9b95ba3a406a1361a3c7ca311d3c514842c2f4"><div class="ttname"><a href="namespacetopi_1_1nn.html#ac531cfce9c3a031fa25cfb6ed1f9b95ba3a406a1361a3c7ca311d3c514842c2f4">topi::nn::kMaxPool</a></div><div class="ttdef"><b>Definition:</b> pooling.h:45</div></div>
<div class="ttc" id="namespacetvm_html_ab49bad0808ba033343e72ba37b39af2e"><div class="ttname"><a href="namespacetvm.html#ab49bad0808ba033343e72ba37b39af2e">tvm::max</a></div><div class="ttdeci">PrimExpr max(PrimExpr a, PrimExpr b)</div><div class="ttdoc">take maximum of two values </div></div>
<div class="ttc" id="classtvm_1_1tir_1_1SelectNode_html_ae0809a88c56d20faceba05184b6e793b"><div class="ttname"><a href="classtvm_1_1tir_1_1SelectNode.html#ae0809a88c56d20faceba05184b6e793b">tvm::tir::SelectNode::make</a></div><div class="ttdeci">static PrimExpr make(PrimExpr condition, PrimExpr true_value, PrimExpr false_value)</div></div>
<div class="ttc" id="ir__pass_8h_html"><div class="ttname"><a href="ir__pass_8h.html">ir_pass.h</a></div><div class="ttdoc">Collection of IR pass functions. </div></div>
<div class="ttc" id="namespacetopi_1_1nn_html_a2e81a7938a1e3f273e184e2373d9138d"><div class="ttname"><a href="namespacetopi_1_1nn.html#a2e81a7938a1e3f273e184e2373d9138d">topi::nn::find_depth_height_width</a></div><div class="ttdeci">bool find_depth_height_width(const std::string &amp;layout, int *depth_axis, int *height_axis, int *width_axis)</div><div class="ttdef"><b>Definition:</b> pooling.h:344</div></div>
<div class="ttc" id="namespacetvm_1_1te_html_ae0c71f84710b436cbe0b32289d0838f4"><div class="ttname"><a href="namespacetvm_1_1te.html#ae0c71f84710b436cbe0b32289d0838f4">tvm::te::var</a></div><div class="ttdeci">Var var(std::string name_hint, DataType t=DataType::Int(32))</div><div class="ttdoc">Construct a new Var expression. </div></div>
<div class="ttc" id="classtvm_1_1te_1_1Tensor_html"><div class="ttname"><a href="classtvm_1_1te_1_1Tensor.html">tvm::te::Tensor</a></div><div class="ttdoc">Tensor structure representing a possible input, or intermediate computation result. </div><div class="ttdef"><b>Definition:</b> tensor.h:52</div></div>
<div class="ttc" id="namespacetopi_1_1nn_html_a0b2681e29b1f733835ffe2e6b3b69c13"><div class="ttname"><a href="namespacetopi_1_1nn.html#a0b2681e29b1f733835ffe2e6b3b69c13">topi::nn::pool_impl_nd</a></div><div class="ttdeci">Tensor pool_impl_nd(const Tensor &amp;x, const Array&lt; PrimExpr &gt; &amp;kernel_size, const Array&lt; PrimExpr &gt; &amp;stride_size, const Array&lt; PrimExpr &gt; &amp;padding_size, PoolType pool_type, bool ceil_mode, const std::vector&lt; int &gt; &amp;axis, bool count_include_pad)</div><div class="ttdoc">Perform pooling on N-dimension of data. </div><div class="ttdef"><b>Definition:</b> pooling.h:668</div></div>
<div class="ttc" id="namespacetopi_html_aaf18db0af5abc7dd13818115bac402bc"><div class="ttname"><a href="namespacetopi.html#aaf18db0af5abc7dd13818115bac402bc">topi::kCommReduceIdx</a></div><div class="ttdeci">constexpr auto kCommReduceIdx</div><div class="ttdef"><b>Definition:</b> tags.h:34</div></div>
<div class="ttc" id="namespacetvm_1_1tir_html_a923d1bb833c984008772782e90cda37a"><div class="ttname"><a href="namespacetvm_1_1tir.html#a923d1bb833c984008772782e90cda37a">tvm::tir::Simplify</a></div><div class="ttdeci">PrimExpr Simplify(PrimExpr expr, Map&lt; Var, Range &gt; vrange=Map&lt; Var, Range &gt;())</div><div class="ttdoc">Simplify the expression. </div></div>
<div class="ttc" id="namespacetopi_1_1nn_html_a379dfcc1d33774fb4ce998550dda187c"><div class="ttname"><a href="namespacetopi_1_1nn.html#a379dfcc1d33774fb4ce998550dda187c">topi::nn::pool1d</a></div><div class="ttdeci">Tensor pool1d(const Tensor &amp;x, const Array&lt; PrimExpr &gt; &amp;kernel_size, const Array&lt; PrimExpr &gt; &amp;stride_size, const Array&lt; PrimExpr &gt; &amp;padding_size, PoolType pool_type, bool ceil_mode, const std::string &amp;layout=&quot;NCW&quot;, bool count_include_pad=true)</div><div class="ttdoc">Perform pooling on the width dimension of data. Width axis is determined by the layout string in whic...</div><div class="ttdef"><b>Definition:</b> pooling.h:813</div></div>
<div class="ttc" id="classtvm_1_1Array_html_a5db0d3faad39ca865162e50d555a25fa"><div class="ttname"><a href="classtvm_1_1Array.html#a5db0d3faad39ca865162e50d555a25fa">tvm::Array::begin</a></div><div class="ttdeci">iterator begin() const </div><div class="ttdef"><b>Definition:</b> container.h:354</div></div>
<div class="ttc" id="namespacetopi_1_1nn_html_af84c2ac0c1fd4ec7db5c9bc661bd5aab"><div class="ttname"><a href="namespacetopi_1_1nn.html#af84c2ac0c1fd4ec7db5c9bc661bd5aab">topi::nn::pool3d</a></div><div class="ttdeci">Tensor pool3d(const Tensor &amp;x, const Array&lt; PrimExpr &gt; &amp;kernel_size, const Array&lt; PrimExpr &gt; &amp;stride_size, const Array&lt; PrimExpr &gt; &amp;padding_size, PoolType pool_type, bool ceil_mode, const std::string &amp;layout=&quot;NCDHW&quot;, bool count_include_pad=true)</div><div class="ttdoc">Perform pooling on depth, height and width dimension of data. It decides the depth, height and width dimension according to the layout string, in which &amp;#39;D&amp;#39;, &amp;#39;W&amp;#39; and &amp;#39;H&amp;#39; means depth, width and height respectively. Depth, Width and height dimension cannot be split. For example, NCDHW, NCDHW16c, etc. are valid for pool, while NCDHW16d, NCDHW16w or NCDHW16h are not. See layout for more information of the layout string convention. </div><div class="ttdef"><b>Definition:</b> pooling.h:859</div></div>
<div class="ttc" id="namespacetopi_1_1nn_html_a91b52c68356d23123474ebf10f9b0140"><div class="ttname"><a href="namespacetopi_1_1nn.html#a91b52c68356d23123474ebf10f9b0140">topi::nn::start_index</a></div><div class="ttdeci">PrimExpr start_index(const Var &amp;out_index, const PrimExpr &amp;odim, const PrimExpr &amp;idim)</div><div class="ttdef"><b>Definition:</b> pooling.h:479</div></div>
<div class="ttc" id="namespacetvm_html_ad400409d87dc337f8b5fe13e18d363f9"><div class="ttname"><a href="namespacetvm.html#ad400409d87dc337f8b5fe13e18d363f9">tvm::if_then_else</a></div><div class="ttdeci">PrimExpr if_then_else(PrimExpr cond, PrimExpr true_value, PrimExpr false_value)</div><div class="ttdoc">Conditional expression. </div></div>
<div class="ttc" id="namespacetopi_1_1nn_html_ab1f1f9f86723b30bb8997615e1d63ca8"><div class="ttname"><a href="namespacetopi_1_1nn.html#ab1f1f9f86723b30bb8997615e1d63ca8">topi::nn::find_width</a></div><div class="ttdeci">bool find_width(const std::string &amp;layout, int *width_axis)</div><div class="ttdef"><b>Definition:</b> pooling.h:384</div></div>
<div class="ttc" id="namespacetopi_html_af82f23bc79d3ecca9919b45568192d07"><div class="ttname"><a href="namespacetopi.html#af82f23bc79d3ecca9919b45568192d07">topi::MakeArgmaxReducer</a></div><div class="ttdeci">FCommReduce MakeArgmaxReducer()</div><div class="ttdef"><b>Definition:</b> reduction.h:489</div></div>
<div class="ttc" id="namespacetvm_html_a857781b7243b2f90018f7fe6baf9c30e"><div class="ttname"><a href="namespacetvm.html#a857781b7243b2f90018f7fe6baf9c30e">tvm::indexmod</a></div><div class="ttdeci">PrimExpr indexmod(PrimExpr a, PrimExpr b)</div><div class="ttdoc">compute the remainder floor(a / b) where a and b are non-negative. </div></div>
<div class="ttc" id="tags_8h_html"><div class="ttname"><a href="tags_8h.html">tags.h</a></div><div class="ttdoc">External function interface to rocBLAS libraries. </div></div>
<div class="ttc" id="classtvm_1_1te_1_1TensorNode_html_a4c0b6e32a09ab6ea6b869de45394294d"><div class="ttname"><a href="classtvm_1_1te_1_1TensorNode.html#a4c0b6e32a09ab6ea6b869de45394294d">tvm::te::TensorNode::dtype</a></div><div class="ttdeci">DataType dtype</div><div class="ttdoc">data type in the content of the tensor </div><div class="ttdef"><b>Definition:</b> tensor.h:169</div></div>
<div class="ttc" id="topi_2include_2topi_2nn_8h_html"><div class="ttname"><a href="topi_2include_2topi_2nn_8h.html">nn.h</a></div><div class="ttdoc">NN op constructions. </div></div>
<div class="ttc" id="namespacetopi_1_1nn_html_ac531cfce9c3a031fa25cfb6ed1f9b95b"><div class="ttname"><a href="namespacetopi_1_1nn.html#ac531cfce9c3a031fa25cfb6ed1f9b95b">topi::nn::PoolType</a></div><div class="ttdeci">PoolType</div><div class="ttdoc">Pooling type. </div><div class="ttdef"><b>Definition:</b> pooling.h:43</div></div>
<div class="ttc" id="classtvm_1_1PrimExpr_html"><div class="ttname"><a href="classtvm_1_1PrimExpr.html">tvm::PrimExpr</a></div><div class="ttdoc">Reference to PrimExprNode. </div><div class="ttdef"><b>Definition:</b> expr.h:98</div></div>
<div class="ttc" id="namespacetopi_1_1nn_html_a4f915567f195ade4a17743a5e7654e88"><div class="ttname"><a href="namespacetopi_1_1nn.html#a4f915567f195ade4a17743a5e7654e88">topi::nn::pool_grad</a></div><div class="ttdeci">Tensor pool_grad(const Tensor &amp;out_grad, const Tensor &amp;x, const Array&lt; PrimExpr &gt; &amp;kernel_size, const Array&lt; PrimExpr &gt; &amp;stride_size, const Array&lt; PrimExpr &gt; &amp;padding_size, PoolType pool_type, bool ceil_mode, const std::string &amp;layout=&quot;NCHW&quot;, bool count_include_pad=true)</div><div class="ttdoc">Calculate gradient of pooling on height and width dimension of data. It decides the height and width ...</div><div class="ttdef"><b>Definition:</b> pooling.h:469</div></div>
<div class="ttc" id="namespacetopi_html_acfc3df84ca997ccac0f57d50e96c1c06"><div class="ttname"><a href="namespacetopi.html#acfc3df84ca997ccac0f57d50e96c1c06">topi::cast</a></div><div class="ttdeci">Tensor cast(const Tensor &amp;x, DataType type, std::string name=&quot;T_cast&quot;, std::string tag=kElementWise)</div><div class="ttdoc">Cast each element of x to the given type. If expr is scalar and type is a corresponding vector type...</div><div class="ttdef"><b>Definition:</b> elemwise.h:278</div></div>
<div class="ttc" id="classtvm_1_1runtime_1_1DataType_html_ab45f13dd70d982d9f977c79b6f7fac98"><div class="ttname"><a href="classtvm_1_1runtime_1_1DataType.html#ab45f13dd70d982d9f977c79b6f7fac98">tvm::runtime::DataType::Int</a></div><div class="ttdeci">static DataType Int(int bits, int lanes=1)</div><div class="ttdoc">Construct an int type. </div><div class="ttdef"><b>Definition:</b> data_type.h:175</div></div>
<div class="ttc" id="namespacetopi_1_1nn_html_ad4f34df5cfa8dc75843116bc39f06066"><div class="ttname"><a href="namespacetopi_1_1nn.html#ad4f34df5cfa8dc75843116bc39f06066">topi::nn::adaptive_pool_impl</a></div><div class="ttdeci">Tensor adaptive_pool_impl(const Tensor &amp;x, const Array&lt; PrimExpr &gt; &amp;output_size, PoolType pool_type, const std::vector&lt; int &gt; &amp;axes)</div><div class="ttdoc">Perform adaptive pooling on N dimensional data. </div><div class="ttdef"><b>Definition:</b> pooling.h:503</div></div>
</div><!-- fragment --></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.11
</small></address>
</body>
</html>
