<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.11"/>
<title>tvm: topi/include/topi/cuda/normalization.h Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { init_search(); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">tvm
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.11 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li class="current"><a href="files.html"><span>Files</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="files.html"><span>File&#160;List</span></a></li>
      <li><a href="globals.html"><span>File&#160;Members</span></a></li>
    </ul>
  </div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="dir_a99f4dc995763900c0e382b7dd5d0038.html">topi</a></li><li class="navelem"><a class="el" href="dir_e79ffd3285e304ad4c501fa62028ed74.html">include</a></li><li class="navelem"><a class="el" href="dir_85f3d6180da4edc5eb489febd20e807a.html">topi</a></li><li class="navelem"><a class="el" href="dir_9a72de697ed8769045f2ae88dc0db9c6.html">cuda</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">normalization.h</div>  </div>
</div><!--header-->
<div class="contents">
<a href="cuda_2normalization_8h.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;<span class="comment">/*</span></div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;<span class="comment"> * Licensed to the Apache Software Foundation (ASF) under one</span></div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;<span class="comment"> * or more contributor license agreements.  See the NOTICE file</span></div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;<span class="comment"> * distributed with this work for additional information</span></div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;<span class="comment"> * regarding copyright ownership.  The ASF licenses this file</span></div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;<span class="comment"> * to you under the Apache License, Version 2.0 (the</span></div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;<span class="comment"> * &quot;License&quot;); you may not use this file except in compliance</span></div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;<span class="comment"> * with the License.  You may obtain a copy of the License at</span></div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;<span class="comment"> *   http://www.apache.org/licenses/LICENSE-2.0</span></div><div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;<span class="comment"> *</span></div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;<span class="comment"> * Unless required by applicable law or agreed to in writing,</span></div><div class="line"><a name="l00013"></a><span class="lineno">   13</span>&#160;<span class="comment"> * software distributed under the License is distributed on an</span></div><div class="line"><a name="l00014"></a><span class="lineno">   14</span>&#160;<span class="comment"> * &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY</span></div><div class="line"><a name="l00015"></a><span class="lineno">   15</span>&#160;<span class="comment"> * KIND, either express or implied.  See the License for the</span></div><div class="line"><a name="l00016"></a><span class="lineno">   16</span>&#160;<span class="comment"> * specific language governing permissions and limitations</span></div><div class="line"><a name="l00017"></a><span class="lineno">   17</span>&#160;<span class="comment"> * under the License.</span></div><div class="line"><a name="l00018"></a><span class="lineno">   18</span>&#160;<span class="comment"> */</span></div><div class="line"><a name="l00019"></a><span class="lineno">   19</span>&#160;</div><div class="line"><a name="l00024"></a><span class="lineno">   24</span>&#160;<span class="preprocessor">#ifndef TOPI_CUDA_NORMALIZATION_H_</span></div><div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;<span class="preprocessor">#define TOPI_CUDA_NORMALIZATION_H_</span></div><div class="line"><a name="l00026"></a><span class="lineno">   26</span>&#160;</div><div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;<span class="preprocessor">#include &lt;<a class="code" href="operation_8h.html">tvm/te/operation.h</a>&gt;</span></div><div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;<span class="preprocessor">#include &lt;<a class="code" href="schedule__pass_8h.html">tvm/te/schedule_pass.h</a>&gt;</span></div><div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;<span class="preprocessor">#include &lt;<a class="code" href="generic__func_8h.html">tvm/target/generic_func.h</a>&gt;</span></div><div class="line"><a name="l00030"></a><span class="lineno">   30</span>&#160;<span class="preprocessor">#include &lt;<a class="code" href="tags_8h.html">topi/tags.h</a>&gt;</span></div><div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;</div><div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;<span class="keyword">namespace </span><a class="code" href="namespacetopi.html">topi</a> {</div><div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;<span class="keyword">using namespace </span><a class="code" href="namespacetvm.html">tvm</a>;</div><div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;<span class="keyword">using namespace </span><a class="code" href="namespacetvm_1_1te.html">tvm::te</a>;</div><div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;<span class="keyword">namespace </span><a class="code" href="namespacetvm_1_1target.html#ae035a32c24d135c0ba65303bdbd87416">cuda</a> {</div><div class="line"><a name="l00041"></a><span class="lineno"><a class="line" href="namespacetopi_1_1cuda.html#ac33d664c4579676ce9ac5773acc67c19">   41</a></span>&#160;<span class="keyword">inline</span> <a class="code" href="classtvm_1_1te_1_1Schedule.html">Schedule</a> <a class="code" href="namespacetopi_1_1rocm.html#a59eae2bcfcaab137309bfa39160abe4d">schedule_lrn</a>(<span class="keyword">const</span> <a class="code" href="classtvm_1_1Array.html">Array&lt;Tensor&gt;</a>&amp; outs) {</div><div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;  <a class="code" href="classtvm_1_1Array.html">Array&lt;Operation&gt;</a> out_ops;</div><div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;  <span class="keywordflow">for</span> (<span class="keyword">auto</span> t : outs) {</div><div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;    out_ops.<a class="code" href="classtvm_1_1Array.html#a24d5ac1f6730d46cb1a6d16729f0a7bb">push_back</a>(t-&gt;op);</div><div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160;  }</div><div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160;  <a class="code" href="classtvm_1_1te_1_1Schedule.html">Schedule</a> s = <a class="code" href="namespacetvm_1_1te.html#a485034766309df280239e0994913b34b">create_schedule</a>(out_ops);</div><div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;  <span class="keywordtype">int</span> num_thread = 64;</div><div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;  <a class="code" href="classtvm_1_1tir_1_1IterVar.html">IterVar</a> block_x = <a class="code" href="namespacetvm_1_1te.html#aacca360b75a7db1eb79785bff8c6e205">tvm::te::thread_axis</a>(<a class="code" href="classtvm_1_1Range.html">Range</a>(), <span class="stringliteral">&quot;blockIdx.x&quot;</span>);</div><div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;  <a class="code" href="classtvm_1_1tir_1_1IterVar.html">IterVar</a> thread_x = <a class="code" href="namespacetvm_1_1te.html#aacca360b75a7db1eb79785bff8c6e205">tvm::te::thread_axis</a>(<a class="code" href="classtvm_1_1Range.html">Range</a>(0, num_thread), <span class="stringliteral">&quot;threadIdx.x&quot;</span>);</div><div class="line"><a name="l00050"></a><span class="lineno">   50</span>&#160;  <a class="code" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> <a class="code" href="namespacetopi_1_1nn.html#a0ded232c2572637db6adc7cf5f0b35b2">lrn</a> = outs[0];</div><div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;  <a class="code" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> sqr_sum_up = lrn-&gt;<a class="code" href="classtvm_1_1te_1_1TensorNode.html#a64faab73896ac7e9dd8dc43110920c7c">op</a>-&gt;<a class="code" href="classtvm_1_1te_1_1OperationNode.html#a9675fbb905d62de5b86624388acec4b1">InputTensors</a>()[1];</div><div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;  <a class="code" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> sqr_sum = sqr_sum_up-&gt;<a class="code" href="classtvm_1_1te_1_1TensorNode.html#a64faab73896ac7e9dd8dc43110920c7c">op</a>-&gt;<a class="code" href="classtvm_1_1te_1_1OperationNode.html#a9675fbb905d62de5b86624388acec4b1">InputTensors</a>()[0];</div><div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;  <a class="code" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> set_pad = sqr_sum-&gt;<a class="code" href="classtvm_1_1te_1_1TensorNode.html#a64faab73896ac7e9dd8dc43110920c7c">op</a>-&gt;<a class="code" href="classtvm_1_1te_1_1OperationNode.html#a9675fbb905d62de5b86624388acec4b1">InputTensors</a>()[0];</div><div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;  s[set_pad].bind(set_pad-&gt;<a class="code" href="classtvm_1_1te_1_1TensorNode.html#a64faab73896ac7e9dd8dc43110920c7c">op</a>.as&lt;<a class="code" href="classtvm_1_1te_1_1ComputeOpNode.html">ComputeOpNode</a>&gt;()-&gt;<a class="code" href="classtvm_1_1te_1_1BaseComputeOpNode.html#a21617a643897727c51ded2b7260df4c3">axis</a>[0], block_x);</div><div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;  <a class="code" href="classtvm_1_1tir_1_1IterVar.html">IterVar</a> rxk = sqr_sum-&gt;<a class="code" href="classtvm_1_1te_1_1TensorNode.html#a64faab73896ac7e9dd8dc43110920c7c">op</a>.as&lt;<a class="code" href="classtvm_1_1te_1_1ComputeOpNode.html">ComputeOpNode</a>&gt;()-&gt;<a class="code" href="namespacetvm_1_1te.html#aae384e9b73c2271905486e4a74b69265">reduce_axis</a>[0];</div><div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;  <a class="code" href="classtvm_1_1tir_1_1IterVar.html">IterVar</a> xko, xki;</div><div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;  s[sqr_sum].split(rxk, num_thread, &amp;xko, &amp;xki);</div><div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;  <a class="code" href="classtvm_1_1te_1_1Tensor.html">Tensor</a> srf = s.<a class="code" href="classtvm_1_1te_1_1Schedule.html#a34ae85add41bbed0140726d024d08862">rfactor</a>(sqr_sum, xki)[0];</div><div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;  s[sqr_sum].bind(s[sqr_sum]-&gt;op.as&lt;<a class="code" href="classtvm_1_1te_1_1ComputeOpNode.html">ComputeOpNode</a>&gt;()-&gt;<a class="code" href="classtvm_1_1te_1_1BaseComputeOpNode.html#a21617a643897727c51ded2b7260df4c3">axis</a>[0], block_x);</div><div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;  s[sqr_sum].bind(s[sqr_sum]-&gt;op.as&lt;<a class="code" href="classtvm_1_1te_1_1ComputeOpNode.html">ComputeOpNode</a>&gt;()-&gt;<a class="code" href="classtvm_1_1te_1_1BaseComputeOpNode.html#ad0df643468fc148d80afd7116abdd2ac">reduce_axis</a>[0], thread_x);</div><div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160;  s[srf].compute_at(s[sqr_sum], s[sqr_sum]-&gt;op.as&lt;<a class="code" href="classtvm_1_1te_1_1ComputeOpNode.html">ComputeOpNode</a>&gt;()-&gt;<a class="code" href="classtvm_1_1te_1_1BaseComputeOpNode.html#ad0df643468fc148d80afd7116abdd2ac">reduce_axis</a>[0]);</div><div class="line"><a name="l00062"></a><span class="lineno">   62</span>&#160;  s[sqr_sum_up].bind(sqr_sum_up-&gt;<a class="code" href="classtvm_1_1te_1_1TensorNode.html#a64faab73896ac7e9dd8dc43110920c7c">op</a>.as&lt;<a class="code" href="classtvm_1_1te_1_1ComputeOpNode.html">ComputeOpNode</a>&gt;()-&gt;<a class="code" href="classtvm_1_1te_1_1BaseComputeOpNode.html#a21617a643897727c51ded2b7260df4c3">axis</a>[0], block_x);</div><div class="line"><a name="l00063"></a><span class="lineno">   63</span>&#160;  <a class="code" href="classtvm_1_1tir_1_1IterVar.html">IterVar</a> xto, xti;</div><div class="line"><a name="l00064"></a><span class="lineno">   64</span>&#160;  s[<a class="code" href="namespacetopi_1_1nn.html#a0ded232c2572637db6adc7cf5f0b35b2">lrn</a>].split_by_nparts(lrn-&gt;<a class="code" href="classtvm_1_1te_1_1TensorNode.html#a64faab73896ac7e9dd8dc43110920c7c">op</a>.as&lt;<a class="code" href="classtvm_1_1te_1_1ComputeOpNode.html">ComputeOpNode</a>&gt;()-&gt;<a class="code" href="classtvm_1_1te_1_1BaseComputeOpNode.html#a21617a643897727c51ded2b7260df4c3">axis</a>[1], num_thread, &amp;xto, &amp;xti);</div><div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;  s[<a class="code" href="namespacetopi_1_1nn.html#a0ded232c2572637db6adc7cf5f0b35b2">lrn</a>].bind(lrn-&gt;<a class="code" href="classtvm_1_1te_1_1TensorNode.html#a64faab73896ac7e9dd8dc43110920c7c">op</a>.as&lt;<a class="code" href="classtvm_1_1te_1_1ComputeOpNode.html">ComputeOpNode</a>&gt;()-&gt;<a class="code" href="classtvm_1_1te_1_1BaseComputeOpNode.html#a21617a643897727c51ded2b7260df4c3">axis</a>[0], block_x);</div><div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;  s[<a class="code" href="namespacetopi_1_1nn.html#a0ded232c2572637db6adc7cf5f0b35b2">lrn</a>].bind(xto, thread_x);</div><div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;</div><div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;  <span class="keywordflow">return</span> s;</div><div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;}</div><div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;</div><div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;}  <span class="comment">// namespace cuda</span></div><div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;}  <span class="comment">// namespace topi</span></div><div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;<span class="preprocessor">#endif  // TOPI_CUDA_NORMALIZATION_H_</span></div><div class="ttc" id="namespacetvm_1_1te_html_aacca360b75a7db1eb79785bff8c6e205"><div class="ttname"><a href="namespacetvm_1_1te.html#aacca360b75a7db1eb79785bff8c6e205">tvm::te::thread_axis</a></div><div class="ttdeci">IterVar thread_axis(Range dom, std::string tag)</div><div class="ttdoc">Create a new IterVar that represents an axis in thread. </div></div>
<div class="ttc" id="classtvm_1_1te_1_1Schedule_html"><div class="ttname"><a href="classtvm_1_1te_1_1Schedule.html">tvm::te::Schedule</a></div><div class="ttdoc">Global schedule container For operations and all the operations they depend on. The schedule per Oper...</div><div class="ttdef"><b>Definition:</b> schedule.h:281</div></div>
<div class="ttc" id="namespacetvm_1_1te_html_a485034766309df280239e0994913b34b"><div class="ttname"><a href="namespacetvm_1_1te.html#a485034766309df280239e0994913b34b">tvm::te::create_schedule</a></div><div class="ttdeci">Schedule create_schedule(Array&lt; Operation &gt; ops)</div><div class="ttdoc">Create a schedule for array of ops(and their dependencies). </div><div class="ttdef"><b>Definition:</b> schedule.h:588</div></div>
<div class="ttc" id="namespacetvm_html"><div class="ttname"><a href="namespacetvm.html">tvm</a></div><div class="ttdef"><b>Definition:</b> analyzer.h:36</div></div>
<div class="ttc" id="classtvm_1_1Array_html_a24d5ac1f6730d46cb1a6d16729f0a7bb"><div class="ttname"><a href="classtvm_1_1Array.html#a24d5ac1f6730d46cb1a6d16729f0a7bb">tvm::Array::push_back</a></div><div class="ttdeci">void push_back(const T &amp;item)</div><div class="ttdoc">push a new item to the back of the list </div><div class="ttdef"><b>Definition:</b> container.h:270</div></div>
<div class="ttc" id="namespacetvm_1_1te_html"><div class="ttname"><a href="namespacetvm_1_1te.html">tvm::te</a></div><div class="ttdoc">Tensor expression language DSL. </div><div class="ttdef"><b>Definition:</b> bound.h:36</div></div>
<div class="ttc" id="classtvm_1_1te_1_1TensorNode_html_a64faab73896ac7e9dd8dc43110920c7c"><div class="ttname"><a href="classtvm_1_1te_1_1TensorNode.html#a64faab73896ac7e9dd8dc43110920c7c">tvm::te::TensorNode::op</a></div><div class="ttdeci">Operation op</div><div class="ttdoc">the source operation, can be None </div><div class="ttdef"><b>Definition:</b> tensor.h:171</div></div>
<div class="ttc" id="classtvm_1_1tir_1_1IterVar_html"><div class="ttname"><a href="classtvm_1_1tir_1_1IterVar.html">tvm::tir::IterVar</a></div><div class="ttdoc">Iteration Variable, represents an iteration over an integer interval. </div><div class="ttdef"><b>Definition:</b> expr.h:254</div></div>
<div class="ttc" id="namespacetopi_1_1rocm_html_a59eae2bcfcaab137309bfa39160abe4d"><div class="ttname"><a href="namespacetopi_1_1rocm.html#a59eae2bcfcaab137309bfa39160abe4d">topi::rocm::schedule_lrn</a></div><div class="ttdeci">Schedule schedule_lrn(const Array&lt; Tensor &gt; &amp;outs)</div><div class="ttdoc">Create a rocm schedule for LRN. </div><div class="ttdef"><b>Definition:</b> normalization.h:40</div></div>
<div class="ttc" id="schedule__pass_8h_html"><div class="ttname"><a href="schedule__pass_8h.html">schedule_pass.h</a></div><div class="ttdoc">Collection of Schedule pass functions. </div></div>
<div class="ttc" id="namespacetopi_html"><div class="ttname"><a href="namespacetopi.html">topi</a></div><div class="ttdef"><b>Definition:</b> broadcast.h:34</div></div>
<div class="ttc" id="classtvm_1_1Range_html"><div class="ttname"><a href="classtvm_1_1Range.html">tvm::Range</a></div><div class="ttdoc">Range constainer. </div><div class="ttdef"><b>Definition:</b> expr.h:404</div></div>
<div class="ttc" id="classtvm_1_1te_1_1OperationNode_html_a9675fbb905d62de5b86624388acec4b1"><div class="ttname"><a href="classtvm_1_1te_1_1OperationNode.html#a9675fbb905d62de5b86624388acec4b1">tvm::te::OperationNode::InputTensors</a></div><div class="ttdeci">virtual Array&lt; Tensor &gt; InputTensors() const =0</div><div class="ttdoc">List all the input Tensors. </div></div>
<div class="ttc" id="classtvm_1_1Array_html"><div class="ttname"><a href="classtvm_1_1Array.html">tvm::Array</a></div><div class="ttdoc">Array container of NodeRef in DSL graph. Array implements copy on write semantics, which means array is mutable but copy will happen when array is referenced in more than two places. </div><div class="ttdef"><b>Definition:</b> container.h:141</div></div>
<div class="ttc" id="classtvm_1_1te_1_1ComputeOpNode_html"><div class="ttname"><a href="classtvm_1_1te_1_1ComputeOpNode.html">tvm::te::ComputeOpNode</a></div><div class="ttdoc">A Compute op that compute a tensor on certain domain. </div><div class="ttdef"><b>Definition:</b> operation.h:240</div></div>
<div class="ttc" id="classtvm_1_1te_1_1BaseComputeOpNode_html_a21617a643897727c51ded2b7260df4c3"><div class="ttname"><a href="classtvm_1_1te_1_1BaseComputeOpNode.html#a21617a643897727c51ded2b7260df4c3">tvm::te::BaseComputeOpNode::axis</a></div><div class="ttdeci">Array&lt; IterVar &gt; axis</div><div class="ttdoc">IterVar on each axis. </div><div class="ttdef"><b>Definition:</b> operation.h:216</div></div>
<div class="ttc" id="namespacetvm_1_1te_html_aae384e9b73c2271905486e4a74b69265"><div class="ttname"><a href="namespacetvm_1_1te.html#aae384e9b73c2271905486e4a74b69265">tvm::te::reduce_axis</a></div><div class="ttdeci">IterVar reduce_axis(Range dom, std::string name=&quot;rv&quot;)</div><div class="ttdoc">Create a new IterVar for reduction operations. </div></div>
<div class="ttc" id="classtvm_1_1te_1_1Tensor_html"><div class="ttname"><a href="classtvm_1_1te_1_1Tensor.html">tvm::te::Tensor</a></div><div class="ttdoc">Tensor structure representing a possible input, or intermediate computation result. </div><div class="ttdef"><b>Definition:</b> tensor.h:52</div></div>
<div class="ttc" id="operation_8h_html"><div class="ttname"><a href="operation_8h.html">operation.h</a></div><div class="ttdoc">Operation node can generate one or multiple Tensors. </div></div>
<div class="ttc" id="classtvm_1_1te_1_1Schedule_html_a34ae85add41bbed0140726d024d08862"><div class="ttname"><a href="classtvm_1_1te_1_1Schedule.html#a34ae85add41bbed0140726d024d08862">tvm::te::Schedule::rfactor</a></div><div class="ttdeci">Array&lt; Tensor &gt; rfactor(const Tensor &amp;tensor, const IterVar &amp;axis, int factor_axis=0)</div><div class="ttdoc">Factor a reduction axis in tensor&amp;#39;s schedule to be an explicit axis. This will create a new stage tha...</div></div>
<div class="ttc" id="namespacetvm_1_1target_html_ae035a32c24d135c0ba65303bdbd87416"><div class="ttname"><a href="namespacetvm_1_1target.html#ae035a32c24d135c0ba65303bdbd87416">tvm::target::cuda</a></div><div class="ttdeci">Target cuda(const std::vector&lt; std::string &gt; &amp;options=std::vector&lt; std::string &gt;())</div></div>
<div class="ttc" id="tags_8h_html"><div class="ttname"><a href="tags_8h.html">tags.h</a></div><div class="ttdoc">External function interface to rocBLAS libraries. </div></div>
<div class="ttc" id="namespacetopi_1_1nn_html_a0ded232c2572637db6adc7cf5f0b35b2"><div class="ttname"><a href="namespacetopi_1_1nn.html#a0ded232c2572637db6adc7cf5f0b35b2">topi::nn::lrn</a></div><div class="ttdeci">Tensor lrn(const Tensor &amp;data, int size, int axis=1, float alpha=0.0001, float beta=0.75, float bias=2, std::string name=&quot;tensor&quot;, std::string tag=kBroadcast)</div><div class="ttdoc">Local response normalization inference operator. </div><div class="ttdef"><b>Definition:</b> local_response_norm.h:51</div></div>
<div class="ttc" id="classtvm_1_1te_1_1BaseComputeOpNode_html_ad0df643468fc148d80afd7116abdd2ac"><div class="ttname"><a href="classtvm_1_1te_1_1BaseComputeOpNode.html#ad0df643468fc148d80afd7116abdd2ac">tvm::te::BaseComputeOpNode::reduce_axis</a></div><div class="ttdeci">Array&lt; IterVar &gt; reduce_axis</div><div class="ttdoc">IterVar on each reduction axis, if the body is a Reduce. </div><div class="ttdef"><b>Definition:</b> operation.h:218</div></div>
<div class="ttc" id="generic__func_8h_html"><div class="ttname"><a href="generic__func_8h.html">generic_func.h</a></div><div class="ttdoc">Generic function that can be specialzied on a per target basis. </div></div>
</div><!-- fragment --></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.11
</small></address>
</body>
</html>
